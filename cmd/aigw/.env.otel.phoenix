# Phoenix configuration - LLM-specific observability
OTEL_SERVICE_NAME=aigw
# Phoenix uses port 4317 for OTLP gRPC, port 6006 for web UI
# TODO: Next release after Envoy Gateway v1.7.0-rc.1 revert to normal service name
# OTEL_EXPORTER_OTLP_ENDPOINT=http://phoenix:4317
OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4317
OTEL_EXPORTER_OTLP_PROTOCOL=grpc
# Phoenix only supports traces, not metrics or logs
OTEL_METRICS_EXPORTER=none
OTEL_LOGS_EXPORTER=console
# Reduce trace export delay for demo purposes
OTEL_BSP_SCHEDULE_DELAY=100

# Below are default values for span redaction in OpenInference.
# See https://github.com/Arize-ai/openinference/blob/main/spec/configuration.md
OPENINFERENCE_HIDE_INPUTS=false
OPENINFERENCE_HIDE_OUTPUTS=false
# See https://github.com/Arize-ai/openinference/blob/main/spec/embedding_spans.md
OPENINFERENCE_HIDE_EMBEDDINGS_TEXT=false
OPENINFERENCE_HIDE_EMBEDDINGS_VECTORS=false

// Copyright Envoy AI Gateway Authors
// SPDX-License-Identifier: Apache-2.0
// The full text of the Apache license is available in the LICENSE file at
// the root of the repo.

// Package openai contains the following is the OpenAI API schema definitions.
// Note that we intentionally do not use the code generation tools like OpenAPI Generator not only to keep the code simple
// but also because the OpenAI's OpenAPI definition is not compliant with the spec and the existing tools do not work well.
package openai

import (
	"bytes"
	"encoding/base64"
	"errors"
	"fmt"
	"strconv"
	"strings"
	"time"

	"github.com/anthropics/anthropic-sdk-go"
	"github.com/openai/openai-go/v2"
	"github.com/tidwall/gjson"
	"google.golang.org/genai"

	"github.com/envoyproxy/ai-gateway/internal/apischema/awsbedrock"
	"github.com/envoyproxy/ai-gateway/internal/json"
)

// Chat message role defined by the OpenAI API.
const (
	ChatMessageRoleSystem    = "system"
	ChatMessageRoleDeveloper = "developer"
	ChatMessageRoleUser      = "user"
	ChatMessageRoleAssistant = "assistant"
	ChatMessageRoleFunction  = "function"
	ChatMessageRoleTool      = "tool"
)

// Model names for testing.
const (
	// ModelBabbage002 is the cheapest model usable with /completions (legacy).
	// It uses cl100k_base tokenizer.
	ModelBabbage002 = "babbage-002"
	// ModelGPT35TurboInstruct is a completion model that supports the suffix parameter.
	// It uses cl100k_base tokenizer.
	ModelGPT35TurboInstruct = "gpt-3.5-turbo-instruct"
	// ModelGPT5Nano is the cheapest model usable with /chat/completions.
	// Note: gpt-5-nano is also the cheapest reasoning model.
	ModelGPT5Nano = "gpt-5-nano"
	// ModelGPT4oMiniAudioPreview is the cheapest audio synthesis model usable with /chat/completions.
	ModelGPT4oMiniAudioPreview = "gpt-4o-mini-audio-preview"
	// ModelGPT4oAudioPreview is the cheapest audio transcription model usable with /chat/completions.
	// Note: gpt-4o-mini-transcribe is NOT a chat model, so cannot be used with /v1/chat/completions.
	ModelGPT4oAudioPreview = "gpt-4o-audio-preview"
	// ModelGPT4oMiniSearchPreview is the cheapest web search model usable with /chat/completions.
	// Note: gpt-5 series supports web search, but only in the /responses API.
	ModelGPT4oMiniSearchPreview = "gpt-4o-mini-search-preview"

	// ModelTextEmbedding3Small is the cheapest model usable with /embeddings.
	ModelTextEmbedding3Small = "text-embedding-3-small"

	// ModelGPTImage1Mini is the smallest/cheapest Images model usable with
	// /v1/images/generations. Use with size "1024x1024" and quality "low".
	ModelGPTImage1Mini = "gpt-image-1-mini"
)

// ChatCompletionContentPartRefusalType The type of the content part.
type ChatCompletionContentPartRefusalType string

// ChatCompletionContentPartInputAudioType The type of the content part. Always `input_audio`.
type ChatCompletionContentPartInputAudioType string

// ChatCompletionContentPartTextType The type of the content part.
type ChatCompletionContentPartTextType string

// ChatCompletionContentPartImageType The type of the content part.
type ChatCompletionContentPartImageType string

// ChatCompletionContentPartFileType The type of the content part.
type ChatCompletionContentPartFileType string

const (
	ChatCompletionContentPartTextTypeText             ChatCompletionContentPartTextType       = "text"
	ChatCompletionContentPartRefusalTypeRefusal       ChatCompletionContentPartRefusalType    = "refusal"
	ChatCompletionContentPartInputAudioTypeInputAudio ChatCompletionContentPartInputAudioType = "input_audio"
	ChatCompletionContentPartImageTypeImageURL        ChatCompletionContentPartImageType      = "image_url"
	ChatCompletionContentPartFileTypeFile             ChatCompletionContentPartFileType       = "file"
)

// ChatCompletionContentPartTextParam Learn about
// [text inputs](https://platform.openai.com/docs/guides/text-generation).
type ChatCompletionContentPartTextParam struct {
	// The text content.
	Text string `json:"text"`
	// The type of the content part.
	Type                    string `json:"type"`
	*AnthropicContentFields `json:",inline,omitempty"`
}

type ChatCompletionContentPartRefusalParam struct {
	// The refusal message generated by the model.
	Refusal string `json:"refusal"`
	// The type of the content part.
	Type ChatCompletionContentPartRefusalType `json:"type"`
}

// ChatCompletionContentPartInputAudioParam Learn about [audio inputs](https://platform.openai.com/docs/guides/audio).
type ChatCompletionContentPartInputAudioParam struct {
	InputAudio ChatCompletionContentPartInputAudioInputAudioParam `json:"input_audio"`
	// The type of the content part. Always `input_audio`.
	Type                    ChatCompletionContentPartInputAudioType `json:"type"`
	*AnthropicContentFields `json:",inline,omitempty"`
}

// ChatCompletionContentPartInputAudioInputAudioFormat The format of the encoded audio data. Currently supports "wav" and "mp3".
type ChatCompletionContentPartInputAudioInputAudioFormat string

const (
	ChatCompletionContentPartInputAudioInputAudioFormatWAV ChatCompletionContentPartInputAudioInputAudioFormat = "wav"
	ChatCompletionContentPartInputAudioInputAudioFormatMP3 ChatCompletionContentPartInputAudioInputAudioFormat = "mp3"
)

type ChatCompletionContentPartInputAudioInputAudioParam struct {
	// Base64 encoded audio data.
	Data string `json:"data"`
	// The format of the encoded audio data. Currently supports "wav" and "mp3".
	Format ChatCompletionContentPartInputAudioInputAudioFormat `json:"format"`
}

type ChatCompletionContentPartImageImageURLDetail string

const (
	ChatCompletionContentPartImageImageURLDetailAuto ChatCompletionContentPartImageImageURLDetail = "auto"
	ChatCompletionContentPartImageImageURLDetailLow  ChatCompletionContentPartImageImageURLDetail = "low"
	// medium is only supported in gemini-3
	ChatCompletionContentPartImageImageURLDetailMedium ChatCompletionContentPartImageImageURLDetail = "medium"
	ChatCompletionContentPartImageImageURLDetailHigh   ChatCompletionContentPartImageImageURLDetail = "high"
)

type ChatCompletionContentPartImageImageURLParam struct {
	// Either a URL of the image or the base64 encoded image data.
	URL string `json:"url"`
	// Specifies the detail level of the image. Learn more in the
	// [Vision guide](https://platform.openai.com/docs/guides/vision#low-or-high-fidelity-image-understanding).
	Detail ChatCompletionContentPartImageImageURLDetail `json:"detail,omitempty"`
}

// ChatCompletionContentPartImageParam Learn about [image inputs](https://platform.openai.com/docs/guides/vision).
type ChatCompletionContentPartImageParam struct {
	ImageURL ChatCompletionContentPartImageImageURLParam `json:"image_url"`
	// The type of the content part.
	Type                    ChatCompletionContentPartImageType `json:"type"`
	*AnthropicContentFields `json:",inline,omitempty"`
}

type ChatCompletionContentPartFileFileParam struct {
	// The base64 encoded file data, used when passing the file to the model as a
	// string.
	FileData string `json:"file_data,omitzero"`
	// The ID of an uploaded file to use as input.
	FileID string `json:"file_id,omitzero"`
	// The name of the file, used when passing the file to the model as a string.
	Filename string `json:"filename,omitzero"`
}

// ChatCompletionContentPartFileParam .
type ChatCompletionContentPartFileParam struct {
	File ChatCompletionContentPartFileFileParam `json:"file,omitzero"`
	// The type of the content part. Always `file`.
	//
	// This field can be elided, and will marshal its zero value as "file".
	Type                    ChatCompletionContentPartFileType `json:"type"`
	*AnthropicContentFields `json:",inline,omitempty"`
}

// ChatCompletionContentPartUserUnionParam Learn about
// [text inputs](https://platform.openai.com/docs/guides/text-generation).
type ChatCompletionContentPartUserUnionParam struct {
	OfText       *ChatCompletionContentPartTextParam       `json:",omitzero,inline"`
	OfInputAudio *ChatCompletionContentPartInputAudioParam `json:",omitzero,inline"`
	OfImageURL   *ChatCompletionContentPartImageParam      `json:",omitzero,inline"`
	OfFile       *ChatCompletionContentPartFileParam       `json:",omitzero,inline"`
}

func (c *ChatCompletionContentPartUserUnionParam) UnmarshalJSON(data []byte) error {
	typeResult := gjson.GetBytes(data, "type")
	if !typeResult.Exists() {
		return errors.New("chat content does not have type")
	}

	// Based on the 'type' field, unmarshal into the correct struct.
	contentType := typeResult.String()

	switch contentType {
	case string(ChatCompletionContentPartTextTypeText):
		var textContent ChatCompletionContentPartTextParam
		if err := json.Unmarshal(data, &textContent); err != nil {
			return err
		}
		c.OfText = &textContent
	case string(ChatCompletionContentPartInputAudioTypeInputAudio):
		var audioContent ChatCompletionContentPartInputAudioParam
		if err := json.Unmarshal(data, &audioContent); err != nil {
			return err
		}
		c.OfInputAudio = &audioContent
	case string(ChatCompletionContentPartImageTypeImageURL):
		var imageContent ChatCompletionContentPartImageParam
		if err := json.Unmarshal(data, &imageContent); err != nil {
			return err
		}
		c.OfImageURL = &imageContent
	case string(ChatCompletionContentPartFileTypeFile):
		var fileContent ChatCompletionContentPartFileParam
		if err := json.Unmarshal(data, &fileContent); err != nil {
			return err
		}
		c.OfFile = &fileContent

	default:
		return fmt.Errorf("unknown ChatCompletionContentPartUnionParam type: %v", contentType)
	}
	return nil
}

func (c ChatCompletionContentPartUserUnionParam) MarshalJSON() ([]byte, error) {
	if c.OfText != nil {
		return json.Marshal(c.OfText)
	}
	if c.OfInputAudio != nil {
		return json.Marshal(c.OfInputAudio)
	}
	if c.OfImageURL != nil {
		return json.Marshal(c.OfImageURL)
	}
	return nil, errors.New("no content to marshal")
}

type StringOrAssistantRoleContentUnion struct {
	Value any
}

func (s *StringOrAssistantRoleContentUnion) UnmarshalJSON(data []byte) error {
	var str string
	err := json.Unmarshal(data, &str)
	if err == nil {
		s.Value = str
		return nil
	}

	var content []ChatCompletionAssistantMessageParamContent
	err = json.Unmarshal(data, &content)
	if err == nil {
		s.Value = content
		return nil
	}

	var singleContent ChatCompletionAssistantMessageParamContent
	err = json.Unmarshal(data, &singleContent)
	if err == nil {
		s.Value = singleContent
		return nil
	}

	return errors.New("cannot unmarshal JSON data as string or assistant content parts")
}

func (s StringOrAssistantRoleContentUnion) MarshalJSON() ([]byte, error) {
	return json.Marshal(s.Value)
}

// ContentUnion represents content fields in system, developer, and tool
// messages.
//
// Note: This does not include user or assistant messages which have their own
// unions due to supporting more types.
//
// According to OpenAI API spec, these accept either:
// - string: plain text content
// - []ChatCompletionContentPartTextParam: array of text content parts (only text type supported)
type ContentUnion struct {
	Value any
}

// UnmarshalJSON is tuned to be faster with substantially reduced allocations
// vs openai-go which has heavy use of reflection.
func (c *ContentUnion) UnmarshalJSON(data []byte) error {
	// Skip leading whitespace
	idx, err := skipLeadingWhitespace("content", data, 0)
	if err != nil {
		return err
	}

	switch data[idx] {
	case '"':
		c.Value, err = unquoteOrUnmarshalJSONString("content", data)
		return err
	case '[':
		var arr []ChatCompletionContentPartTextParam
		if err := json.Unmarshal(data, &arr); err != nil {
			return fmt.Errorf("cannot unmarshal content as []ChatCompletionContentPartTextParam: %w", err)
		}
		c.Value = arr
		return nil
	default:
		return fmt.Errorf("invalid content type (must be string or array of ChatCompletionContentPartTextParam)")
	}
}

func (c ContentUnion) MarshalJSON() ([]byte, error) {
	return json.Marshal(c.Value)
}

// EmbeddingContent represents content that can be either a string or an array of strings.
// This allows embedding inputs to specify multiple texts with a shared task_type.
type EmbeddingContent struct {
	Value any // string or []string
}

func (c *EmbeddingContent) UnmarshalJSON(data []byte) error {
	// Try string first
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		c.Value = str
		return nil
	}
	// Try array of strings
	var strs []string
	if err := json.Unmarshal(data, &strs); err == nil {
		c.Value = strs
		return nil
	}
	return fmt.Errorf("content must be string or array of strings")
}

func (c EmbeddingContent) MarshalJSON() ([]byte, error) {
	return json.Marshal(c.Value)
}

// IsEmpty returns true if the content is empty (no string or empty string, no array or empty array)
func (c EmbeddingContent) IsEmpty() bool {
	switch v := c.Value.(type) {
	case string:
		return v == ""
	case []string:
		return len(v) == 0
	default:
		return true
	}
}

// EmbeddingInputItem represents a single embedding input with optional metadata
type EmbeddingInputItem struct {
	Content  EmbeddingContent  `json:"content"`             // The actual text content (string or []string)
	TaskType EmbeddingTaskType `json:"task_type,omitempty"` // Optional task type
	Title    string            `json:"title,omitempty"`     // Optional title
}

// EmbeddingRequestInput is the EmbeddingRequest.Input type.
type EmbeddingRequestInput struct {
	Value any
}

func (s *EmbeddingRequestInput) UnmarshalJSON(data []byte) (err error) {
	// Use embedding-specific parser that supports objects with content/task_type/title
	s.Value, err = unmarshalJSONEmbeddingInput("input", data)
	if err != nil {
		return
	}
	return
}

func (s EmbeddingRequestInput) MarshalJSON() ([]byte, error) {
	return json.Marshal(s.Value)
}

type StringOrUserRoleContentUnion struct {
	Value any
}

func (s *StringOrUserRoleContentUnion) UnmarshalJSON(data []byte) error {
	var str string
	err := json.Unmarshal(data, &str)
	if err == nil {
		s.Value = str
		return nil
	}

	var arr []ChatCompletionContentPartUserUnionParam
	err = json.Unmarshal(data, &arr)
	if err == nil {
		s.Value = arr
		return nil
	}

	return fmt.Errorf("cannot unmarshal JSON data as string or array of content parts")
}

func (s StringOrUserRoleContentUnion) MarshalJSON() ([]byte, error) {
	return json.Marshal(s.Value)
}

// AnthropicContentFields contains Anthropic model-specific fields that can be added to messages.
type AnthropicContentFields struct {
	CacheControl anthropic.CacheControlEphemeralParam `json:"cache_control,omitzero"`
}

// Function message is deprecated and we do not allow it.
type ChatCompletionMessageParamUnion struct {
	OfDeveloper *ChatCompletionDeveloperMessageParam `json:",omitzero,inline"`
	OfSystem    *ChatCompletionSystemMessageParam    `json:",omitzero,inline"`
	OfUser      *ChatCompletionUserMessageParam      `json:",omitzero,inline"`
	OfAssistant *ChatCompletionAssistantMessageParam `json:",omitzero,inline"`
	OfTool      *ChatCompletionToolMessageParam      `json:",omitzero,inline"`
}

func (c *ChatCompletionMessageParamUnion) UnmarshalJSON(data []byte) error {
	roleResult := gjson.GetBytes(data, "role")
	if !roleResult.Exists() {
		return errors.New("chat message does not have role")
	}

	// Based on the 'role' field, unmarshal into the correct struct.
	role := roleResult.String()

	switch role {
	case ChatMessageRoleUser:
		var userMessage ChatCompletionUserMessageParam
		if err := json.Unmarshal(data, &userMessage); err != nil {
			return err
		}
		c.OfUser = &userMessage
	case ChatMessageRoleAssistant:
		var assistantMessage ChatCompletionAssistantMessageParam
		if err := json.Unmarshal(data, &assistantMessage); err != nil {
			return err
		}
		c.OfAssistant = &assistantMessage
	case ChatMessageRoleSystem:
		var systemMessage ChatCompletionSystemMessageParam
		if err := json.Unmarshal(data, &systemMessage); err != nil {
			return err
		}
		c.OfSystem = &systemMessage
	case ChatMessageRoleDeveloper:
		var developerMessage ChatCompletionDeveloperMessageParam
		if err := json.Unmarshal(data, &developerMessage); err != nil {
			return err
		}
		c.OfDeveloper = &developerMessage
	case ChatMessageRoleTool:
		var toolMessage ChatCompletionToolMessageParam
		if err := json.Unmarshal(data, &toolMessage); err != nil {
			return err
		}
		c.OfTool = &toolMessage
	default:
		return fmt.Errorf("unknown ChatCompletionMessageParam type: %v", role)
	}
	return nil
}

func (c ChatCompletionMessageParamUnion) MarshalJSON() ([]byte, error) {
	if c.OfUser != nil {
		return json.Marshal(c.OfUser)
	}
	if c.OfAssistant != nil {
		return json.Marshal(c.OfAssistant)
	}
	if c.OfSystem != nil {
		return json.Marshal(c.OfSystem)
	}
	if c.OfDeveloper != nil {
		return json.Marshal(c.OfDeveloper)
	}
	if c.OfTool != nil {
		return json.Marshal(c.OfTool)
	}

	return nil, errors.New("no message to marshal")
}

// ChatCompletionUserMessageParam Messages sent by an end user, containing prompts or additional context
// information.
type ChatCompletionUserMessageParam struct {
	// The contents of the user message.
	Content StringOrUserRoleContentUnion `json:"content"`
	// The role of the messages author, in this case `user`.
	Role string `json:"role"`
	// An optional name for the participant. Provides the model information to
	// differentiate between participants of the same role.
	Name string `json:"name,omitempty"`
}

// ChatCompletionSystemMessageParam represents a system message.
// Developer-provided instructions that the model should follow, regardless of
// messages sent by the user. With o1 models and newer, use `developer` messages
// for this purpose instead.
// Docs: https://platform.openai.com/docs/api-reference/chat/create#messages
type ChatCompletionSystemMessageParam struct {
	// Content: The contents of the system message.
	Content ContentUnion `json:"content"`
	// The role of the messages author, in this case `system`.
	Role string `json:"role"`
	// An optional name for the participant. Provides the model information to
	// differentiate between participants of the same role.
	Name string `json:"name,omitempty"`
}

// ChatCompletionDeveloperMessageParam represents a developer message.
// Developer-provided instructions that the model should follow, regardless of
// messages sent by the user. With o1 models and newer, `developer` messages
// replace the previous `system` messages.
// Docs: https://platform.openai.com/docs/api-reference/chat/create#messages
type ChatCompletionDeveloperMessageParam struct {
	// Content: The contents of the developer message.
	Content ContentUnion `json:"content"`
	// The role of the messages author, in this case `developer`.
	Role string `json:"role"`
	// An optional name for the participant. Provides the model information to
	// differentiate between participants of the same role.
	Name string `json:"name,omitempty"`
}

// ChatCompletionToolMessageParam represents a tool message.
// Docs: https://platform.openai.com/docs/api-reference/chat/create#messages
type ChatCompletionToolMessageParam struct {
	// Content: The contents of the tool message.
	Content ContentUnion `json:"content"`
	// The role of the messages author, in this case `tool`.
	Role string `json:"role"`
	// Tool call that this message is responding to.
	ToolCallID string `json:"tool_call_id"`
}

// ChatCompletionAssistantMessageParamAudio Data about a previous audio response from the model.
// [Learn more](https://platform.openai.com/docs/guides/audio).
type ChatCompletionAssistantMessageParamAudio struct {
	// Unique identifier for a previous audio response from the model.
	ID string `json:"id"`
}

// ChatCompletionAssistantMessageParamContentType The type of the content part.
type ChatCompletionAssistantMessageParamContentType string

const (
	ChatCompletionAssistantMessageParamContentTypeText             ChatCompletionAssistantMessageParamContentType = "text"
	ChatCompletionAssistantMessageParamContentTypeRefusal          ChatCompletionAssistantMessageParamContentType = "refusal"
	ChatCompletionAssistantMessageParamContentTypeThinking         ChatCompletionAssistantMessageParamContentType = "thinking"
	ChatCompletionAssistantMessageParamContentTypeRedactedThinking ChatCompletionAssistantMessageParamContentType = "redacted_thinking"
)

// ChatCompletionAssistantMessageParamContent Learn about
// [text inputs](https://platform.openai.com/docs/guides/text-generation).
type ChatCompletionAssistantMessageParamContent struct {
	// The type of the content part.
	Type ChatCompletionAssistantMessageParamContentType `json:"type"`
	// The refusal message generated by the model.
	Refusal *string `json:"refusal,omitempty"`
	// The text content.
	Text *string `json:"text,omitempty"`

	// The signature for a thinking block.
	Signature               *string               `json:"signature,omitempty"`
	RedactedContent         *RedactedContentUnion `json:"redactedContent,omitempty"`
	*AnthropicContentFields `json:",inline,omitempty"`
}

// ChatCompletionAssistantMessageParam Messages sent by the model in response to user messages.
type ChatCompletionAssistantMessageParam struct {
	// The role of the messages author, in this case `assistant`.
	Role string `json:"role"`
	// Data about a previous audio response from the model.
	// [Learn more](https://platform.openai.com/docs/guides/audio).
	Audio ChatCompletionAssistantMessageParamAudio `json:"audio,omitzero"`
	// The contents of the assistant message. Required unless `tool_calls` or
	// `function_call` is specified.
	Content StringOrAssistantRoleContentUnion `json:"content"`
	// An optional name for the participant. Provides the model information to
	// differentiate between participants of the same role.
	Name string `json:"name,omitempty"`
	// The refusal message by the assistant.
	Refusal string `json:"refusal,omitempty"`
	// The tool calls generated by the model, such as function calls.
	ToolCalls []ChatCompletionMessageToolCallParam `json:"tool_calls,omitempty"`
}

// ChatCompletionMessageToolCallType The type of the tool. Currently, only `function` is supported.
type ChatCompletionMessageToolCallType string

const (
	ChatCompletionMessageToolCallTypeFunction ChatCompletionMessageToolCallType = "function"
)

// ChatCompletionMessageToolCallFunctionParam The function that the model called.
type ChatCompletionMessageToolCallFunctionParam struct {
	// The arguments to call the function with, as generated by the model in JSON
	// format. Note that the model does not always generate valid JSON, and may
	// hallucinate parameters not defined by your function schema. Validate the
	// arguments in your code before calling your function.
	Arguments string `json:"arguments"`
	// The name of the function to call.
	Name string `json:"name"`
}

type ChatCompletionMessageToolCallParam struct {
	// The ID of the tool call.
	ID *string `json:"id"`
	// The function that the model called.
	Function ChatCompletionMessageToolCallFunctionParam `json:"function"`
	// The type of the tool. Currently, only `function` is supported.
	Type                    ChatCompletionMessageToolCallType `json:"type,omitempty"`
	*AnthropicContentFields `json:",inline,omitempty"`
}

// extractMessageRole extracts role from OpenAI message union types.
func (c ChatCompletionMessageParamUnion) ExtractMessgaeRole() string {
	switch {
	case c.OfDeveloper != nil:
		return c.OfDeveloper.Role
	case c.OfSystem != nil:
		return c.OfSystem.Role
	case c.OfAssistant != nil:
		return c.OfAssistant.Role
	case c.OfTool != nil:
		return c.OfTool.Role
	case c.OfUser != nil:
		return c.OfUser.Role
	// Add other cases here for any other message types in the union.
	default:
		return "[unknown message type]"
	}
}

type ChatCompletionResponseFormatType string

// Constants for the different response formats.
const (
	ChatCompletionResponseFormatTypeText       ChatCompletionResponseFormatType = "text"
	ChatCompletionResponseFormatTypeJSONSchema ChatCompletionResponseFormatType = "json_schema"
	ChatCompletionResponseFormatTypeJSONObject ChatCompletionResponseFormatType = "json_object"
)

// Only one field can be non-empty.
type ChatCompletionResponseFormatUnion struct {
	OfText       *ChatCompletionResponseFormatTextParam       `json:",omitempty,inline"`
	OfJSONSchema *ChatCompletionResponseFormatJSONSchema      `json:",omitempty,inline"`
	OfJSONObject *ChatCompletionResponseFormatJSONObjectParam `json:",omitempty,inline"`
}

type ChatCompletionResponseFormatTextParam struct {
	// The type of response format being defined. Always `text`.
	Type ChatCompletionResponseFormatType `json:"type"`
}

// JSON Schema response format. Used to generate structured JSON responses. Learn
// more about
// [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).
// The properties JSONSchema, Type are required.
type ChatCompletionResponseFormatJSONSchema struct {
	// Structured Outputs configuration options, including a JSON Schema.
	JSONSchema ChatCompletionResponseFormatJSONSchemaJSONSchema `json:"json_schema,omitzero"`
	// The type of response format being defined. Always `json_schema`.
	//
	// This field can be elided, and will marshal its zero value as "json_schema".
	Type ChatCompletionResponseFormatType `json:"type"`
}

// ChatCompletionResponseFormatJSONSchema Structured Outputs configuration options, including a JSON Schema.
type ChatCompletionResponseFormatJSONSchemaJSONSchema struct {
	// The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores
	// and dashes, with a maximum length of 64.
	Name string `json:"name"`
	// A description of what the response format is for, used by the model to determine
	// how to respond in the format.
	Description string `json:"description,omitempty"`
	// The schema for the response format, described as a JSON Schema object. Learn how
	// to build JSON schemas [here](https://json-schema.org/).
	Schema json.RawMessage `json:"schema"`
	// Whether to enable strict schema adherence when generating the output. If set to
	// true, the model will always follow the exact schema defined in the `schema`
	// field. Only a subset of JSON Schema is supported when `strict` is `true`. To
	// learn more, read the
	// [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).
	Strict bool `json:"strict,omitempty"`
}

// JSON object response format. An older method of generating JSON responses. Using
// `json_schema` is recommended for models that support it. Note that the model
// will not generate JSON without a system or user message instructing it to do so.
type ChatCompletionResponseFormatJSONObjectParam struct {
	// The type of response format being defined. Always `json_object`.
	Type ChatCompletionResponseFormatType `json:"type"`
}

func (c ChatCompletionResponseFormatUnion) MarshalJSON() ([]byte, error) {
	if c.OfText != nil {
		return json.Marshal(c.OfText)
	}
	if c.OfJSONSchema != nil {
		return json.Marshal(c.OfJSONSchema)
	}
	if c.OfJSONObject != nil {
		return json.Marshal(c.OfJSONObject)
	}
	return nil, errors.New("no content to marshal")
}

// UnmarshalJSON implements the json.Unmarshaler interface for ChatCompletionResponseFormatUnion.
func (c *ChatCompletionResponseFormatUnion) UnmarshalJSON(data []byte) error {
	typeResult := gjson.GetBytes(data, "type")
	if !typeResult.Exists() {
		return errors.New("response format does not have type")
	}

	// Based on the 'type' field, unmarshal into the correct struct.
	responseFormatType := ChatCompletionResponseFormatType(typeResult.String())

	switch responseFormatType {
	case ChatCompletionResponseFormatTypeText:
		var textParam ChatCompletionResponseFormatTextParam
		if err := json.Unmarshal(data, &textParam); err != nil {
			return err
		}
		c.OfText = &textParam
	case ChatCompletionResponseFormatTypeJSONSchema:
		var jsonSchemaParam ChatCompletionResponseFormatJSONSchema
		if err := json.Unmarshal(data, &jsonSchemaParam); err != nil {
			return err
		}
		c.OfJSONSchema = &jsonSchemaParam
	case ChatCompletionResponseFormatTypeJSONObject:
		var jsonObjectParam ChatCompletionResponseFormatJSONObjectParam
		if err := json.Unmarshal(data, &jsonObjectParam); err != nil {
			return err
		}
		c.OfJSONObject = &jsonObjectParam
	default:
		// If the type is unknown, return an error.
		return errors.New("unsupported ChatCompletionResponseFormatType")
	}

	return nil
}

// ChatCompletionModality represents the output types that the model can generate.
type ChatCompletionModality string

const (
	// ChatCompletionModalityText represents text output.
	ChatCompletionModalityText ChatCompletionModality = "text"
	// ChatCompletionModalityAudio represents audio output.
	ChatCompletionModalityAudio ChatCompletionModality = "audio"
)

// ChatCompletionAudioVoice represents available voices for audio output.
type ChatCompletionAudioVoice string

const (
	// ChatCompletionAudioVoiceAlloy represents the alloy voice.
	ChatCompletionAudioVoiceAlloy ChatCompletionAudioVoice = "alloy"
	// ChatCompletionAudioVoiceAsh represents the ash voice.
	ChatCompletionAudioVoiceAsh ChatCompletionAudioVoice = "ash"
	// ChatCompletionAudioVoiceBallad represents the ballad voice.
	ChatCompletionAudioVoiceBallad ChatCompletionAudioVoice = "ballad"
	// ChatCompletionAudioVoiceCoral represents the coral voice.
	ChatCompletionAudioVoiceCoral ChatCompletionAudioVoice = "coral"
	// ChatCompletionAudioVoiceEcho represents the echo voice.
	ChatCompletionAudioVoiceEcho ChatCompletionAudioVoice = "echo"
	// ChatCompletionAudioVoiceFable represents the fable voice.
	ChatCompletionAudioVoiceFable ChatCompletionAudioVoice = "fable"
	// ChatCompletionAudioVoiceNova represents the nova voice.
	ChatCompletionAudioVoiceNova ChatCompletionAudioVoice = "nova"
	// ChatCompletionAudioVoiceOnyx represents the onyx voice.
	ChatCompletionAudioVoiceOnyx ChatCompletionAudioVoice = "onyx"
	// ChatCompletionAudioVoiceSage represents the sage voice.
	ChatCompletionAudioVoiceSage ChatCompletionAudioVoice = "sage"
	// ChatCompletionAudioVoiceShimmer represents the shimmer voice.
	ChatCompletionAudioVoiceShimmer ChatCompletionAudioVoice = "shimmer"
)

// ChatCompletionAudioFormat represents the output audio format.
type ChatCompletionAudioFormat string

const (
	// ChatCompletionAudioFormatWav represents WAV audio format.
	ChatCompletionAudioFormatWav ChatCompletionAudioFormat = "wav"
	// ChatCompletionAudioFormatAAC represents AAC audio format.
	ChatCompletionAudioFormatAAC ChatCompletionAudioFormat = "aac"
	// ChatCompletionAudioFormatMP3 represents MP3 audio format.
	ChatCompletionAudioFormatMP3 ChatCompletionAudioFormat = "mp3"
	// ChatCompletionAudioFormatFlac represents FLAC audio format.
	ChatCompletionAudioFormatFlac ChatCompletionAudioFormat = "flac"
	// ChatCompletionAudioFormatOpus represents Opus audio format.
	ChatCompletionAudioFormatOpus ChatCompletionAudioFormat = "opus"
	// ChatCompletionAudioFormatPCM16 represents PCM16 audio format.
	ChatCompletionAudioFormatPCM16 ChatCompletionAudioFormat = "pcm16"
)

// ChatCompletionAudioParam represents parameters for audio output. Required when audio output is requested with modalities: ["audio"].
type ChatCompletionAudioParam struct {
	// Voice specifies the voice the model uses to respond. Supported voices are alloy, ash, ballad, coral, echo, fable, nova, onyx, sage, and shimmer.
	Voice ChatCompletionAudioVoice `json:"voice"`
	// Format specifies the output audio format. Must be one of wav, mp3, flac, opus, or pcm16.
	Format ChatCompletionAudioFormat `json:"format"`
}

// PredictionContentType represents the type of predicted content.
type PredictionContentType string

const (
	// PredictionContentTypeContent represents static content prediction.
	PredictionContentTypeContent PredictionContentType = "content"
)

// PredictionContent represents static predicted output content, such as the content
// of a text file that is being regenerated.
// Docs: https://platform.openai.com/docs/guides/predicted-outputs
type PredictionContent struct {
	// Type: The type of the predicted content you want to provide.
	// This type is currently always "content".
	Type PredictionContentType `json:"type"`

	// Content: The content that should be matched when generating a model response.
	// If generated tokens would match this content, the entire model response
	// can be returned much more quickly.
	Content ContentUnion `json:"content"`
}

// WebSearchContextSize represents the context size for web search.
type WebSearchContextSize string

const (
	// WebSearchContextSizeLow provides minimal context from search results.
	WebSearchContextSizeLow WebSearchContextSize = "low"
	// WebSearchContextSizeMedium provides moderate context from search results.
	WebSearchContextSizeMedium WebSearchContextSize = "medium"
	// WebSearchContextSizeHigh provides maximum context from search results.
	WebSearchContextSizeHigh WebSearchContextSize = "high"
)

// WebSearchOptions configures the web search tool behavior.
type WebSearchOptions struct {
	// UserLocation provides approximate location parameters for the search.
	UserLocation *WebSearchUserLocation `json:"user_location,omitempty"` //nolint:tagliatelle //follow openai api
	// SearchContextSize controls how much context to include from search results.
	SearchContextSize WebSearchContextSize `json:"search_context_size,omitempty"` //nolint:tagliatelle //follow openai api
}

// WebSearchUserLocation represents approximate location for web search.
type WebSearchUserLocation struct {
	// Type is the type of location approximation. Always "approximate".
	Type string `json:"type"`
	// Approximate contains the approximate location details.
	Approximate WebSearchLocation `json:"approximate"`
}

// WebSearchLocation contains location details for web search.
type WebSearchLocation struct {
	// City is the approximate city name.
	City string `json:"city,omitempty"`
	// Region is the approximate region or state.
	Region string `json:"region,omitempty"`
	// Country is the approximate country.
	Country string `json:"country,omitempty"`
}

// ThinkingConfig contains thinking config for reasoning models
type ThinkingUnion struct {
	OfEnabled  *ThinkingEnabled  `json:",omitzero,inline"`
	OfDisabled *ThinkingDisabled `json:",omitzero,inline"`
}

type ThinkingEnabled struct {
	// Determines how many tokens the model can use for its internal reasoning process.
	// Larger budgets can enable more thorough analysis for complex problems, improving
	// response quality.
	BudgetTokens int64 `json:"budget_tokens"`
	// This field can be elided, and will marshal its zero value as "enabled".
	Type string `json:"type"`

	// Optional. Indicates the thinking budget in tokens.
	IncludeThoughts bool `json:"includeThoughts,omitempty"`
}

type ThinkingDisabled struct {
	Type string `json:"type,"`
}

// MarshalJSON implements the json.Marshaler interface for ThinkingUnion.
func (t *ThinkingUnion) MarshalJSON() ([]byte, error) {
	if t.OfEnabled != nil {
		return json.Marshal(t.OfEnabled)
	}
	if t.OfDisabled != nil {
		return json.Marshal(t.OfDisabled)
	}
	// If both are nil, return an empty object or an error, depending on your desired behavior.
	return []byte(`{}`), nil
}

// UnmarshalJSON implements the json.Unmarshaler interface for ThinkingUnion.
func (t *ThinkingUnion) UnmarshalJSON(data []byte) error {
	// Use a temporary struct to determine the type
	typeResult := gjson.GetBytes(data, "type")
	if !typeResult.Exists() {
		return errors.New("thinking config does not have a type")
	}

	// Based on the 'type' field, unmarshal into the correct struct.
	typeVal := typeResult.String()

	switch typeVal {
	case "enabled":
		var enabled ThinkingEnabled
		if err := json.Unmarshal(data, &enabled); err != nil {
			return err
		}
		t.OfEnabled = &enabled
	case "disabled":
		var disabled ThinkingDisabled
		if err := json.Unmarshal(data, &disabled); err != nil {
			return err
		}
		t.OfDisabled = &disabled
	default:
		return fmt.Errorf("invalid thinking union type: %s", typeVal)
	}

	return nil
}

type ChatCompletionRequest struct {
	// Messages: A list of messages comprising the conversation so far.
	// Depending on the model you use, different message types (modalities) are supported,
	// like text, images, and audio.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages
	Messages []ChatCompletionMessageParamUnion `json:"messages"`
	// ^^ not omitempty because OpenAI requires either ('messages' and 'model')
	// or ('messages', 'model' and 'stream') arguments to be given.

	// Model: ID of the model to use
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-model
	Model string `json:"model"`

	// FrequencyPenalty: Number between -2.0 and 2.0
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-frequency_penalty
	FrequencyPenalty *float32 `json:"frequency_penalty,omitempty"` //nolint:tagliatelle //follow openai api

	// LogitBias Modify the likelihood of specified tokens appearing in the completion.
	// It must be a token id string (specified by their token ID in the tokenizer), not a word string.
	// incorrect: `"logit_bias":{"You": 6}`, correct: `"logit_bias":{"1639": 6}`
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-logit_bias
	LogitBias map[string]int `json:"logit_bias,omitempty"` //nolint:tagliatelle //follow openai api

	// LogProbs indicates whether to return log probabilities of the output tokens or not.
	// If true, returns the log probabilities of each output token returned in the content of message.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-logprobs
	LogProbs *bool `json:"logprobs,omitempty"`

	// TopLogProbs is an integer between 0 and 5 specifying the number of most likely tokens to return at each
	// token position, each with an associated log probability.
	// logprobs must be set to true if this parameter is used.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-top_logprobs
	TopLogProbs *int `json:"top_logprobs,omitempty"` //nolint:tagliatelle //follow openai api

	// MaxTokens The maximum number of tokens that can be generated in the chat completion.
	// This value can be used to control costs for text generated via API.
	// This value is now deprecated in favor of max_completion_tokens, and is not compatible with o1 series models.
	// refs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-max_tokens
	MaxTokens *int64 `json:"max_tokens,omitempty"` //nolint:tagliatelle //follow openai api

	// MaxCompletionTokens is an Optional integer
	// An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens.
	// refs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-max_completion_tokens
	MaxCompletionTokens *int64 `json:"max_completion_tokens,omitempty"` //nolint:tagliatelle //follow openai api

	// N: LLM Gateway does not support multiple completions.
	// The only accepted value is 1.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-n
	N *int `json:"n,omitempty"`

	// PresencePenalty Positive values penalize new tokens based on whether they appear in the text so far,
	// increasing the model's likelihood to talk about new topics.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-presence_penalty
	PresencePenalty *float32 `json:"presence_penalty,omitempty"` //nolint:tagliatelle //follow openai api

	// An object specifying the format that the model must output.
	//
	// Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured
	// Outputs which ensures the model will match your supplied JSON schema. Learn more
	// in the
	// [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).
	//
	// Setting to `{ "type": "json_object" }` enables the older JSON mode, which
	// ensures the message the model generates is valid JSON. Using `json_schema` is
	// preferred for models that support it.
	ResponseFormat *ChatCompletionResponseFormatUnion `json:"response_format,omitempty"` //nolint:tagliatelle //follow openai api

	// Seed: This feature is in Beta. If specified, our system will make a best effort to
	// sample deterministically, such that repeated requests with the same `seed` and
	// parameters should return the same result. Determinism is not guaranteed, and you
	// should refer to the `system_fingerprint` response parameter to monitor changes
	// in the backend.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-seed
	Seed *int `json:"seed,omitempty"`

	// Constrains effort on reasoning for
	// [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently
	// supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning
	// effort can result in faster responses and fewer tokens used on reasoning in a
	// response.
	//
	// Any of "minimal", "low", "medium", "high".
	ReasoningEffort openai.ReasoningEffort `json:"reasoning_effort,omitzero"`

	// ServiceTier:string or null
	// Specifies the processing type used for serving the request.
	//
	// For OpenAI requests:
	//   Defaults to auto for openai
	//   If set to 'auto', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use 'default'.
	//   If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.
	//   If set to 'flex' or 'priority', then the request will be processed with the corresponding service tier.
	//
	// For AWS Bedrock requests:
	//   If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.
	//   If set to 'reserved', 'flex', or 'priority', then the request will be processed with the corresponding service tier.
	//   Models that do not support the selected service tier will return a 400 error.
	//
	// When the service_tier parameter is set, the response body will include the service_tier value based on the processing mode actually used to serve the request.
	// This response value may be different from the value set in the parameter.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-service_tier
	// Any of "auto", "default", "flex", "scale", "priority" for OpenAI.
	// Any of "reserved", "default", "flex", "priority" for AWS Bedrock.
	ServiceTier string `json:"service_tier,omitzero"`

	// Constrains the verbosity of the model's response. Lower values will result in
	// more concise responses, while higher values will result in more verbose
	// responses. Currently supported values are `low`, `medium`, and `high`.
	//
	// Any of "low", "medium", "high".
	Verbosity openai.ChatCompletionNewParamsVerbosity `json:"verbosity,omitzero"`

	// Stop string / array / null Defaults to null
	// Up to 4 sequences where the API will stop generating further tokens.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-stop
	Stop openai.ChatCompletionNewParamsStopUnion `json:"stop,omitzero"`

	// Stream: If set, partial message deltas will be sent, like in ChatGPT.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-stream
	Stream bool `json:"stream,omitempty"`

	// StreamOptions for streaming response. Only set this when you set stream: true.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-stream_options
	StreamOptions *StreamOptions `json:"stream_options,omitempty"` //nolint:tagliatelle //follow openai api

	// Temperature What sampling temperature to use, between 0 and 2.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-temperature
	Temperature *float64 `json:"temperature,omitempty"`

	// TopP An alternative to sampling with temperature, called nucleus sampling,
	// where the model considers the results of the tokens with top_p probability mass.
	// So 0.1 means only the tokens comprising the top 10% probability mass are considered.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-top_p
	TopP *float64 `json:"top_p,omitempty"` //nolint:tagliatelle //follow openai api

	// Tools provide a list of tool definitions to be used by the LLM.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format
	Tools []Tool `json:"tools,omitempty"`

	// ToolChoice controls which (if any) tool is called by the model.
	// `none` means the model will not call any tool and instead generates a message.
	// `auto` means the model can pick between generating a message or calling one or more tools.
	// `required` means the model must call one or more tools.
	// Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
	// `none` is the default when no tools are present. `auto` is the default if tools are present.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice
	ToolChoice *ChatCompletionToolChoiceUnion `json:"tool_choice,omitempty"` //nolint:tagliatelle //follow openai api

	// ParallelToolCalls enables multiple tools to be returned by the model.
	// Docs: https://platform.openai.com/docs/guides/function-calling/parallel-function-calling
	ParallelToolCalls *bool `json:"parallel_tool_calls,omitempty"` //nolint:tagliatelle //follow openai api

	// User: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
	// Docs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-user
	User string `json:"user,omitempty"`

	// Modalities specifies the output types that you would like the model to generate. Most models are capable of generating text, which is the default. The gpt-4o-audio-preview model can also generate audio.
	Modalities []ChatCompletionModality `json:"modalities,omitempty"`

	// Audio specifies parameters for audio output. Required when audio output is requested with modalities: ["audio"].
	Audio *ChatCompletionAudioParam `json:"audio,omitempty"`

	// PredictionContent provides configuration for a Predicted Output, which can greatly improve response times when large parts of the model response are known ahead of time.
	PredictionContent *PredictionContent `json:"prediction,omitempty"`

	// WebSearchOptions configures web search tool for models that support it.
	// This tool searches the web for relevant results to use in a response.
	// Docs: https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat
	WebSearchOptions *WebSearchOptions `json:"web_search_options,omitempty"` //nolint:tagliatelle //follow openai api

	// GCPVertexAIVendorFields configures the GCP VertexAI specific fields during schema translation.
	*GCPVertexAIVendorFields `json:",inline,omitempty"`

	// GuidedChoice: The output will be exactly one of the choices.
	GuidedChoice []string `json:"guided_choice,omitzero"`

	// GuidedRegex: The output will follow the regex pattern.
	GuidedRegex string `json:"guided_regex,omitzero"`

	// GuidedJSON: The output will follow the JSON schema.
	GuidedJSON json.RawMessage `json:"guided_json,omitzero"`

	// Thinking: The thinking config for reasoning models
	Thinking *ThinkingUnion `json:"thinking,omitzero"`
}

type StreamOptions struct {
	// If set, an additional chunk will be streamed before the data: [DONE] message.
	// The usage field on this chunk shows the token usage statistics for the entire request,
	// and the choices field will always be an empty array.
	// All other chunks will also include a usage field, but with a null value.
	IncludeUsage bool `json:"include_usage,omitempty"` //nolint:tagliatelle //follow openai api
}

type ToolType string

const (
	ToolTypeFunction            ToolType = "function"
	ToolTypeImageGeneration     ToolType = "image_generation"
	ToolTypeEnterpriseWebSearch ToolType = "enterprise_search"
	ToolTypeGoogleSearch        ToolType = "google_search"
)

// GCPGoogleSearchConfig contains GCP-specific configuration for Google Search grounding.
// https://pkg.go.dev/google.golang.org/genai#GoogleSearch
type GCPGoogleSearchConfig struct {
	ExcludeDomains     []string            `json:"exclude_domains,omitempty"`     //nolint:tagliatelle
	BlockingConfidence string              `json:"blocking_confidence,omitempty"` //nolint:tagliatelle
	TimeRangeFilter    *GCPTimeRangeFilter `json:"time_range_filter,omitempty"`   //nolint:tagliatelle
}

// GCPTimeRangeFilter filters search results to a specific time range.
type GCPTimeRangeFilter struct {
	StartTime string `json:"start_time,omitempty"` //nolint:tagliatelle
	EndTime   string `json:"end_time,omitempty"`   //nolint:tagliatelle
}

type Tool struct {
	Type         ToolType               `json:"type"`
	Function     *FunctionDefinition    `json:"function,omitempty"`
	GoogleSearch *GCPGoogleSearchConfig `json:"google_search,omitempty"` //nolint:tagliatelle
}

// ToolChoiceType represents the type of tool choice.
type ToolChoiceType string

const (
	// ToolChoiceTypeNone means the model will not call any tool and instead generates a message.
	ToolChoiceTypeNone ToolChoiceType = "none"
	// ToolChoiceTypeAuto means the model can pick between generating a message or calling one or more tools.
	ToolChoiceTypeAuto ToolChoiceType = "auto"
	// ToolChoiceTypeRequired means the model must call one or more tools.
	ToolChoiceTypeRequired ToolChoiceType = "required"
	// ToolChoiceTypeFunction is used when specifying a particular function.
	ToolChoiceTypeFunction ToolChoiceType = "function"
)

// ChatCompletionToolChoiceUnion represents the tool choice for chat completions.
// It can be either a string (none, auto, required) or a ChatCompletionNamedToolChoice object.
type ChatCompletionToolChoiceUnion struct {
	Value any
}

func (c ChatCompletionToolChoiceUnion) MarshalJSON() ([]byte, error) {
	return json.Marshal(c.Value)
}

func (c *ChatCompletionToolChoiceUnion) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as string.
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		c.Value = str
		return nil
	}

	// Try to unmarshal as ChatCompletionNamedToolChoice.
	var namedChoice ChatCompletionNamedToolChoice
	if err := json.Unmarshal(data, &namedChoice); err == nil {
		c.Value = namedChoice
		return nil
	}

	return errors.New("tool choice must be either string or ChatCompletionNamedToolChoice")
}

// ChatCompletionNamedToolChoice specifies a tool the model should use. Use to force the model to call a specific function.
type ChatCompletionNamedToolChoice struct {
	// Type is the type of the tool. Currently, only `function` is supported.
	Type ToolType `json:"type"`
	// Function specifies the function to call.
	Function ChatCompletionNamedToolChoiceFunction `json:"function"`
}

// ChatCompletionNamedToolChoiceFunction represents the function to call.
type ChatCompletionNamedToolChoiceFunction struct {
	// Name is the name of the function to call.
	Name string `json:"name"`
}

// FunctionDefinition represents a function that can be called.
type FunctionDefinition struct {
	// Name is the name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
	Name string `json:"name"`
	// Description is a description of what the function does, used by the model to choose when and how to call the function.
	Description string `json:"description,omitempty"`
	Strict      bool   `json:"strict,omitempty"`
	// Parameters is an object describing the function.
	// You can pass json.RawMessage to describe the schema,
	// or you can pass in a struct which serializes to the proper JSON schema.
	// The jsonschema package is provided for convenience, but you should
	// consider another specialized library if you require more complex schemas.
	Parameters              any `json:"parameters"`
	*AnthropicContentFields `json:",inline,omitempty"`
}

// Deprecated: use FunctionDefinition instead.
type FunctionDefine = FunctionDefinition

type TopLogProbs struct {
	Token   string  `json:"token"`
	LogProb float64 `json:"logprob"`
	Bytes   []byte  `json:"bytes,omitempty"`
}

// LogProb represents the probability information for a token.
type LogProb struct {
	Token   string  `json:"token"`
	LogProb float64 `json:"logprob"`
	Bytes   []byte  `json:"bytes,omitempty"` // Omitting the field if it is null.
	// TopLogProbs is a list of the most likely tokens and their log probability, at this token position.
	// In rare cases, there may be fewer than the number of requested top_logprobs returned.
	TopLogProbs []TopLogProbs `json:"top_logprobs"` //nolint:tagliatelle //follow openai api
}

// LogProbs is the top-level structure containing the log probability information.
type LogProbs struct {
	// Content is a list of message content tokens with log probability information.
	Content []LogProb `json:"content"`
}

// ChatCompletionResponse represents a response from /v1/chat/completions.
// https://platform.openai.com/docs/api-reference/chat/object
type ChatCompletionResponse struct {
	// ID is a unique identifier for the chat completion.
	ID string `json:"id,omitempty"`
	// Choices are described in the OpenAI API documentation:
	// https://platform.openai.com/docs/api-reference/chat/object#chat/object-choices
	Choices []ChatCompletionResponseChoice `json:"choices,omitempty"`

	// Created is the Unix timestamp (in seconds) of when the chat completion was created.
	Created JSONUNIXTime `json:"created,omitzero"`

	// Model is the model used for the chat completion.
	Model string `json:"model,omitempty"`

	// ServiceTier is the service tier used for the completion.
	ServiceTier string `json:"service_tier,omitempty"`

	// SystemFingerprint represents the backend configuration that the model runs with.
	SystemFingerprint string `json:"system_fingerprint,omitempty"`

	// Object is always "chat.completion" for completions.
	// https://platform.openai.com/docs/api-reference/chat/object#chat/object-object
	Object string `json:"object,omitempty"`

	// Usage is described in the OpenAI API documentation:
	// https://platform.openai.com/docs/api-reference/chat/object#chat/object-usage
	Usage Usage `json:"usage,omitzero"`

	// Obfuscation are random characters that normalize payload sizes as a
	// mitigation to certain side-channel attacks.
	// https://platform.openai.com/docs/api-reference/responses/get#responses_get-include_obfuscation
	Obfuscation string `json:"obfuscation,omitempty"`
}

// ChatCompletionChoicesFinishReason The reason the model stopped generating tokens. This will be `stop` if the model
// hit a natural stop point or a provided stop sequence, `length` if the maximum
// number of tokens specified in the request was reached, `content_filter` if
// content was omitted due to a flag from our content filters, `tool_calls` if the
// model called a tool, or `function_call` (deprecated) if the model called a
// function.
type ChatCompletionChoicesFinishReason string

const (
	ChatCompletionChoicesFinishReasonStop          ChatCompletionChoicesFinishReason = "stop"
	ChatCompletionChoicesFinishReasonLength        ChatCompletionChoicesFinishReason = "length"
	ChatCompletionChoicesFinishReasonToolCalls     ChatCompletionChoicesFinishReason = "tool_calls"
	ChatCompletionChoicesFinishReasonContentFilter ChatCompletionChoicesFinishReason = "content_filter"
)

type ChatCompletionTokenLogprobTopLogprob struct {
	// The token.
	Token string `json:"token"`
	// A list of integers representing the UTF-8 bytes representation of the token.
	// Useful in instances where characters are represented by multiple tokens and
	// their byte representations must be combined to generate the correct text
	// representation. Can be `null` if there is no bytes representation for the token.
	Bytes []int64 `json:"bytes,omitempty"`
	// The log probability of this token, if it is within the top 20 most likely
	// tokens. Otherwise, the value `-9999.0` is used to signify that the token is very
	// unlikely.
	Logprob float64 `json:"logprob"`
}

type ChatCompletionTokenLogprob struct {
	// The token.
	Token string `json:"token"`
	// A list of integers representing the UTF-8 bytes representation of the token.
	// Useful in instances where characters are represented by multiple tokens and
	// their byte representations must be combined to generate the correct text
	// representation. Can be `null` if there is no bytes representation for the token.
	Bytes []int64 `json:"bytes,omitempty"`
	// The log probability of this token, if it is within the top 20 most likely
	// tokens. Otherwise, the value `-9999.0` is used to signify that the token is very
	// unlikely.
	Logprob float64 `json:"logprob"`
	// List of the most likely tokens and their log probability, at this token
	// position. In rare cases, there may be fewer than the number of requested
	// `top_logprobs` returned.
	TopLogprobs []ChatCompletionTokenLogprobTopLogprob `json:"top_logprobs"`
}

// ChatCompletionChoicesLogprobs Log probability information for the choice.
type ChatCompletionChoicesLogprobs struct {
	// A list of message content tokens with log probability information.
	Content []ChatCompletionTokenLogprob `json:"content,omitempty"`
	// A list of message refusal tokens with log probability information.
	Refusal []ChatCompletionTokenLogprob `json:"refusal,omitempty"`
}

// ChatCompletionResponseChoice is described in the OpenAI API documentation:
// https://platform.openai.com/docs/api-reference/chat/object#chat/object-choices
type ChatCompletionResponseChoice struct {
	// The reason the model stopped generating tokens. This will be `stop` if the model
	// hit a natural stop point or a provided stop sequence, `length` if the maximum
	// number of tokens specified in the request was reached, `content_filter` if
	// content was omitted due to a flag from our content filters, `tool_calls` if the
	// model called a tool, or `function_call` (deprecated) if the model called a
	// function.
	FinishReason ChatCompletionChoicesFinishReason `json:"finish_reason"`
	// The index of the choice in the list of choices.
	Index int64 `json:"index"`
	// Log probability information for the choice.
	Logprobs ChatCompletionChoicesLogprobs `json:"logprobs,omitzero"`
	// Message is described in the OpenAI API documentation:
	// https://platform.openai.com/docs/api-reference/chat/object#chat/object-choices
	Message ChatCompletionResponseChoiceMessage `json:"message,omitempty"`
}

// ChatCompletionResponseChoiceMessage is described in the OpenAI API documentation:
// https://platform.openai.com/docs/api-reference/chat/object#chat/object-choices
type ChatCompletionResponseChoiceMessage struct {
	// The contents of the message.
	Content *string `json:"content,omitempty"`

	// The role of the author of this message.
	Role string `json:"role,omitempty"`

	// The tool calls generated by the model, such as function calls.
	ToolCalls []ChatCompletionMessageToolCallParam `json:"tool_calls,omitempty"`

	// Annotations for the message, when applicable, as when using the web search tool.
	Annotations *[]Annotation `json:"annotations,omitempty"`

	// Audio is the audio response generated by the model, if applicable.
	Audio *ChatCompletionResponseChoiceMessageAudio `json:"audio,omitempty"`

	// ReasoningContent is used to hold any non-standard fields from the backend which supports reasoning,
	// like "reasoningContent" from AWS Bedrock.
	ReasoningContent *ReasoningContentUnion `json:"reasoning_content,omitempty"`

	// GCPVertexAI specific fields.

	// SafetyRatings contains safety ratings copied from the GCP Vertex AI response as-is.
	// List of ratings for the safety of a response candidate. There is at most one rating per category.
	// https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1/GenerateContentResponse#SafetyRating
	SafetyRatings []*genai.SafetyRating `json:"safety_ratings,omitempty"`

	// GroundingMetadata specifies sources used to ground generated content.
	// https://docs.cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/GroundingMetadata
	GroundingMetadata *genai.GroundingMetadata `json:"grounding_metadata,omitempty"`
}

// URLCitation contains citation information for web search results.
// Docs: https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat
type URLCitation struct {
	// EndIndex is the index of the last character of the URL citation in the message.
	EndIndex int `json:"end_index"`
	// StartIndex is the index of the first character of the URL citation in the message.
	StartIndex int `json:"start_index"`
	// URL is the URL of the web resource.
	URL string `json:"url"`
	// Title is the title of the web resource.
	Title string `json:"title"`
}

// Annotation represents a URL citation when using web search.
// The annotation appears in message content when the model cites web sources.
// Docs: https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat
type Annotation struct {
	// Type is the type of the annotation. Always "url_citation" for web search.
	Type string `json:"type"`
	// URLCitation contains the citation details when type is "url_citation".
	URLCitation *URLCitation `json:"url_citation,omitempty"` //nolint:tagliatelle //follow openai api
}

// ChatCompletionResponseChoiceMessageAudio is described in the OpenAI API documentation.
type ChatCompletionResponseChoiceMessageAudio struct {
	Data       string `json:"data"`
	ExpiresAt  int64  `json:"expires_at"`
	ID         string `json:"id"`
	Transcript string `json:"transcript"`
}

// CompletionTokensDetails breakdown of tokens used in a completion.
type CompletionTokensDetails struct {
	// Text input tokens present in the prompt.
	TextTokens int `json:"text_tokens,omitzero"`
	// ^^  TODO: no idea why this is undocumented on the official OpenAI API docs.

	// When using Predicted Outputs, the number of tokens in the prediction that appeared in the completion.
	AcceptedPredictionTokens int `json:"accepted_prediction_tokens,omitzero"`
	// Audio input tokens generated by the model.
	AudioTokens int `json:"audio_tokens,omitzero"`
	// Tokens generated by the model for reasoning.
	ReasoningTokens int `json:"reasoning_tokens,omitzero"`
	// When using Predicted Outputs, the number of tokens in the prediction that did not appear in the completion.
	// However, like reasoning tokens, these tokens are still counted in the total completion tokens
	// for purposes of billing, output, and context window limits.
	RejectedPredictionTokens int `json:"rejected_prediction_tokens,omitzero"`
}

// PromptTokensDetails breakdown of tokens used in the prompt.
type PromptTokensDetails struct {
	// Text input tokens present in the prompt.
	TextTokens int `json:"text_tokens,omitzero"`
	// ^^  TODO: no idea why this is undocumented on the official OpenAI API docs.

	// Audio input tokens present in the prompt.
	AudioTokens int `json:"audio_tokens,omitzero"`
	// Cached tokens present in the prompt.
	CachedTokens int `json:"cached_tokens,omitzero"`
	// Tokens written to the cache.
	CacheCreationTokens int `json:"cache_creation_input_tokens,omitzero"`
}

// ChatCompletionResponseChunk is described in the OpenAI API documentation:
// https://platform.openai.com/docs/api-reference/chat/streaming#chat-create-messages
type ChatCompletionResponseChunk struct {
	// ID is a unique identifier for the chat completion chunk.
	ID string `json:"id,omitempty"`
	// Choices are described in the OpenAI API documentation:
	// https://platform.openai.com/docs/api-reference/chat/streaming#chat/streaming-choices
	Choices []ChatCompletionResponseChunkChoice `json:"choices,omitempty"`

	// Created is the Unix timestamp (in seconds) of when the chat completion was created.
	Created JSONUNIXTime `json:"created,omitzero"`

	// Model is the model used for the chat completion.
	Model string `json:"model,omitempty"`

	// ServiceTier is the service tier used for the completion.
	ServiceTier string `json:"service_tier,omitempty"`

	// SystemFingerprint represents the backend configuration that the model runs with.
	SystemFingerprint string `json:"system_fingerprint,omitempty"`

	// Object is always "chat.completion.chunk" for completions.
	// https://platform.openai.com/docs/api-reference/chat/streaming#chat/streaming-object
	Object string `json:"object,omitempty"`

	// Usage is described in the OpenAI API documentation:
	// https://platform.openai.com/docs/api-reference/chat/streaming#chat/streaming-usage
	Usage *Usage `json:"usage,omitempty"`

	// Obfuscation are random characters that normalize payload sizes as a
	// mitigation to certain side-channel attacks.
	// https://platform.openai.com/docs/api-reference/responses/get#responses_get-include_obfuscation
	Obfuscation string `json:"obfuscation,omitempty"`
}

// String implements fmt.Stringer.
func (c *ChatCompletionResponseChunk) String() string {
	buf, _ := json.Marshal(c)
	return strings.ReplaceAll(string(buf), ",", ", ")
}

// ChatCompletionResponseChunkChoice is described in the OpenAI API documentation:
// https://platform.openai.com/docs/api-reference/chat/streaming#chat/streaming-choices
type ChatCompletionResponseChunkChoice struct {
	Index        int64                                   `json:"index"`
	Delta        *ChatCompletionResponseChunkChoiceDelta `json:"delta,omitzero"`
	Logprobs     *ChatCompletionChoicesLogprobs          `json:"logprobs,omitzero"`
	FinishReason ChatCompletionChoicesFinishReason       `json:"finish_reason,omitempty"`
}

type ChatCompletionChunkChoiceDeltaToolCall struct {
	Index int64 `json:"index"`
	// The ID of the tool call.
	ID *string `json:"id"`
	// The function that the model called.
	Function ChatCompletionMessageToolCallFunctionParam `json:"function"`
	// The type of the tool. Currently, only `function` is supported.
	Type ChatCompletionMessageToolCallType `json:"type,omitempty"`
}

// ChatCompletionResponseChunkChoiceDelta is described in the OpenAI API documentation:
// https://platform.openai.com/docs/api-reference/chat/streaming#chat/streaming-choices
type ChatCompletionResponseChunkChoiceDelta struct {
	Content          *string                                  `json:"content,omitempty"`
	Role             string                                   `json:"role,omitempty"`
	ToolCalls        []ChatCompletionChunkChoiceDeltaToolCall `json:"tool_calls,omitempty"`
	Annotations      *[]Annotation                            `json:"annotations,omitempty"`
	ReasoningContent *StreamReasoningContent                  `json:"reasoning_content,omitempty"`
}

// Error is described in the OpenAI API documentation
// https://platform.openai.com/docs/api-reference/realtime-server-events/error
type Error struct {
	// The unique ID of the server event.
	EventID *string `json:"event_id,omitempty"`
	// The event type, must be error.
	Type string `json:"type"`
	// Details of the error.
	Error ErrorType `json:"error"`
}

type ErrorType struct {
	// The type of error (e.g., "invalid_request_error", "server_error").
	Type string `json:"type"`
	// Error code, if any.
	Code *string `json:"code,omitempty"`
	// A human-readable error message.
	Message string `json:"message,omitempty"`
	// Parameter related to the error, if any.
	Param *string `json:"param,omitempty"`
	// The event_id of the client event that caused the error, if applicable.
	EventID *string `json:"event_id,omitempty"`
}

// ModelList is described in the OpenAI API documentation
// https://platform.openai.com/docs/api-reference/models/list
type ModelList struct {
	// Data is a list of models.
	Data []Model `json:"data"`
	// Object is the object type, which is always "list".
	Object string `json:"object"`
}

// Model is described in the OpenAI API documentation
// https://platform.openai.com/docs/api-reference/models/object
type Model struct {
	// ID is the model identifier, which can be referenced in the API endpoints.
	ID string `json:"id"`
	// Created is the Unix timestamp (in seconds) when the model was created.
	Created JSONUNIXTime `json:"created"`
	// Object is the object type, which is always "model".
	Object string `json:"object"`
	// OwnedBy is the organization that owns the model.
	OwnedBy string `json:"owned_by"`
}

// EmbeddingRequest represents a request structure for embeddings API.
type EmbeddingRequest struct {
	// Input: Input text to embed, encoded as a string or array of tokens.
	// To embed multiple inputs in a single request, pass an array of strings or array of token arrays.
	// The input must not exceed the max input tokens for the model (8192 tokens for text-embedding-ada-002),
	// cannot be an empty string, and any array must be 2048 dimensions or less.
	// Docs: https://platform.openai.com/docs/api-reference/embeddings/create#embeddings-create-input
	Input EmbeddingRequestInput `json:"input"`

	// Model: ID of the model to use.
	// Docs: https://platform.openai.com/docs/api-reference/embeddings/create#embeddings-create-model
	Model string `json:"model"`

	// EncodingFormat: The format to return the embeddings in. Can be either float or base64.
	// Docs: https://platform.openai.com/docs/api-reference/embeddings/create#embeddings-create-encoding_format
	EncodingFormat *string `json:"encoding_format,omitempty"` //nolint:tagliatelle //follow openai api

	// Dimensions: The number of dimensions the resulting output embeddings should have.
	// Only supported in text-embedding-3 and later models.
	// Docs: https://platform.openai.com/docs/api-reference/embeddings/create#embeddings-create-dimensions
	Dimensions *int `json:"dimensions,omitempty"`

	// User: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
	// Docs: https://platform.openai.com/docs/api-reference/embeddings/create#embeddings-create-user
	User *string `json:"user,omitempty"`

	// GCPVertexAIEmbeddingVendorFields configures the GCP VertexAI specific fields for embedding during schema translation.
	*GCPVertexAIEmbeddingVendorFields `json:",inline,omitempty"`
}

type EmbeddingTaskType string

const (
	EmbeddingTaskTypeRetrievalQuery     EmbeddingTaskType = "RETRIEVAL_QUERY"
	EmbeddingTaskTypeRetrievalDocument  EmbeddingTaskType = "RETRIEVAL_DOCUMENT"
	EmbeddingTaskTypeSemanticSimilarity EmbeddingTaskType = "SEMANTIC_SIMILARITY"
	EmbeddingTaskTypeClassification     EmbeddingTaskType = "CLASSIFICATION"
	EmbeddingTaskTypeClustering         EmbeddingTaskType = "CLUSTERING"
	EmbeddingTaskTypeQuestionAnswering  EmbeddingTaskType = "QUESTION_ANSWERING"
	EmbeddingTaskTypeFactVerification   EmbeddingTaskType = "FACT_VERIFICATION"
	EmbeddingTaskTypeCodeRetrievalQuery EmbeddingTaskType = "CODE_RETRIEVAL_QUERY"
)

// GCPVertexAIEmbeddingVendorFields contains GCP Vertex AI (Gemini) vendor-specific fields for embeddings.
type GCPVertexAIEmbeddingVendorFields struct {
	// When set to true, input text will be truncated. When set to false, an error is returned if the input text is longer than the maximum length supported by the model. Defaults to true.
	// https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api#parameter-list

	AutoTruncate bool `json:"auto_truncate,omitempty"`

	// This is global task_type set, which is convenient for users. If left blank, the default used is RETRIEVAL_QUERY.
	// For more information about task types, see https://docs.cloud.google.com/vertex-ai/generative-ai/docs/embeddings/task-types
	TaskType EmbeddingTaskType `json:"task_type,omitempty"`
}

// EmbeddingResponse represents a response from /v1/embeddings.
// https://platform.openai.com/docs/api-reference/embeddings/object
type EmbeddingResponse struct {
	// Object: The object type, which is always "list".
	// https://platform.openai.com/docs/api-reference/embeddings/object#embeddings/object-object
	Object string `json:"object"`

	// Data: The list of embeddings generated by the model.
	// https://platform.openai.com/docs/api-reference/embeddings/object#embeddings/object-data
	Data []Embedding `json:"data"`

	// Model: The name of the model used to generate the embedding.
	// https://platform.openai.com/docs/api-reference/embeddings/object#embeddings/object-model
	Model string `json:"model"`

	// Usage: The usage information for the request.
	// https://platform.openai.com/docs/api-reference/embeddings/object#embeddings/object-usage
	Usage EmbeddingUsage `json:"usage"`
}

// Embedding represents a single embedding vector.
// https://platform.openai.com/docs/api-reference/embeddings/object#embeddings/object-data
type Embedding struct {
	// Object: The object type, which is always "embedding".
	Object string `json:"object"`

	// Embedding: The embedding vector, which can be a list of floats or a string.
	// The length of vector depends on the model as listed in the embedding guide.
	Embedding EmbeddingUnion `json:"embedding"`

	// Index: The index of the embedding in the list of embeddings.
	Index int `json:"index"`

	// If the input text was truncated due to having a length longer than the allowed maximum input.
	// https://github.com/googleapis/go-genai/blob/cb486e101dc66794d52125dd22ff43ff4c0e76a6/types.go#L2807
	Truncated bool `json:"truncated,omitempty"`
}

// EmbeddingUnion is a union type that can handle both []float64 and string formats.
type EmbeddingUnion struct {
	Value any
}

// UnmarshalJSON implements json.Unmarshaler to handle both []float64 and string formats.
func (e *EmbeddingUnion) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as []float64 first.
	var floats []float64
	if err := json.Unmarshal(data, &floats); err == nil {
		e.Value = floats
		return nil
	}

	// Try to unmarshal as string.
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		e.Value = str
		return nil
	}

	return errors.New("embedding must be either []float64 or string")
}

// MarshalJSON implements json.Marshaler.
func (e EmbeddingUnion) MarshalJSON() ([]byte, error) {
	return json.Marshal(e.Value)
}

// RedactedContentUnion is a union type that can handle both []byte and string formats.
// AWS Bedrock uses []byte while GCP Anthropic uses string.
type RedactedContentUnion struct {
	Value any
}

// UnmarshalJSON implements json.Unmarshaler to handle both []byte and string formats.
func (r *RedactedContentUnion) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as []byte first (base64 encoded).
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		// Try to decode as base64 first (this would be []byte encoded as base64)
		if decoded, err := base64.StdEncoding.DecodeString(str); err == nil {
			r.Value = decoded
			return nil
		}
		// If not base64, treat as plain string
		r.Value = str
		return nil
	}

	return errors.New("redactedContent must be either []byte (base64 encoded) or string")
}

// MarshalJSON implements json.Marshaler.
func (r RedactedContentUnion) MarshalJSON() ([]byte, error) {
	switch v := r.Value.(type) {
	case []byte:
		// Encode []byte as base64 string
		return json.Marshal(base64.StdEncoding.EncodeToString(v))
	case string:
		return json.Marshal(v)
	default:
		return json.Marshal(r.Value)
	}
}

// EmbeddingUsage represents the usage information for an embeddings request.
// https://platform.openai.com/docs/api-reference/embeddings/object#embeddings/object-usage
type EmbeddingUsage struct {
	// PromptTokens: The number of tokens used by the prompt.
	PromptTokens int `json:"prompt_tokens"` //nolint:tagliatelle //follow openai api

	// TotalTokens: The total number of tokens used by the request.
	TotalTokens int `json:"total_tokens"` //nolint:tagliatelle //follow openai api
}

// JSONUNIXTime is a helper type to marshal/unmarshal time.Time UNIX timestamps.
type JSONUNIXTime time.Time

// MarshalJSON implements [json.Marshaler].
func (t JSONUNIXTime) MarshalJSON() ([]byte, error) {
	return []byte(strconv.FormatInt(time.Time(t).Unix(), 10)), nil
}

// UnmarshalJSON implements [json.Unmarshaler].
func (t *JSONUNIXTime) UnmarshalJSON(s []byte) error {
	// Find "." decimal point and remove it the decimal part if it exists.
	// Usually the timestamp is in seconds meaning it is an integer, but some providers
	// return the created timestamp with nanoseconds, which is a float json Number.
	//
	// Since this is only called on the response path in reality where we do not use this
	// type for translation, we can safely ignore the decimal part. Even if it is necessary
	// for the translation later, it should be safe to ignore it, because at the end of the day
	// the OpenAI client assumes that the time is in seconds.
	if index := bytes.IndexByte(s, '.'); index != -1 {
		s = s[:index]
	}
	q, err := strconv.ParseInt(string(s), 10, 64)
	if err != nil {
		return err
	}
	*(*time.Time)(t) = time.Unix(q, 0).UTC()
	return nil
}

// Equal compares two JSONUNIXTime values for equality. This is only for testing purposes.
func (t JSONUNIXTime) Equal(other JSONUNIXTime) bool {
	return time.Time(t).Unix() == time.Time(other).Unix()
}

// GCPVertexAIVendorFields contains GCP Vertex AI (Gemini) vendor-specific fields.
type GCPVertexAIVendorFields struct {
	// GenerationConfig holds Gemini generation configuration options.
	// Currently only a subset of the options are supported.
	//
	// https://cloud.google.com/vertex-ai/docs/reference/rest/v1/GenerationConfig
	GenerationConfig *GCPVertexAIGenerationConfig `json:"generationConfig,omitzero"`

	// SafetySettings: Safety settings in the request to block unsafe content in the response.
	//
	// https://cloud.google.com/vertex-ai/docs/reference/rest/v1/SafetySetting
	SafetySettings []*genai.SafetySetting `json:"safetySettings,omitzero"`
}

// GCPVertexAIGenerationConfig represents Gemini generation configuration options.
type GCPVertexAIGenerationConfig struct {
	// MediaResolution is to set global media resolution in gemini models: https://ai.google.dev/api/caching#MediaResolution
	MediaResolution genai.MediaResolution `json:"media_resolution,omitempty"`
}

// ReasoningContentUnion content regarding the reasoning that is carried out by the model.
// Reasoning refers to a Chain of Thought (CoT) that the model generates to enhance the accuracy of its final response.
type ReasoningContentUnion struct {
	Value any
}

func (r *ReasoningContentUnion) UnmarshalJSON(data []byte) error {
	// For qwen model it returns the reason content as a string.
	var str string
	err := json.Unmarshal(data, &str)
	if err == nil {
		r.Value = str
		return nil
	}

	var content *ReasoningContent
	err = json.Unmarshal(data, &content)
	if err == nil {
		r.Value = content
		return nil
	}
	return errors.New("cannot unmarshal JSON data as string or reasoningContentBlock")
}

func (r ReasoningContentUnion) MarshalJSON() ([]byte, error) {
	if stringContent, ok := r.Value.(string); ok {
		return json.Marshal(stringContent)
	}
	if reasoningContent, ok := r.Value.(*ReasoningContent); ok {
		return json.Marshal(reasoningContent)
	}

	return nil, errors.New("no reasoning content to marshal")
}

// ReasoningContent is used on both aws bedrock and gemini's reasoning
type ReasoningContent struct {
	// See https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ReasoningContentBlock.html for more information.
	ReasoningContent *awsbedrock.ReasoningContentBlock `json:"reasoningContent,omitzero"`
}

type StreamReasoningContent struct {
	Text            string `json:"text,omitzero"`
	Signature       string `json:"signature,omitzero"`
	RedactedContent []byte `json:"redactedContent,omitzero"`
}

// CompletionRequest represents a request to the legacy /completions endpoint.
// See https://platform.openai.com/docs/api-reference/completions/create
type CompletionRequest struct {
	// ID of the model to use. You can use the List models API to see all of your
	// available models, or see the Model overview for descriptions of them.
	Model string `json:"model"`

	// The prompt(s) to generate completions for, encoded as a string, array of
	// strings, array of tokens, or array of token arrays.
	// Note that <|endoftext|> is the document separator that the model sees during
	// training, so if a prompt is not specified the model will generate as if from
	// the beginning of a new document.
	Prompt PromptUnion `json:"prompt"`

	// Generates `best_of` completions server-side and returns the "best" (the one
	// with the highest log probability per token). Results cannot be streamed.
	// When used with `n`, `best_of` controls the number of candidate completions
	// and `n` specifies how many to return  `best_of` must be greater than `n`.
	// Minimum: 0, Maximum: 20, Default: 1
	BestOf *int `json:"best_of,omitempty"`

	// Echo back the prompt in addition to the completion.
	// Default: false
	Echo bool `json:"echo,omitzero"`

	// Number between -2.0 and 2.0. Positive values penalize new tokens based on
	// their existing frequency in the text so far, decreasing the model's
	// likelihood to repeat the same line verbatim.
	// Minimum: -2, Maximum: 2, Default: 0
	FrequencyPenalty *float64 `json:"frequency_penalty,omitempty"`

	// Modify the likelihood of specified tokens appearing in the completion.
	// Accepts a JSON object that maps tokens (specified by their token ID in the
	// GPT tokenizer) to an associated bias value from -100 to 100.
	LogitBias map[string]int `json:"logit_bias,omitempty"`

	// Include the log probabilities on the `logprobs` most likely output tokens,
	// as well the chosen tokens. The maximum value for `logprobs` is 5.
	// Minimum: 0, Maximum: 5, Default: null
	Logprobs *int `json:"logprobs,omitempty"`

	// The maximum number of tokens that can be generated in the completion.
	// The token count of your prompt plus `max_tokens` cannot exceed the model's
	// context length.
	// Minimum: 0, Default: 16
	MaxTokens *int `json:"max_tokens,omitempty"`

	// How many completions to generate for each prompt.
	// Minimum: 1, Maximum: 128, Default: 1
	N *int `json:"n,omitempty"`

	// Number between -2.0 and 2.0. Positive values penalize new tokens based on
	// whether they appear in the text so far, increasing the model's likelihood
	// to talk about new topics.
	// Minimum: -2, Maximum: 2, Default: 0
	PresencePenalty *float64 `json:"presence_penalty,omitempty"`

	// If specified, our system will make a best effort to sample deterministically,
	// such that repeated requests with the same `seed` and parameters should return
	// the same result. Determinism is not guaranteed.
	Seed *int64 `json:"seed,omitempty"`

	// Up to 4 sequences where the API will stop generating further tokens.
	Stop any `json:"stop,omitempty"`

	// Whether to stream back partial progress. If set, tokens will be sent as
	// data-only server-sent events as they become available, with the stream
	// terminated by a `data: [DONE]` message.
	// Default: false
	Stream bool `json:"stream,omitzero"`

	// Options for streaming response. Only set this when you set stream: true.
	StreamOptions *StreamOptions `json:"stream_options,omitempty"`

	// The suffix that comes after a completion of inserted text.
	// This parameter is only supported for `gpt-3.5-turbo-instruct`.
	// Default: null
	Suffix string `json:"suffix,omitzero"`

	// What sampling temperature to use, between 0 and 2. Higher values like 0.8
	// will make the output more random, while lower values like 0.2 will make it
	// more focused and deterministic.
	// Minimum: 0, Maximum: 2, Default: 1
	Temperature *float64 `json:"temperature,omitempty"`

	// An alternative to sampling with temperature, called nucleus sampling, where
	// the model considers the results of the tokens with top_p probability mass.
	// So 0.1 means only the tokens comprising the top 10% probability mass are
	// considered. We generally recommend altering this or temperature but not both.
	// Minimum: 0, Maximum: 1, Default: 1
	TopP *float64 `json:"top_p,omitempty"`

	// A unique identifier representing your end-user, which can help OpenAI to
	// monitor and detect abuse.
	User string `json:"user,omitzero"`
}

// PromptUnion represents the polymorphic prompt field that can be:
// - string: a single prompt
// - []string: batch of prompts
// - []int64: array of token IDs
// - [][]int64: batch of token ID arrays
type PromptUnion struct {
	Value interface{}
}

func (p PromptUnion) MarshalJSON() ([]byte, error) {
	return json.Marshal(p.Value)
}

func (p *PromptUnion) UnmarshalJSON(data []byte) (err error) {
	p.Value, err = unmarshalJSONNestedUnion("prompt", data)
	return
}

// CompletionResponse represents a completion response from the API.
// Note: both the streamed and non-streamed response objects share the same shape
// (unlike the chat endpoint).
// See https://platform.openai.com/docs/api-reference/completions/object
type CompletionResponse struct {
	// A unique identifier for the completion.
	ID string `json:"id"`

	// The object type, which is always "text_completion".
	Object string `json:"object"`

	// The Unix timestamp (in seconds) of when the completion was created.
	Created JSONUNIXTime `json:"created,omitzero"`

	// The model used for completion.
	Model string `json:"model"`

	// This fingerprint represents the backend configuration that the model runs with.
	SystemFingerprint string `json:"system_fingerprint,omitzero"`

	// The list of completion choices generated by the model.
	Choices []CompletionChoice `json:"choices"`

	// Usage statistics for the completion request.
	Usage *Usage `json:"usage,omitzero"`
}

// CompletionChoice represents a single completion choice.
type CompletionChoice struct {
	// The generated text completion.
	Text string `json:"text"`

	// The index of the choice in the list of choices.
	Index *int `json:"index,omitempty"`

	// Log probability information for the choice.
	Logprobs *CompletionLogprobs `json:"logprobs,omitzero"`

	// The reason the model stopped generating tokens.
	// This will be "stop" if the model hit a natural stop point or a provided stop
	// sequence, "length" if the maximum number of tokens specified in the request
	// was reached, or "content_filter" if content was omitted due to a flag from
	// our content filters.
	FinishReason string `json:"finish_reason,omitzero"`
}

// CompletionLogprobs represents log probability information.
type CompletionLogprobs struct {
	// The tokens chosen by the model.
	Tokens []string `json:"tokens,omitzero"`

	// The log probability of each token.
	TokenLogprobs []float64 `json:"token_logprobs,omitzero"`

	// A list of the top log probabilities for each token position.
	TopLogprobs []map[string]float64 `json:"top_logprobs,omitzero"`

	// The character offset from the start of the returned text for each token.
	TextOffset []int `json:"text_offset,omitzero"`
}

// Usage represents the usage information for completion requests (both chat and text).
// Maps to OpenAI's CompletionUsage schema.
// https://platform.openai.com/docs/api-reference/chat/object#chat/object-usage
// https://platform.openai.com/docs/api-reference/completions/object#completions/object-usage
//
// For /v1/completions endpoint: Only the basic fields (prompt_tokens, completion_tokens, total_tokens) are populated.
// For /v1/chat/completions endpoint: All fields including the detailed breakdowns may be populated.
type Usage struct {
	// Number of tokens in the prompt.
	PromptTokens int `json:"prompt_tokens,omitempty"` //nolint:tagliatelle //follow openai api

	// Number of tokens in the generated completion.
	CompletionTokens int `json:"completion_tokens,omitempty"` //nolint:tagliatelle //follow openai api

	// Total number of tokens used in the request (prompt + completion).
	TotalTokens int `json:"total_tokens,omitempty"` //nolint:tagliatelle //follow openai api

	// CompletionTokensDetails: Breakdown of tokens used in a completion.
	// Only populated for /v1/chat/completions endpoint, not for /v1/completions.
	CompletionTokensDetails *CompletionTokensDetails `json:"completion_tokens_details,omitempty"` //nolint:tagliatelle //follow openai api

	// PromptTokensDetails: Breakdown of tokens used in the prompt.
	// Only populated for /v1/chat/completions endpoint, not for /v1/completions.
	PromptTokensDetails *PromptTokensDetails `json:"prompt_tokens_details,omitempty"` //nolint:tagliatelle //follow openai api
}

// ImageGenerationRequest represents the request body for /v1/images/generations.
// https://platform.openai.com/docs/api-reference/images/create
type ImageGenerationRequest struct {
	// A text description of the desired image(s). The maximum length is 1000 characters for DALL-E 2,
	// 4000 characters for DALL-E 3, and 32000 characters for gpt-image-1.
	Prompt string `json:"prompt"`
	// The model to use for image generation. Defaults to dall-e-2.
	Model string `json:"model,omitempty"`
	// The number of images to generate. Must be between 1 and 10. For DALL-E 3, only n=1 is supported.
	// Defaults to 1.
	N int `json:"n,omitempty"`
	// The quality of the image that will be generated.
	// - hd or standard for DALL-E 3.
	// - high, medium, or low for gpt-image-1.
	// Defaults to standard for DALL-E 3, auto for gpt-image-1.
	Quality string `json:"quality,omitempty"`
	// The format in which the generated images are returned. Must be one of url or b64_json.
	// URLs are only valid for 60 minutes after the image has been generated.
	// This parameter isn't supported for gpt-image-1 which will always return base64-encoded images.
	// Defaults to url.
	ResponseFormat string `json:"response_format,omitempty"`
	// The size of the generated images.
	// - DALL-E 2: 256x256, 512x512, or 1024x1024.
	// - DALL-E 3: 1024x1024, 1792x1024, or 1024x1792.
	// - gpt-image-1: 1024x1024, 1536x1024, 1024x1536, or auto.
	// Defaults to 1024x1024 (DALL-E 2/3) or auto (gpt-image-1).
	Size string `json:"size,omitempty"`
	// The style of the generated images. vivid or natural. DALL-E 3 only.
	// Defaults to vivid.
	Style string `json:"style,omitempty"`
	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
	User string `json:"user,omitempty"`
	// The output format of the image generation. Either png, webp, or jpeg.
	// This parameter is only supported for gpt-image-1.
	// Defaults to png.
	OutputFormat string `json:"output_format,omitempty"`
	// The background parameter used for the image generation. Either transparent, opaque, or auto.
	// This parameter is only supported for gpt-image-1.
	// Defaults to auto.
	Background string `json:"background,omitempty"`
	// Control the content-moderation level for images generated by gpt-image-1. Must be either low or auto.
	// Defaults to auto.
	Moderation string `json:"moderation,omitempty"`
	// The compression level (0-100%) for the generated images.
	// This parameter is only supported for gpt-image-1 with the webp or jpeg output formats.
	// Defaults to 100.
	OutputCompression *int `json:"output_compression,omitempty"`
	// The number of partial images to generate.
	// This parameter is used for streaming responses that return partial images. Value must be between 0 and 3.
	// Defaults to 0.
	PartialImages int `json:"partial_images,omitempty"`
	// Generate the image in streaming mode.
	// This parameter is only supported for gpt-image-1.
	// Defaults to false.
	Stream bool `json:"stream,omitempty"`
}

// ImageGenerationInputTokensDetails breakdown of tokens used in the prompt for image generation.
type ImageGenerationInputTokensDetails struct {
	TextTokens  int `json:"text_tokens,omitempty"`
	ImageTokens int `json:"image_tokens,omitempty"`
}

// ImageGenerationUsage represents the usage information for image generation requests.
type ImageGenerationUsage struct {
	TotalTokens        int                                `json:"total_tokens"`
	InputTokens        int                                `json:"input_tokens"`
	OutputTokens       int                                `json:"output_tokens"`
	InputTokensDetails *ImageGenerationInputTokensDetails `json:"input_tokens_details,omitempty"`
}

// ImageGenerationResponse represents the response body for /v1/images/generations.
// https://platform.openai.com/docs/api-reference/images/object
type ImageGenerationResponse struct {
	// The Unix timestamp (in seconds) of when the image was created.
	Created int64 `json:"created"`
	// The list of generated images.
	Data []ImageGenerationResponseData `json:"data"`
	// For gpt-image-1 only, the token usage information for the image generation.
	Usage *ImageGenerationUsage `json:"usage,omitempty"`
	// The output format of the image generation. Either png, webp, or jpeg.
	OutputFormat string `json:"output_format,omitempty"`
	// The quality of the image generated. Either low, medium, or high.
	Quality string `json:"quality,omitempty"`
	// The size of the image generated. Either 1024x1024, 1024x1536, or 1536x1024.
	Size string `json:"size,omitempty"`
	// The background parameter used for the image generation. Either transparent or opaque.
	Background string `json:"background,omitempty"`
}

type ImageGenerationResponseData struct {
	B64JSON       string `json:"b64_json,omitempty"`
	URL           string `json:"url,omitempty"`
	RevisedPrompt string `json:"revised_prompt,omitempty"`
}

// ResponseRequest represents a request to the /v1/responses endpoint.
// The Responses API is a stateful API that combines capabilities from chat completions and assistants.
// Docs: https://platform.openai.com/docs/api-reference/responses/create

type ResponseRequest struct {
	// Whether to run the model response in the background.
	// [Learn more](https://platform.openai.com/docs/guides/background).
	Background *bool `json:"background,omitempty"`

	// A system (or developer) message inserted into the model's context.
	//
	// When using along with `previous_response_id`, the instructions from a previous
	// response will not be carried over to the next response. This makes it simple to
	// swap out system (or developer) messages in new responses.
	Instructions string `json:"instructions,omitzero"`

	// An upper bound for the number of tokens that can be generated for a response,
	// including visible output tokens and
	// [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).
	MaxOutputTokens *int64 `json:"max_output_tokens,omitempty"`

	// The maximum number of total calls to built-in tools that can be processed in a
	// response. This maximum number applies across all built-in tool calls, not per
	// individual tool. Any further attempts to call a tool by the model will be
	// ignored.
	MaxToolCalls *int64 `json:"max_tool_calls,omitempty"`

	// Whether to allow the model to run tool calls in parallel.
	ParallelToolCalls *bool `json:"parallel_tool_calls,omitempty"`

	// The unique ID of the previous response to the model. Use this to create
	// multi-turn conversations. Learn more about
	// [conversation state](https://platform.openai.com/docs/guides/conversation-state).
	// Cannot be used in conjunction with `conversation`.
	PreviousResponseID string `json:"previous_response_id,omitzero"`

	// Whether to store the generated model response for later retrieval via API.
	Store *bool `json:"store,omitempty"`

	// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will
	// make the output more random, while lower values like 0.2 will make it more
	// focused and deterministic. We generally recommend altering this or `top_p` but
	// not both.
	Temperature *float64 `json:"temperature,omitempty"`

	// An integer between 0 and 20 specifying the number of most likely tokens to
	// return at each token position, each with an associated log probability.
	TopLogprobs *int64 `json:"top_logprobs,omitempty"`

	// An alternative to sampling with temperature, called nucleus sampling, where the
	// model considers the results of the tokens with top_p probability mass. So 0.1
	// means only the tokens comprising the top 10% probability mass are considered.
	//
	// We generally recommend altering this or `temperature` but not both.
	TopP *float64 `json:"top_p,omitempty"`

	// Used by OpenAI to cache responses for similar requests to optimize your cache
	// hit rates. Replaces the `user` field.
	// [Learn more](https://platform.openai.com/docs/guides/prompt-caching).
	PromptCacheKey string `json:"prompt_cache_key,omitzero"`

	// A stable identifier used to help detect users of your application that may be
	// violating OpenAI's usage policies. The IDs should be a string that uniquely
	// identifies each user. We recommend hashing their username or email address, in
	// order to avoid sending us any identifying information.
	// [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).
	SafetyIdentifier string `json:"safety_identifier,omitzero"`

	// This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use
	// `prompt_cache_key` instead to maintain caching optimizations. A stable
	// identifier for your end-users. Used to boost cache hit rates by better bucketing
	// similar requests and to help OpenAI detect and prevent abuse.
	// [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).
	User string `json:"user,omitzero"`

	// The conversation that this response belongs to. Items from this conversation are
	// prepended to `input_items` for this response request. Input items and output
	// items from this response are automatically added to this conversation after this
	// response completes.
	Conversation ResponseNewParamsConversationUnion `json:"conversation,omitzero"`

	// Specify additional output data to include in the model response. Currently
	// supported values are:
	//
	//   - `web_search_call.action.sources`: Include the sources of the web search tool
	//     call.
	//   - `code_interpreter_call.outputs`: Includes the outputs of python code execution
	//     in code interpreter tool call items.
	//   - `computer_call_output.output.image_url`: Include image urls from the computer
	//     call output.
	//   - `file_search_call.results`: Include the search results of the file search tool
	//     call.
	//   - `message.input_image.image_url`: Include image urls from the input message.
	//   - `message.output_text.logprobs`: Include logprobs with assistant messages.
	//   - `reasoning.encrypted_content`: Includes an encrypted version of reasoning
	//     tokens in reasoning item outputs. This enables reasoning items to be used in
	//     multi-turn conversations when using the Responses API statelessly (like when
	//     the `store` parameter is set to `false`, or when an organization is enrolled
	//     in the zero data retention program).
	Include []string `json:"include,omitzero"`

	// Set of 16 key-value pairs that can be attached to an object. This can be useful
	// for storing additional information about the object in a structured format, and
	// querying for objects via API or the dashboard.
	//
	// Keys are strings with a maximum length of 64 characters. Values are strings with
	// a maximum length of 512 characters.
	Metadata map[string]string `json:"metadata,omitzero"`

	// Reference to a prompt template and its variables.
	// [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).
	Prompt ResponsePromptParam `json:"prompt,omitzero"`

	// The retention policy for the prompt cache. Set to `24h` to enable extended
	// prompt caching, which keeps cached prefixes active for longer, up to a maximum
	// of 24 hours.
	// [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).
	//
	// Any of "in-memory", "24h".
	PromptCacheRetention string `json:"prompt_cache_retention,omitzero"`

	// Specifies the processing type used for serving the request.
	//
	//   - If set to 'auto', then the request will be processed with the service tier
	//     configured in the Project settings. Unless otherwise configured, the Project
	//     will use 'default'.
	//   - If set to 'default', then the request will be processed with the standard
	//     pricing and performance for the selected model.
	//   - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or
	//     '[priority](https://openai.com/api-priority-processing/)', then the request
	//     will be processed with the corresponding service tier.
	//   - When not set, the default behavior is 'auto'.
	//
	// When the `service_tier` parameter is set, the response body will include the
	// `service_tier` value based on the processing mode actually used to serve the
	// request. This response value may be different from the value set in the
	// parameter.
	//
	// Any of "auto", "default", "flex", "scale", "priority".
	ServiceTier string `json:"service_tier,omitzero"`

	// Options for streaming responses. Only set this when you set `stream: true`.
	StreamOptions ResponseStreamOptions `json:"stream_options,omitzero"`

	// The truncation strategy to use for the model response.
	//
	//   - `auto`: If the input to this Response exceeds the model's context window size,
	//     the model will truncate the response to fit the context window by dropping
	//     items from the beginning of the conversation.
	//   - `disabled` (default): If the input size will exceed the context window size
	//     for a model, the request will fail with a 400 error.
	//
	// Any of "auto", "disabled".
	Truncation string `json:"truncation,omitzero"`

	// Text, image, or file inputs to the model, used to generate a response.
	//
	// Learn more:
	//
	// - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
	// - [Image inputs](https://platform.openai.com/docs/guides/images)
	// - [File inputs](https://platform.openai.com/docs/guides/pdf-files)
	// - [Conversation state](https://platform.openai.com/docs/guides/conversation-state)
	// - [Function calling](https://platform.openai.com/docs/guides/function-calling)
	Input ResponseNewParamsInputUnion `json:"input,omitzero"`

	// Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a
	// wide range of models with different capabilities, performance characteristics,
	// and price points. Refer to the
	// [model guide](https://platform.openai.com/docs/models) to browse and compare
	// available models.
	Model string `json:"model,omitzero"`

	// Configuration options for
	// [reasoning models](https://platform.openai.com/docs/guides/reasoning).
	Reasoning ReasoningParam `json:"reasoning,omitzero"`

	// Stream: If set, the response will be streamed back as server-sent events.
	Stream bool `json:"stream,omitempty"`

	// Configuration options for a text response from the model. Can be plain text or
	// structured JSON data. Learn more:
	//
	// - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
	// - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
	Text ResponseTextConfigParam `json:"text,omitzero"`

	// How the model should select which tool (or tools) to use when generating a
	// response. See the `tools` parameter to see how to specify which tools the model
	// can call.
	ToolChoice ResponseToolChoiceUnion `json:"tool_choice,omitzero"`

	// An array of tools the model may call while generating a response. You can
	// specify which tool to use by setting the `tool_choice` parameter.
	//
	// We support the following categories of tools:
	//
	//   - **Built-in tools**: Tools that are provided by OpenAI that extend the model's
	//     capabilities, like
	//     [web search](https://platform.openai.com/docs/guides/tools-web-search) or
	//     [file search](https://platform.openai.com/docs/guides/tools-file-search).
	//     Learn more about
	//     [built-in tools](https://platform.openai.com/docs/guides/tools).
	//   - **MCP Tools**: Integrations with third-party systems via custom MCP servers or
	//     predefined connectors such as Google Drive and SharePoint. Learn more about
	//     [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).
	//   - **Function calls (custom tools)**: Functions that are defined by you, enabling
	//     the model to call your own code with strongly typed arguments and outputs.
	//     Learn more about
	//     [function calling](https://platform.openai.com/docs/guides/function-calling).
	//     You can also use custom tools to call your own code.
	Tools []ResponseToolUnion `json:"tools,omitzero"`
}

// Configuration options for a text response from the model. Can be plain text or
// structured JSON data. Learn more:
//
// - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
// - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
type ResponseTextConfigParam struct {
	// Constrains the verbosity of the model's response. Lower values will result in
	// more concise responses, while higher values will result in more verbose
	// responses. Currently supported values are `low`, `medium`, and `high`.
	//
	// Any of "low", "medium", "high".
	Verbosity string `json:"verbosity,omitzero"`
	// An object specifying the format that the model must output.
	//
	// Configuring `{ "type": "json_schema" }` enables Structured Outputs, which
	// ensures the model will match your supplied JSON schema. Learn more in the
	// [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).
	//
	// The default format is `{ "type": "text" }` with no additional options.
	//
	//
	// Setting to `{ "type": "json_object" }` enables the older JSON mode, which
	// ensures the message the model generates is valid JSON. Using `json_schema` is
	// preferred for models that support it.
	Format ResponseFormatTextConfigUnionParam `json:"format,omitzero"`
}

// A union type for different text response format configurations.
// Only one field can be non-zero.
type ResponseFormatTextConfigUnionParam struct {
	OfText       *ResponseFormatTextParam
	OfJSONSchema *ResponseFormatTextJSONSchemaConfigParam
	OfJSONObject *ResponseFormatJSONObjectParam
}

func (r ResponseFormatTextConfigUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfText != nil:
		return json.Marshal(r.OfText)
	case r.OfJSONSchema != nil:
		return json.Marshal(r.OfJSONSchema)
	case r.OfJSONObject != nil:
		return json.Marshal(r.OfJSONObject)
	default:
		return nil, errors.New("no format to marshal in ResponseFormatTextConfigUnionParam")
	}
}

func (r *ResponseFormatTextConfigUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "text":
		var textParam ResponseFormatTextParam
		if err := json.Unmarshal(data, &textParam); err != nil {
			return err
		}
		r.OfText = &textParam
	case "json_schema":
		var jsonSchemaParam ResponseFormatTextJSONSchemaConfigParam
		if err := json.Unmarshal(data, &jsonSchemaParam); err != nil {
			return err
		}
		r.OfJSONSchema = &jsonSchemaParam
	case "json_object":
		var jsonObjectParam ResponseFormatJSONObjectParam
		if err := json.Unmarshal(data, &jsonObjectParam); err != nil {
			return err
		}
		r.OfJSONObject = &jsonObjectParam
	default:
		return errors.New("invalid format type in response format text config")
	}
	return nil
}

// Default response format. Used to generate text responses.
type ResponseFormatTextParam struct {
	// The type of response format being defined. Always `text`.
	Type string `json:"type"`
}

// JSON Schema response format. Used to generate structured JSON responses. Learn
// more about
// [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).
//
// The properties Name, Schema, Type are required.
type ResponseFormatTextJSONSchemaConfigParam struct {
	// The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores
	// and dashes, with a maximum length of 64.
	Name string `json:"name"`
	// The schema for the response format, described as a JSON Schema object. Learn how
	// to build JSON schemas [here](https://json-schema.org/).
	Schema map[string]any `json:"schema,omitzero"`
	// Whether to enable strict schema adherence when generating the output. If set to
	// true, the model will always follow the exact schema defined in the `schema`
	// field. Only a subset of JSON Schema is supported when `strict` is `true`. To
	// learn more, read the
	// [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).
	Strict *bool `json:"strict,omitempty"`
	// A description of what the response format is for, used by the model to determine
	// how to respond in the format.
	Description string `json:"description,omitzero"`
	// The type of response format being defined. Always `json_schema`.
	Type string `json:"type"`
}

// JSON object response format. An older method of generating JSON responses. Using
// `json_schema` is recommended for models that support it. Note that the model
// will not generate JSON without a system or user message instructing it to do so.
type ResponseFormatJSONObjectParam struct {
	// The type of response format being defined. Always `json_object`.
	Type string `json:"type"`
}

// Reasoning configuration for reasoning models.
type ReasoningParam struct {
	// Constrains effort on reasoning for
	// [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently
	// supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.
	// Reducing reasoning effort can result in faster responses and fewer tokens used
	// on reasoning in a response.
	//
	//   - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported
	//     reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool
	//     calls are supported for all reasoning values in gpt-5.1.
	//   - All models before `gpt-5.1` default to `medium` reasoning effort, and do not
	//     support `none`.
	//   - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
	//   - `xhigh` is currently only supported for `gpt-5.1-codex-max`.
	//
	// Any of "none", "minimal", "low", "medium", "high", "xhigh".
	Effort string `json:"effort,omitzero"`
	// **Deprecated:** use `summary` instead.
	//
	// A summary of the reasoning performed by the model. This can be useful for
	// debugging and understanding the model's reasoning process. One of `auto`,
	// `concise`, or `detailed`.
	//
	// Any of "auto", "concise", "detailed".
	//
	// Deprecated: deprecated
	GenerateSummary string `json:"generate_summary,omitzero"`
	// A summary of the reasoning performed by the model. This can be useful for
	// debugging and understanding the model's reasoning process. One of `auto`,
	// `concise`, or `detailed`.
	//
	// `concise` is only supported for `computer-use-preview` models.
	//
	// Any of "auto", "concise", "detailed".
	Summary string `json:"summary,omitzero"`
}

// Options for streaming responses.
type ResponseStreamOptions struct {
	// When true, stream obfuscation will be enabled. Stream obfuscation adds random
	// characters to an `obfuscation` field on streaming delta events to normalize
	// payload sizes as a mitigation to certain side-channel attacks. These obfuscation
	// fields are included by default, but add a small amount of overhead to the data
	// stream. You can set `include_obfuscation` to false to optimize for bandwidth if
	// you trust the network links between your application and the OpenAI API.
	IncludeObfuscation bool `json:"include_obfuscation,omitzero"`
}

// Reference to a prompt template and its variables.
// [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).
//
// The property ID is required.
type ResponsePromptParam struct {
	// The unique identifier of the prompt template to use.
	ID string `json:"id"`
	// Optional version of the prompt template.
	Version string `json:"version,omitzero"`
	// Optional map of values to substitute in for variables in your prompt. The
	// substitution values can either be strings, or other Response input types like
	// images or files.
	Variables map[string]ResponsePromptVariableUnionParam `json:"variables,omitzero"`
}

// ResponsePromptVariableUnionParam is a union type for different prompt variable parameters.
// Only one field can be non-zero.
type ResponsePromptVariableUnionParam struct {
	OfString     *string
	OfInputText  *ResponseInputTextParam
	OfInputImage *ResponseInputImageParam
	OfInputFile  *ResponseInputFileParam
}

func (r ResponsePromptVariableUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfString != nil:
		return json.Marshal(r.OfString)
	case r.OfInputText != nil:
		return json.Marshal(r.OfInputText)
	case r.OfInputImage != nil:
		return json.Marshal(r.OfInputImage)
	case r.OfInputFile != nil:
		return json.Marshal(r.OfInputFile)
	default:
		return nil, errors.New("no prompt variable to marshal in ResponsePromptVariableUnionParam")
	}
}

func (r *ResponsePromptVariableUnionParam) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as string first.
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		r.OfString = &str
		return nil
	}

	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "input_text":
		var it ResponseInputTextParam
		if err := json.Unmarshal(data, &it); err != nil {
			return err
		}
		r.OfInputText = &it
	case "input_image":
		var ii ResponseInputImageParam
		if err := json.Unmarshal(data, &ii); err != nil {
			return err
		}
		r.OfInputImage = &ii
	case "input_file":
		var ifp ResponseInputFileParam
		if err := json.Unmarshal(data, &ifp); err != nil {
			return err
		}
		r.OfInputFile = &ifp
	default:
		return errors.New("unknown type for ResponsePromptVariableUnionParam: " + typ.String())
	}
	return nil
}

// ResponseToolUnion is a union type for different tool parameters.
// Only one field can be non-zero.
type ResponseToolUnion struct {
	OfFunction         *FunctionToolParam
	OfFileSearch       *FileSearchToolParam
	OfComputerTool     *ComputerToolParam
	OfWebSearch        *WebSearchToolParam
	OfMcp              *ToolMcpParam
	OfCodeInterpreter  *ToolCodeInterpreterParam
	OfImageGeneration  *ToolImageGenerationParam
	OfLocalShell       *ToolLocalShellParam
	OfShell            *FunctionShellToolParam
	OfCustom           *CustomToolParam
	OfWebSearchPreview *WebSearchPreviewToolParam
	OfApplyPatch       *ApplyPatchToolParam
}

func (t ResponseToolUnion) MarshalJSON() ([]byte, error) { // nolint:gocritic
	switch {
	case t.OfFunction != nil:
		return json.Marshal(t.OfFunction)
	case t.OfFileSearch != nil:
		return json.Marshal(t.OfFileSearch)
	case t.OfComputerTool != nil:
		return json.Marshal(t.OfComputerTool)
	case t.OfWebSearch != nil:
		return json.Marshal(t.OfWebSearch)
	case t.OfMcp != nil:
		return json.Marshal(t.OfMcp)
	case t.OfCodeInterpreter != nil:
		return json.Marshal(t.OfCodeInterpreter)
	case t.OfImageGeneration != nil:
		return json.Marshal(t.OfImageGeneration)
	case t.OfLocalShell != nil:
		return json.Marshal(t.OfLocalShell)
	case t.OfShell != nil:
		return json.Marshal(t.OfShell)
	case t.OfCustom != nil:
		return json.Marshal(t.OfCustom)
	case t.OfWebSearchPreview != nil:
		return json.Marshal(t.OfWebSearchPreview)
	case t.OfApplyPatch != nil:
		return json.Marshal(t.OfApplyPatch)
	default:
		return nil, errors.New("no tool to marshal in ToolUnionParam")
	}
}

func (t *ResponseToolUnion) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "function":
		var f FunctionToolParam
		if err := json.Unmarshal(data, &f); err != nil {
			return err
		}
		t.OfFunction = &f
	case "file_search":
		var fs FileSearchToolParam
		if err := json.Unmarshal(data, &fs); err != nil {
			return err
		}
		t.OfFileSearch = &fs
	case "computer_use_preview":
		var cp ComputerToolParam
		if err := json.Unmarshal(data, &cp); err != nil {
			return err
		}
		t.OfComputerTool = &cp
	case "web_search", "web_search_2025_08_26":
		var ws WebSearchToolParam
		if err := json.Unmarshal(data, &ws); err != nil {
			return err
		}
		t.OfWebSearch = &ws
	case "mcp":
		var mcp ToolMcpParam
		if err := json.Unmarshal(data, &mcp); err != nil {
			return err
		}
		t.OfMcp = &mcp
	case "code_interpreter":
		var ci ToolCodeInterpreterParam
		if err := json.Unmarshal(data, &ci); err != nil {
			return err
		}
		t.OfCodeInterpreter = &ci
	case "image_generation":
		var ig ToolImageGenerationParam
		if err := json.Unmarshal(data, &ig); err != nil {
			return err
		}
		t.OfImageGeneration = &ig
	case "custom":
		var ct CustomToolParam
		if err := json.Unmarshal(data, &ct); err != nil {
			return err
		}
		t.OfCustom = &ct
	case "local_shell":
		var ls ToolLocalShellParam
		if err := json.Unmarshal(data, &ls); err != nil {
			return err
		}
		t.OfLocalShell = &ls
	case "shell":
		var st FunctionShellToolParam
		if err := json.Unmarshal(data, &st); err != nil {
			return err
		}
		t.OfShell = &st
	case "web_search_preview", "web_search_preview_2025_03_11":
		var wsp WebSearchPreviewToolParam
		if err := json.Unmarshal(data, &wsp); err != nil {
			return err
		}
		t.OfWebSearchPreview = &wsp
	case "apply_patch":
		var ap ApplyPatchToolParam
		if err := json.Unmarshal(data, &ap); err != nil {
			return err
		}
		t.OfApplyPatch = &ap
	default:
		return errors.New("unknown tool type")
	}
	return nil
}

// Defines a function in your own code the model can choose to call. Learn more
// about
// [function calling](https://platform.openai.com/docs/guides/function-calling).
//
// The properties Name, Parameters, Strict, Type are required.
type FunctionToolParam struct {
	// Whether to enforce strict parameter validation. Default `true`.
	Strict *bool `json:"strict,omitempty"`
	// A JSON schema object describing the parameters of the function.
	Parameters map[string]any `json:"parameters,omitzero"`
	// The name of the function to call.
	Name string `json:"name"`
	// A description of the function. Used by the model to determine whether or not to
	// call the function.
	Description string `json:"description,omitzero"`
	// The type of the function tool. Always `function`.
	Type string `json:"type"`
}

// A tool that searches for relevant content from uploaded files. Learn more about
// the
// [file search tool](https://platform.openai.com/docs/guides/tools-file-search).
//
// The properties Type, VectorStoreIDs are required.
type FileSearchToolParam struct {
	// The IDs of the vector stores to search.
	VectorStoreIDs []string `json:"vector_store_ids,omitzero"`
	// The maximum number of results to return. This number should be between 1 and 50
	// inclusive.
	MaxNumResults int64 `json:"max_num_results,omitzero"`
	// A filter to apply.
	Filters FileSearchToolFiltersUnionParam `json:"filters,omitzero"`
	// Ranking options for search.
	RankingOptions FileSearchToolRankingOptionsParam `json:"ranking_options,omitzero"`
	// The type of the file search tool. Always `file_search`.
	Type string `json:"type"`
}

// A union type for different file search tool filters.
// Only one field can be non-zero.
type FileSearchToolFiltersUnionParam struct {
	OfComparisonFilter *ComparisonFilterParam
	OfCompoundFilter   *CompoundFilterParam
}

func (f FileSearchToolFiltersUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case f.OfComparisonFilter != nil:
		return json.Marshal(f.OfComparisonFilter)
	case f.OfCompoundFilter != nil:
		return json.Marshal(f.OfCompoundFilter)
	default:
		return nil, errors.New("no filesearch filter to marshal")
	}
}

func (f *FileSearchToolFiltersUnionParam) UnmarshalJSON(data []byte) error {
	// Use gjson to efficiently get the type field
	typeVal := gjson.GetBytes(data, "type")
	switch typeVal.String() {
	case "and", "or":
		// This is a CompoundFilterParam
		var compdFilter CompoundFilterParam
		if err := json.Unmarshal(data, &compdFilter); err != nil {
			return errors.New("cannot unmarshal filesearch tool filters as compound filter")
		}
		f.OfCompoundFilter = &compdFilter
		return nil
	default:
		// This is a ComparisonFilterParam with a comparison operator
		var compFilter ComparisonFilterParam
		if err := json.Unmarshal(data, &compFilter); err != nil {
			return errors.New("cannot unmarshal filesearch tool filters as comparison filter")
		}
		f.OfComparisonFilter = &compFilter
		return nil
	}
}

// Combine multiple filters using `and` or `or`.
//
// The properties Filters, Type are required.
type CompoundFilterParam struct {
	// Array of filters to combine. Items can be `ComparisonFilter` or
	// `CompoundFilter`.
	Filters []ComparisonFilterParam `json:"filters,omitzero"`
	// Type of operation: `and` or `or`.
	//
	// Any of "and", "or".
	Type string `json:"type,omitzero"`
}

// A filter used to compare a specified attribute key to a given value using a
// defined comparison operation.
//
// The properties Key, Type, Value are required.
type ComparisonFilterParam struct {
	// The key to compare against the value.
	Key string `json:"key,omitzero"`
	// Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`,
	// `nin`.
	//
	// - `eq`: equals
	// - `ne`: not equal
	// - `gt`: greater than
	// - `gte`: greater than or equal
	// - `lt`: less than
	// - `lte`: less than or equal
	// - `in`: in
	// - `nin`: not in
	//
	// Any of "eq", "ne", "gt", "gte", "lt", "lte".
	Type string `json:"type,omitzero"`
	// The value to compare against the attribute key; supports string, number, or
	// boolean types.
	Value ComparisonFilterValueUnionParam `json:"value,omitzero"`
}

// A union type for different comparison filter values.
// Only one field can be non-zero.
type ComparisonFilterValueUnionParam struct {
	OfString                     *string
	OfFloat                      *float64
	OfBool                       *bool
	OfComparisonFilterValueArray []ComparisonFilterValueArrayItemUnionParam
}

func (c ComparisonFilterValueUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case c.OfString != nil:
		return json.Marshal(c.OfString)
	case c.OfFloat != nil:
		return json.Marshal(c.OfFloat)
	case c.OfBool != nil:
		return json.Marshal(c.OfBool)
	case c.OfComparisonFilterValueArray != nil:
		return json.Marshal(c.OfComparisonFilterValueArray)
	default:
		return nil, errors.New("no value to marshal in comparison filter")
	}
}

func (c *ComparisonFilterValueUnionParam) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as string
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		c.OfString = &str
		return nil
	}

	// Try to unmarshal as float64
	var f float64
	if err := json.Unmarshal(data, &f); err == nil {
		c.OfFloat = &f
		return nil
	}

	// Try to unmarshal as bool
	var b bool
	if err := json.Unmarshal(data, &b); err == nil {
		c.OfBool = &b
		return nil
	}

	// Try to unmarshal as array of ComparisonFilterValueArrayItemUnionParam
	var arr []ComparisonFilterValueArrayItemUnionParam
	if err := json.Unmarshal(data, &arr); err == nil {
		c.OfComparisonFilterValueArray = arr
		return nil
	}
	return errors.New("cannot unmarshal comparison filter value")
}

// A union type for different comparison filter array item values.
// Only one field can be non-zero.
type ComparisonFilterValueArrayItemUnionParam struct {
	OfString *string
	OfFloat  *float64
}

func (c ComparisonFilterValueArrayItemUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case c.OfString != nil:
		return json.Marshal(c.OfString)
	case c.OfFloat != nil:
		return json.Marshal(c.OfFloat)
	default:
		return nil, errors.New("no value to marshal in comparison filter value array")
	}
}

func (c *ComparisonFilterValueArrayItemUnionParam) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as string
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		c.OfString = &str
		return nil
	}

	// Try to unmarshal as float64
	var f float64
	if err := json.Unmarshal(data, &f); err == nil {
		c.OfFloat = &f
		return nil
	}

	return errors.New("cannot unmarshal comparison filter value array item")
}

// Ranking options for search.
type FileSearchToolRankingOptionsParam struct {
	// The score threshold for the file search, a number between 0 and 1. Numbers
	// closer to 1 will attempt to return only the most relevant results, but may
	// return fewer results.
	ScoreThreshold *float64 `json:"score_threshold,omitempty"`
	// Weights that control how reciprocal rank fusion balances semantic embedding
	// matches versus sparse keyword matches when hybrid search is enabled.
	HybridSearch FileSearchToolRankingOptionsHybridSearchParam `json:"hybrid_search,omitzero"`
	// The ranker to use for the file search.
	//
	// Any of "auto", "default-2024-11-15".
	Ranker string `json:"ranker,omitzero"`
}

// Weights that control how reciprocal rank fusion balances semantic embedding
// matches versus sparse keyword matches when hybrid search is enabled.
//
// The properties EmbeddingWeight, TextWeight are required.
type FileSearchToolRankingOptionsHybridSearchParam struct {
	// The weight of the embedding in the reciprocal ranking fusion.
	EmbeddingWeight float64 `json:"embedding_weight"`
	// The weight of the text in the reciprocal ranking fusion.
	TextWeight float64 `json:"text_weight"`
}

// A tool that controls a virtual computer. Learn more about the
// [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).
//
// The properties DisplayHeight, DisplayWidth, Environment, Type are required.
type ComputerToolParam struct {
	// The height of the computer display.
	DisplayHeight int64 `json:"display_height,omitzero"`
	// The width of the computer display.
	DisplayWidth int64 `json:"display_width,omitzero"`
	// The type of computer environment to control.
	//
	// Any of "windows", "mac", "linux", "ubuntu", "browser".
	Environment string `json:"environment,omitzero"`
	// The type of the computer use tool. Always `computer_use_preview`.
	Type string `json:"type,omitzero"`
}

// Search the Internet for sources related to the prompt. Learn more about the
// [web search tool](https://platform.openai.com/docs/guides/tools-web-search).
//
// The property Type is required.
type WebSearchToolParam struct {
	// The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.
	//
	// Any of "web_search", "web_search_2025_08_26".
	Type string `json:"type,omitzero"`
	// Filters for the search.
	Filters WebSearchToolFiltersParam `json:"filters,omitzero"`
	// The approximate location of the user.
	UserLocation WebSearchToolUserLocationParam `json:"user_location,omitzero"`
	// High level guidance for the amount of context window space to use for the
	// search. One of `low`, `medium`, or `high`. `medium` is the default.
	//
	// Any of "low", "medium", "high".
	SearchContextSize string `json:"search_context_size,omitzero"`
}

// Filters for the search.
type WebSearchToolFiltersParam struct {
	// Allowed domains for the search. If not provided, all domains are allowed.
	// Subdomains of the provided domains are allowed as well.
	//
	// Example: `["pubmed.ncbi.nlm.nih.gov"]`
	AllowedDomains []string `json:"allowed_domains,omitzero"`
}

// The approximate location of the user.
type WebSearchToolUserLocationParam struct {
	// Free text input for the city of the user, e.g. `San Francisco`.
	City string `json:"city,omitzero"`
	// The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of
	// the user, e.g. `US`.
	Country string `json:"country,omitzero"`
	// Free text input for the region of the user, e.g. `California`.
	Region string `json:"region,omitzero"`
	// The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the
	// user, e.g. `America/Los_Angeles`.
	Timezone string `json:"timezone,omitzero"`
	// The type of location approximation. Always `approximate`.
	Type string `json:"type,omitzero"`
}

// Give the model access to additional tools via remote Model Context Protocol
// (MCP) servers.
// [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).
//
// The properties ServerLabel, Type are required.
type ToolMcpParam struct {
	// A label for this MCP server, used to identify it in tool calls.
	ServerLabel string `json:"server_label"`
	// An OAuth access token that can be used with a remote MCP server, either with a
	// custom MCP server URL or a service connector. Your application must handle the
	// OAuth authorization flow and provide the token here.
	Authorization string `json:"authorization,omitzero"`
	// Optional description of the MCP server, used to provide more context.
	ServerDescription string `json:"server_description,omitzero"`
	// The URL for the MCP server. One of `server_url` or `connector_id` must be
	// provided.
	ServerURL string `json:"server_url,omitzero"`
	// List of allowed tool names or a filter object.
	AllowedTools ToolMcpAllowedToolsUnionParam `json:"allowed_tools,omitzero"`
	// Optional HTTP headers to send to the MCP server. Use for authentication or other
	// purposes.
	Headers map[string]string `json:"headers,omitzero"`
	// Specify which of the MCP server's tools require approval.
	RequireApproval ToolMcpRequireApprovalUnionParam `json:"require_approval,omitzero"`
	// Identifier for service connectors, like those available in ChatGPT. One of
	// `server_url` or `connector_id` must be provided. Learn more about service
	// connectors
	// [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).
	//
	// Currently supported `connector_id` values are:
	//
	// - Dropbox: `connector_dropbox`
	// - Gmail: `connector_gmail`
	// - Google Calendar: `connector_googlecalendar`
	// - Google Drive: `connector_googledrive`
	// - Microsoft Teams: `connector_microsoftteams`
	// - Outlook Calendar: `connector_outlookcalendar`
	// - Outlook Email: `connector_outlookemail`
	// - SharePoint: `connector_sharepoint`
	//
	// Any of "connector_dropbox", "connector_gmail", "connector_googlecalendar",
	// "connector_googledrive", "connector_microsoftteams",
	// "connector_outlookcalendar", "connector_outlookemail", "connector_sharepoint".
	ConnectorID string `json:"connector_id,omitzero"`
	// The type of the MCP tool. Always `mcp`.
	Type string `json:"type"`
}

// A union type for specifying allowed MCP server tools.
// Only one field can be non-zero.
type ToolMcpAllowedToolsUnionParam struct {
	OfMcpAllowedTools []string
	OfMcpToolFilter   *ToolMcpAllowedToolsMcpToolFilterParam
}

func (t ToolMcpAllowedToolsUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case t.OfMcpAllowedTools != nil:
		return json.Marshal(t.OfMcpAllowedTools)
	case t.OfMcpToolFilter != nil:
		return json.Marshal(t.OfMcpToolFilter)
	default:
		return nil, errors.New("no tools to marshal in mcp allowed tools")
	}
}

func (t *ToolMcpAllowedToolsUnionParam) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as []string
	var toolNames []string
	if err := json.Unmarshal(data, &toolNames); err == nil {
		t.OfMcpAllowedTools = toolNames
		return nil
	}

	// Try to unmarshal as ToolMcpAllowedToolsMcpToolFilterParam
	var toolFilter ToolMcpAllowedToolsMcpToolFilterParam
	if err := json.Unmarshal(data, &toolFilter); err == nil {
		t.OfMcpToolFilter = &toolFilter
		return nil
	}

	return errors.New("cannot unmarshal Mcp allowed tools")
}

// A filter object to specify which tools are allowed.
type ToolMcpAllowedToolsMcpToolFilterParam struct {
	// Indicates whether or not a tool modifies data or is read-only. If an MCP server
	// is
	// [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),
	// it will match this filter.
	ReadOnly *bool `json:"read_only,omitempty"`
	// List of allowed tool names.
	ToolNames []string `json:"tool_names,omitzero"`
}

// A union type for specifying which MCP server tools require approval.
// Only one field can be non-zero.
type ToolMcpRequireApprovalUnionParam struct {
	OfMcpToolApprovalFilter  *ToolMcpRequireApprovalMcpToolApprovalFilterParam
	OfMcpToolApprovalSetting *string
}

func (t ToolMcpRequireApprovalUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case t.OfMcpToolApprovalFilter != nil:
		return json.Marshal(t.OfMcpToolApprovalFilter)
	case t.OfMcpToolApprovalSetting != nil:
		return json.Marshal(t.OfMcpToolApprovalSetting)
	default:
		return nil, errors.New("no tool to marshal in mcp require approval")
	}
}

func (t *ToolMcpRequireApprovalUnionParam) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as ToolMcpRequireApprovalMcpToolApprovalFilterParam
	var toolApprovalFilter ToolMcpRequireApprovalMcpToolApprovalFilterParam
	if err := json.Unmarshal(data, &toolApprovalFilter); err == nil {
		t.OfMcpToolApprovalFilter = &toolApprovalFilter
		return nil
	}

	// Try to unmarshal as string
	var setting string
	if err := json.Unmarshal(data, &setting); err == nil {
		t.OfMcpToolApprovalSetting = &setting
		return nil
	}

	return errors.New("cannot unmarshal Mcp require approval")
}

// Specify which of the MCP server's tools require approval. Can be `always`,
// `never`, or a filter object associated with tools that require approval.
type ToolMcpRequireApprovalMcpToolApprovalFilterParam struct {
	// A filter object to specify which tools are allowed.
	Always ToolMcpRequireApprovalMcpToolApprovalFilterObjectParam `json:"always,omitzero"`
	// A filter object to specify which tools are allowed.
	Never ToolMcpRequireApprovalMcpToolApprovalFilterObjectParam `json:"never,omitzero"`
}

// A filter object to specify which tools are allowed.
type ToolMcpRequireApprovalMcpToolApprovalFilterObjectParam struct {
	// Indicates whether or not a tool modifies data or is read-only. If an MCP server
	// is
	// [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),
	// it will match this filter.
	ReadOnly *bool `json:"read_only,omitempty"`
	// List of allowed tool names.
	ToolNames []string `json:"tool_names,omitzero"`
}

// A tool that runs Python code to help generate a response to a prompt.
//
// The properties Container, Type are required.
type ToolCodeInterpreterParam struct {
	// The code interpreter container. Can be a container ID or an object that
	// specifies uploaded file IDs to make available to your code, along with an
	// optional `memory_limit` setting.
	Container ToolCodeInterpreterContainerUnionParam `json:"container,omitzero"`
	// The type of the code interpreter tool. Always `code_interpreter`.
	Type string `json:"type"`
}

// A union type for different code interpreter container parameters.
// Only one field can be non-zero.
type ToolCodeInterpreterContainerUnionParam struct {
	OfString                  *string
	OfCodeInterpreterToolAuto *ToolCodeInterpreterContainerCodeInterpreterContainerAutoParam
}

func (t ToolCodeInterpreterContainerUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case t.OfString != nil:
		return json.Marshal(t.OfString)
	case t.OfCodeInterpreterToolAuto != nil:
		return json.Marshal(t.OfCodeInterpreterToolAuto)
	default:
		return nil, errors.New("no container to marshal in code interpreter")
	}
}

func (t *ToolCodeInterpreterContainerUnionParam) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as string
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		t.OfString = &str
		return nil
	}

	// Try to unmarshal as ToolCodeInterpreterContainerCodeInterpreterContainerAutoParam
	var autoParam ToolCodeInterpreterContainerCodeInterpreterContainerAutoParam
	if err := json.Unmarshal(data, &autoParam); err == nil {
		t.OfCodeInterpreterToolAuto = &autoParam
		return nil
	}

	return errors.New("cannot unmarshal code interpreter container")
}

// Configuration for a code interpreter container. Optionally specify the IDs of
// the files to run the code on.
//
// The property Type is required.
type ToolCodeInterpreterContainerCodeInterpreterContainerAutoParam struct {
	// Any of "1g", "4g", "16g", "64g".
	MemoryLimit string `json:"memory_limit,omitzero"`
	// An optional list of uploaded files to make available to your code.
	FileIDs []string `json:"file_ids,omitzero"`
	// Always `auto`.
	Type string `json:"type"`
}

// A tool that generates images using a model like `gpt-image-1`.
//
// The property Type is required.
type ToolImageGenerationParam struct {
	// Compression level for the output image. Default: 100.
	OutputCompression *int64 `json:"output_compression,omitempty"`
	// Number of partial images to generate in streaming mode, from 0 (default value)
	// to 3.
	PartialImages *int64 `json:"partial_images,omitempty"`
	// Control how much effort the model will exert to match the style and features,
	// especially facial features, of input images. This parameter is only supported
	// for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and
	// `low`. Defaults to `low`.
	//
	// Any of "high", "low".
	InputFidelity string `json:"input_fidelity,omitzero"`
	// Background type for the generated image. One of `transparent`, `opaque`, or
	// `auto`. Default: `auto`.
	//
	// Any of "transparent", "opaque", "auto".
	Background string `json:"background,omitzero"`
	// Optional mask for inpainting. Contains `image_url` (string, optional) and
	// `file_id` (string, optional).
	InputImageMask ToolImageGenerationInputImageMaskParam `json:"input_image_mask,omitzero"`
	// The image generation model to use. Default: `gpt-image-1`.
	//
	// Any of "gpt-image-1", "gpt-image-1-mini".
	Model string `json:"model,omitzero"`
	// Moderation level for the generated image. Default: `auto`.
	//
	// Any of "auto", "low".
	Moderation string `json:"moderation,omitzero"`
	// The output format of the generated image. One of `png`, `webp`, or `jpeg`.
	// Default: `png`.
	//
	// Any of "png", "webp", "jpeg".
	OutputFormat string `json:"output_format,omitzero"`
	// The quality of the generated image. One of `low`, `medium`, `high`, or `auto`.
	// Default: `auto`.
	//
	// Any of "low", "medium", "high", "auto".
	Quality string `json:"quality,omitzero"`
	// The size of the generated image. One of `1024x1024`, `1024x1536`, `1536x1024`,
	// or `auto`. Default: `auto`.
	//
	// Any of "1024x1024", "1024x1536", "1536x1024", "auto".
	Size string `json:"size,omitzero"`
	// The type of the image generation tool. Always `image_generation`.
	Type string `json:"type"`
}

// Optional mask for inpainting. Contains `image_url` (string, optional) and
// `file_id` (string, optional).
type ToolImageGenerationInputImageMaskParam struct {
	// File ID for the mask image.
	FileID string `json:"file_id,omitzero"`
	// Base64-encoded mask image.
	ImageURL string `json:"image_url,omitzero"`
}

// A tool that allows the model to execute shell commands in a local environment.
type ToolLocalShellParam struct {
	// The type of the local shell tool. Always `local_shell`.
	Type string `json:"type"`
}

// A tool that allows the model to execute shell commands.
type FunctionShellToolParam struct {
	// The type of the shell tool. Always `shell`.
	Type string `json:"type"`
}

// A custom tool that processes input using a specified format. Learn more about
// [custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools)
//
// The properties Name, Type are required.
type CustomToolParam struct {
	// The name of the custom tool, used to identify it in tool calls.
	Name string `json:"name"`
	// Optional description of the custom tool, used to provide more context.
	Description string `json:"description,omitzero"`
	// The input format for the custom tool. Default is unconstrained text.
	Format CustomToolInputFormatUnionParam `json:"format,omitzero"`
	// The type of the custom tool. Always `custom`.
	Type string `json:"type"`
}

// A union type for different custom tool input format parameters.
// Only one field can be non-zero.
type CustomToolInputFormatUnionParam struct {
	OfText    *CustomToolInputFormatTextParam
	OfGrammar *CustomToolInputFormatGrammarParam
}

func (c CustomToolInputFormatUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case c.OfText != nil:
		return json.Marshal(c.OfText)
	case c.OfGrammar != nil:
		return json.Marshal(c.OfGrammar)
	default:
		return nil, errors.New("no format to marshal in CustomToolInputFormatUnionParam")
	}
}

func (c *CustomToolInputFormatUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "text":
		var textParam CustomToolInputFormatTextParam
		if err := json.Unmarshal(data, &textParam); err != nil {
			return err
		}
		c.OfText = &textParam
	case "grammar":
		var grammarParam CustomToolInputFormatGrammarParam
		if err := json.Unmarshal(data, &grammarParam); err != nil {
			return err
		}
		c.OfGrammar = &grammarParam
	default:
		return errors.New("invalid format type in custom tool input format")
	}
	return nil
}

// Unconstrained free-form text.
type CustomToolInputFormatTextParam struct {
	// Unconstrained text format. Always `text`.
	Type string `json:"type"`
}

// A grammar defined by the user.
//
// The properties Definition, Syntax, Type are required.
type CustomToolInputFormatGrammarParam struct {
	// The grammar definition.
	Definition string `json:"definition"`
	// The syntax of the grammar definition. One of `lark` or `regex`.
	//
	// Any of "lark", "regex".
	Syntax string `json:"syntax,omitzero"`
	// Grammar format. Always `grammar`.
	Type string `json:"type"`
}

// This tool searches the web for relevant results to use in a response. Learn more
// about the
// [web search tool](https://platform.openai.com/docs/guides/tools-web-search).
//
// The property Type is required.
type WebSearchPreviewToolParam struct {
	// The type of the web search tool. One of `web_search_preview` or
	// `web_search_preview_2025_03_11`.
	//
	// Any of "web_search_preview", "web_search_preview_2025_03_11".
	Type string `json:"type,omitzero"`
	// The user's location.
	UserLocation WebSearchPreviewToolUserLocationParam `json:"user_location,omitzero"`
	// High level guidance for the amount of context window space to use for the
	// search. One of `low`, `medium`, or `high`. `medium` is the default.
	//
	// Any of "low", "medium", "high".
	SearchContextSize string `json:"search_context_size,omitzero"`
}

// The user's location.
//
// The property Type is required.
type WebSearchPreviewToolUserLocationParam struct {
	// Free text input for the city of the user, e.g. `San Francisco`.
	City string `json:"city,omitzero"`
	// The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of
	// the user, e.g. `US`.
	Country string `json:"country,omitzero"`
	// Free text input for the region of the user, e.g. `California`.
	Region string `json:"region,omitzero"`
	// The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the
	// user, e.g. `America/Los_Angeles`.
	Timezone string `json:"timezone,omitzero"`
	// The type of location approximation. Always `approximate`.
	Type string `json:"type"`
}

// Allows the assistant to create, delete, or update files using unified diffs.
type ApplyPatchToolParam struct {
	// The type of the tool. Always `apply_patch`.
	Type string `json:"type"`
}

// A text input to the model.
//
// The properties Text, Type are required.
type ResponseInputTextParam struct {
	// The text input to the model.
	Text string `json:"text"`
	// The type of the input item. Always `input_text`.
	Type string `json:"type"`
}

// An image input to the model. Learn about
// [image inputs](https://platform.openai.com/docs/guides/vision).
//
// The properties Detail, Type are required.
type ResponseInputImageParam struct {
	// The detail level of the image to be sent to the model. One of `high`, `low`, or
	// `auto`. Defaults to `auto`.
	//
	// Any of "low", "high", "auto".
	Detail string `json:"detail,omitzero"`
	// The ID of the file to be sent to the model.
	FileID string `json:"file_id,omitzero"`
	// The URL of the image to be sent to the model. A fully qualified URL or base64
	// encoded image in a data URL.
	ImageURL string `json:"image_url,omitzero"`
	// The type of the input item. Always `input_image`.
	Type string `json:"type"`
}

// A file input to the model.
//
// The property Type is required.
type ResponseInputFileParam struct {
	// The ID of the file to be sent to the model.
	FileID string `json:"file_id,omitzero"`
	// The content of the file to be sent to the model.
	FileData string `json:"file_data,omitzero"`
	// The URL of the file to be sent to the model.
	FileURL string `json:"file_url,omitzero"`
	// The name of the file to be sent to the model.
	Filename string `json:"filename,omitzero"`
	// The type of the input item. Always `input_file`.
	Type string `json:"type"`
}

// ResponseNewParamsConversationUnion is a union type for different conversation parameters.
// Only one field can be non-zero.
type ResponseNewParamsConversationUnion struct {
	OfString             *string
	OfConversationObject *ResponseConversationParam
}

func (r ResponseNewParamsConversationUnion) MarshalJSON() ([]byte, error) {
	if r.OfString != nil {
		return json.Marshal(r.OfString)
	}
	if r.OfConversationObject != nil {
		return json.Marshal(r.OfConversationObject)
	}
	return nil, errors.New("no conversation parameter to marshal")
}

func (r *ResponseNewParamsConversationUnion) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as string first.
	var str string
	if err := json.Unmarshal(data, &str); err == nil {
		r.OfString = &str
		return nil
	}

	// Try to unmarshal as ResponseConversationParam.
	var conv ResponseConversationParam
	if err := json.Unmarshal(data, &conv); err == nil {
		r.OfConversationObject = &conv
		return nil
	}

	return errors.New("cannot unmarshal conversation parameter")
}

// The conversation that this response belongs to.
//
// The property ID is required.
type ResponseConversationParam struct {
	// The unique ID of the conversation.
	ID string `json:"id"`
}

type ResponseNewParamsInputUnion struct {
	OfString        *string
	OfInputItemList []ResponseInputItemUnionParam
}

func (r *ResponseNewParamsInputUnion) UnmarshalJSON(data []byte) error {
	// Try string
	var s string
	if err := json.Unmarshal(data, &s); err == nil {
		r.OfString = &s
		r.OfInputItemList = nil
		return nil
	}

	// Try input item list
	var items []ResponseInputItemUnionParam
	if err := json.Unmarshal(data, &items); err == nil {
		r.OfString = nil
		r.OfInputItemList = items
		return nil
	}

	return errors.New("input must be either a string or an array of input items")
}

func (r ResponseNewParamsInputUnion) MarshalJSON() ([]byte, error) {
	if r.OfString != nil {
		return json.Marshal(r.OfString)
	}
	if r.OfInputItemList != nil {
		return json.Marshal(r.OfInputItemList)
	}
	return nil, errors.New("no response input to marshal")
}

// ResponseInputItemUnionParam is a union type for different input item parameters.
// Only one field can be non-zero.
type ResponseInputItemUnionParam struct {
	OfMessage              *EasyInputMessageParam
	OfInputMessage         *ResponseInputItemMessageParam
	OfOutputMessage        *ResponseOutputMessage
	OfFileSearchCall       *ResponseFileSearchToolCall
	OfComputerCall         *ResponseComputerToolCall
	OfComputerCallOutput   *ResponseInputItemComputerCallOutputParam
	OfWebSearchCall        *ResponseFunctionWebSearch
	OfFunctionCall         *ResponseFunctionToolCall
	OfFunctionCallOutput   *ResponseInputItemFunctionCallOutputParam
	OfReasoning            *ResponseReasoningItem
	OfCompaction           *ResponseCompactionItemParam
	OfImageGenerationCall  *ResponseInputItemImageGenerationCallParam
	OfCodeInterpreterCall  *ResponseCodeInterpreterToolCallParam
	OfLocalShellCall       *ResponseInputItemLocalShellCallParam
	OfLocalShellCallOutput *ResponseInputItemLocalShellCallOutputParam
	OfShellCall            *ResponseInputItemShellCallParam
	OfShellCallOutput      *ResponseInputItemShellCallOutputParam
	OfApplyPatchCall       *ResponseInputItemApplyPatchCallParam
	OfApplyPatchCallOutput *ResponseInputItemApplyPatchCallOutputParam
	OfMcpListTools         *ResponseMcpListTools
	OfMcpApprovalRequest   *ResponseMcpApprovalRequest
	OfMcpApprovalResponse  *ResponseInputItemMcpApprovalResponseParam
	OfMcpCall              *ResponseMcpCall
	OfCustomToolCallOutput *ResponseCustomToolCallOutputParam
	OfCustomToolCall       *ResponseCustomToolCall
	OfItemReference        *ResponseInputItemItemReferenceParam
}

func (r ResponseInputItemUnionParam) MarshalJSON() ([]byte, error) { // nolint:gocritic
	switch {
	case r.OfMessage != nil:
		return json.Marshal(r.OfMessage)
	case r.OfInputMessage != nil:
		return json.Marshal(r.OfInputMessage)
	case r.OfOutputMessage != nil:
		return json.Marshal(r.OfOutputMessage)
	case r.OfFileSearchCall != nil:
		return json.Marshal(r.OfFileSearchCall)
	case r.OfComputerCall != nil:
		return json.Marshal(r.OfComputerCall)
	case r.OfComputerCallOutput != nil:
		return json.Marshal(r.OfComputerCallOutput)
	case r.OfWebSearchCall != nil:
		return json.Marshal(r.OfWebSearchCall)
	case r.OfFunctionCall != nil:
		return json.Marshal(r.OfFunctionCall)
	case r.OfFunctionCallOutput != nil:
		return json.Marshal(r.OfFunctionCallOutput)
	case r.OfReasoning != nil:
		return json.Marshal(r.OfReasoning)
	case r.OfCompaction != nil:
		return json.Marshal(r.OfCompaction)
	case r.OfImageGenerationCall != nil:
		return json.Marshal(r.OfImageGenerationCall)
	case r.OfCodeInterpreterCall != nil:
		return json.Marshal(r.OfCodeInterpreterCall)
	case r.OfLocalShellCall != nil:
		return json.Marshal(r.OfLocalShellCall)
	case r.OfLocalShellCallOutput != nil:
		return json.Marshal(r.OfLocalShellCallOutput)
	case r.OfShellCall != nil:
		return json.Marshal(r.OfShellCall)
	case r.OfShellCallOutput != nil:
		return json.Marshal(r.OfShellCallOutput)
	case r.OfApplyPatchCall != nil:
		return json.Marshal(r.OfApplyPatchCall)
	case r.OfApplyPatchCallOutput != nil:
		return json.Marshal(r.OfApplyPatchCallOutput)
	case r.OfMcpListTools != nil:
		return json.Marshal(r.OfMcpListTools)
	case r.OfMcpApprovalRequest != nil:
		return json.Marshal(r.OfMcpApprovalRequest)
	case r.OfMcpApprovalResponse != nil:
		return json.Marshal(r.OfMcpApprovalResponse)
	case r.OfMcpCall != nil:
		return json.Marshal(r.OfMcpCall)
	case r.OfCustomToolCallOutput != nil:
		return json.Marshal(r.OfCustomToolCallOutput)
	case r.OfCustomToolCall != nil:
		return json.Marshal(r.OfCustomToolCall)
	case r.OfItemReference != nil:
		return json.Marshal(r.OfItemReference)
	default:
		return nil, errors.New("no input item to marshal")
	}
}

func (r *ResponseInputItemUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "message":
		// Check for id field to determine which type to unmarshal into
		// ResponseOutputMessage has id field (required property)
		if gjson.GetBytes(data, "id").Exists() {
			var om ResponseOutputMessage
			if err := json.Unmarshal(data, &om); err != nil {
				return err
			}
			r.OfOutputMessage = &om
			return nil
		}

		// Try ResponseInputItemMessageParam (has status field for tracking)
		var im ResponseInputItemMessageParam
		if err := json.Unmarshal(data, &im); err == nil {
			r.OfInputMessage = &im
			return nil
		}

		// Fall back to EasyInputMessageParam
		var msg EasyInputMessageParam
		if err := json.Unmarshal(data, &msg); err != nil {
			return err
		}
		r.OfMessage = &msg
	case "file_search_call":
		var fsc ResponseFileSearchToolCall
		if err := json.Unmarshal(data, &fsc); err != nil {
			return err
		}
		r.OfFileSearchCall = &fsc
	case "computer_call":
		var cc ResponseComputerToolCall
		if err := json.Unmarshal(data, &cc); err != nil {
			return err
		}
		r.OfComputerCall = &cc
	case "computer_call_output":
		var cco ResponseInputItemComputerCallOutputParam
		if err := json.Unmarshal(data, &cco); err != nil {
			return err
		}
		r.OfComputerCallOutput = &cco
	case "web_search_call":
		var wsc ResponseFunctionWebSearch
		if err := json.Unmarshal(data, &wsc); err != nil {
			return err
		}
		r.OfWebSearchCall = &wsc
	case "function_call":
		var fc ResponseFunctionToolCall
		if err := json.Unmarshal(data, &fc); err != nil {
			return err
		}
		r.OfFunctionCall = &fc
	case "function_call_output":
		var fco ResponseInputItemFunctionCallOutputParam
		if err := json.Unmarshal(data, &fco); err != nil {
			return err
		}
		r.OfFunctionCallOutput = &fco
	case "reasoning":
		var ri ResponseReasoningItem
		if err := json.Unmarshal(data, &ri); err != nil {
			return err
		}
		r.OfReasoning = &ri
	case "compaction":
		var ci ResponseCompactionItemParam
		if err := json.Unmarshal(data, &ci); err != nil {
			return err
		}
		r.OfCompaction = &ci
	case "image_generation_call":
		var igc ResponseInputItemImageGenerationCallParam
		if err := json.Unmarshal(data, &igc); err != nil {
			return err
		}
		r.OfImageGenerationCall = &igc
	case "code_interpreter_call":
		var cic ResponseCodeInterpreterToolCallParam
		if err := json.Unmarshal(data, &cic); err != nil {
			return err
		}
		r.OfCodeInterpreterCall = &cic
	case "local_shell_call":
		var lsc ResponseInputItemLocalShellCallParam
		if err := json.Unmarshal(data, &lsc); err != nil {
			return err
		}
		r.OfLocalShellCall = &lsc
	case "local_shell_call_output":
		var lsco ResponseInputItemLocalShellCallOutputParam
		if err := json.Unmarshal(data, &lsco); err != nil {
			return err
		}
		r.OfLocalShellCallOutput = &lsco
	case "shell_call":
		var sc ResponseInputItemShellCallParam
		if err := json.Unmarshal(data, &sc); err != nil {
			return err
		}
		r.OfShellCall = &sc
	case "shell_call_output":
		var sco ResponseInputItemShellCallOutputParam
		if err := json.Unmarshal(data, &sco); err != nil {
			return err
		}
		r.OfShellCallOutput = &sco
	case "apply_patch_call":
		var apc ResponseInputItemApplyPatchCallParam
		if err := json.Unmarshal(data, &apc); err != nil {
			return err
		}
		r.OfApplyPatchCall = &apc
	case "apply_patch_call_output":
		var apco ResponseInputItemApplyPatchCallOutputParam
		if err := json.Unmarshal(data, &apco); err != nil {
			return err
		}
		r.OfApplyPatchCallOutput = &apco
	case "mcp_list_tools":
		var mlt ResponseMcpListTools
		if err := json.Unmarshal(data, &mlt); err != nil {
			return err
		}
		r.OfMcpListTools = &mlt
	case "mcp_approval_request":
		var mar ResponseMcpApprovalRequest
		if err := json.Unmarshal(data, &mar); err != nil {
			return err
		}
		r.OfMcpApprovalRequest = &mar
	case "mcp_approval_response":
		var mar ResponseInputItemMcpApprovalResponseParam
		if err := json.Unmarshal(data, &mar); err != nil {
			return err
		}
		r.OfMcpApprovalResponse = &mar
	case "mcp_call":
		var mc ResponseMcpCall
		if err := json.Unmarshal(data, &mc); err != nil {
			return err
		}
		r.OfMcpCall = &mc
	case "custom_tool_call_output":
		var ctco ResponseCustomToolCallOutputParam
		if err := json.Unmarshal(data, &ctco); err != nil {
			return err
		}
		r.OfCustomToolCallOutput = &ctco
	case "custom_tool_call":
		var ctc ResponseCustomToolCall
		if err := json.Unmarshal(data, &ctc); err != nil {
			return err
		}
		r.OfCustomToolCall = &ctc
	case "item_reference":
		var ir ResponseInputItemItemReferenceParam
		if err := json.Unmarshal(data, &ir); err != nil {
			return err
		}
		r.OfItemReference = &ir
	// Add other cases here for different input item types as needed.
	default:
		return errors.New("cannot unmarshal unknown input type: " + typ.String())
	}
	return nil
}

// A message input to the model with a role indicating instruction following
// hierarchy. Instructions given with the `developer` or `system` role take
// precedence over instructions given with the `user` role. Messages with the
// `assistant` role are presumed to have been generated by the model in previous
// interactions.
//
// The properties Content, Role are required.
type EasyInputMessageParam struct {
	// Text, image, or audio input to the model, used to generate a response. Can also
	// contain previous assistant responses.
	Content EasyInputMessageContentUnionParam `json:"content,omitzero"`
	// The role of the message input. One of `user`, `assistant`, `system`, or
	// `developer`.
	//
	// Any of "user", "assistant", "system", "developer".
	Role string `json:"role,omitzero"`
	// The type of the message input. Always `message`.
	Type string `json:"type,omitzero"`
}

// EasyInputMessageContentUnionParam is a union type for different message content parameters.
// Only one field can be non-zero.
type EasyInputMessageContentUnionParam struct {
	OfString               *string
	OfInputItemContentList []ResponseInputContentUnionParam
}

func (r *EasyInputMessageContentUnionParam) UnmarshalJSON(data []byte) error {
	// Try string
	var s string
	if err := json.Unmarshal(data, &s); err == nil {
		r.OfString = &s
		r.OfInputItemContentList = nil
		return nil
	}

	// Try input item content list
	var items []ResponseInputContentUnionParam
	if err := json.Unmarshal(data, &items); err == nil {
		r.OfString = nil
		r.OfInputItemContentList = items
		return nil
	}

	return errors.New("content must be either a string or an array of input content items")
}

func (r EasyInputMessageContentUnionParam) MarshalJSON() ([]byte, error) {
	if r.OfString != nil {
		return json.Marshal(r.OfString)
	}
	if r.OfInputItemContentList != nil {
		return json.Marshal(r.OfInputItemContentList)
	}
	return nil, errors.New("no message content to marshal")
}

// ResponseInputContentUnionParam is a union type for different input content parameters.
// Only one field can be non-zero.
type ResponseInputContentUnionParam struct {
	OfInputText  *ResponseInputTextParam
	OfInputImage *ResponseInputImageParam
	OfInputFile  *ResponseInputFileParam
}

func (r ResponseInputContentUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfInputText != nil:
		return json.Marshal(r.OfInputText)
	case r.OfInputImage != nil:
		return json.Marshal(r.OfInputImage)
	case r.OfInputFile != nil:
		return json.Marshal(r.OfInputFile)
	default:
		return nil, errors.New("no input content to marshal")
	}
}

func (r *ResponseInputContentUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "input_text":
		var it ResponseInputTextParam
		if err := json.Unmarshal(data, &it); err != nil {
			return err
		}
		r.OfInputText = &it
	case "input_image":
		var ii ResponseInputImageParam
		if err := json.Unmarshal(data, &ii); err != nil {
			return err
		}
		r.OfInputImage = &ii
	case "input_file":
		var ifp ResponseInputFileParam
		if err := json.Unmarshal(data, &ifp); err != nil {
			return err
		}
		r.OfInputFile = &ifp
	default:
		return errors.New("unknown type for input content: " + typ.String())
	}
	return nil
}

// A message input to the model with a role indicating instruction following
// hierarchy. Instructions given with the `developer` or `system` role take
// precedence over instructions given with the `user` role.
//
// The properties Content, Role are required.
type ResponseInputItemMessageParam struct {
	// A list of one or many input items to the model, containing different content
	// types.
	Content []ResponseInputContentUnionParam `json:"content,omitzero"`
	// The role of the message input. One of `user`, `system`, or `developer`.
	//
	// Any of "user", "system", "developer".
	Role string `json:"role,omitzero"`
	// The status of item. One of `in_progress`, `completed`, or `incomplete`.
	// Populated when items are returned via API.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the message input. Always set to `message`.
	Type string `json:"type,omitzero"`
}

// An output message from the model.
//
// The properties ID, Content, Role, Status, Type are required.
type ResponseOutputMessage struct {
	// The unique ID of the output message.
	ID string `json:"id,omitzero"`
	// The content of the output message.
	Content []ResponseOutputMessageContentUnion `json:"content,omitzero"`
	// The status of the message input. One of `in_progress`, `completed`, or
	// `incomplete`. Populated when input items are returned via API.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The role of the output message. Always `assistant`.
	Role string `json:"role"`
	// The type of the output message. Always `message`.
	Type string `json:"type"`
}

// ResponseOutputMessageContentUnion is a union type for different output message content parameters.
// Only one field can be non-zero.
type ResponseOutputMessageContentUnion struct {
	OfOutputText *ResponseOutputTextParam
	OfRefusal    *ResponseOutputRefusalParam
}

func (r ResponseOutputMessageContentUnion) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfOutputText != nil:
		return json.Marshal(r.OfOutputText)
	case r.OfRefusal != nil:
		return json.Marshal(r.OfRefusal)
	default:
		return nil, errors.New("no output message content to marshal")
	}
}

func (r *ResponseOutputMessageContentUnion) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "output_text":
		var ot ResponseOutputTextParam
		if err := json.Unmarshal(data, &ot); err != nil {
			return err
		}
		r.OfOutputText = &ot
	case "refusal":
		var rf ResponseOutputRefusalParam
		if err := json.Unmarshal(data, &rf); err != nil {
			return err
		}
		r.OfRefusal = &rf
	default:
		return errors.New("unknown type for output message content: " + typ.String())
	}
	return nil
}

// A text output from the model.
//
// The properties Annotations, Text, Type are required.
type ResponseOutputTextParam struct {
	// The annotations of the text output.
	Annotations []ResponseOutputTextAnnotationUnionParam `json:"annotations,omitzero"`
	// The text output from the model.
	Text     string                           `json:"text"`
	Logprobs []ResponseOutputTextLogprobParam `json:"logprobs,omitzero"`
	// The type of the output text. Always `output_text`.
	Type string `json:"type"`
}

// The log probability of a token.
//
// The properties Token, Bytes, Logprob, TopLogprobs are required.
type ResponseOutputTextLogprobParam struct {
	Token       string                                     `json:"token"`
	Bytes       []int64                                    `json:"bytes,omitzero"`
	Logprob     float64                                    `json:"logprob"`
	TopLogprobs []ResponseOutputTextLogprobTopLogprobParam `json:"top_logprobs,omitzero"`
}

// The top log probability of a token.
//
// The properties Token, Bytes, Logprob are required.
type ResponseOutputTextLogprobTopLogprobParam struct {
	Token   string  `json:"token"`
	Bytes   []int64 `json:"bytes,omitzero"`
	Logprob float64 `json:"logprob"`
}

// ResponseOutputTextAnnotationUnionParam is a union type for different text annotation parameters.
// Only one field can be non-zero.
type ResponseOutputTextAnnotationUnionParam struct {
	OfFileCitation          *ResponseOutputTextAnnotationFileCitationParam
	OfURLCitation           *ResponseOutputTextAnnotationURLCitationParam
	OfContainerFileCitation *ResponseOutputTextAnnotationContainerFileCitationParam
	OfFilePath              *ResponseOutputTextAnnotationFilePathParam
}

func (r ResponseOutputTextAnnotationUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfFileCitation != nil:
		return json.Marshal(r.OfFileCitation)
	case r.OfURLCitation != nil:
		return json.Marshal(r.OfURLCitation)
	case r.OfContainerFileCitation != nil:
		return json.Marshal(r.OfContainerFileCitation)
	case r.OfFilePath != nil:
		return json.Marshal(r.OfFilePath)
	default:
		return nil, errors.New("no text annotation to marshal in output text annotation")
	}
}

func (r *ResponseOutputTextAnnotationUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "file_citation":
		var fc ResponseOutputTextAnnotationFileCitationParam
		if err := json.Unmarshal(data, &fc); err != nil {
			return err
		}
		r.OfFileCitation = &fc
	case "url_citation":
		var uc ResponseOutputTextAnnotationURLCitationParam
		if err := json.Unmarshal(data, &uc); err != nil {
			return err
		}
		r.OfURLCitation = &uc
	case "container_file_citation":
		var cfc ResponseOutputTextAnnotationContainerFileCitationParam
		if err := json.Unmarshal(data, &cfc); err != nil {
			return err
		}
		r.OfContainerFileCitation = &cfc
	case "file_path":
		var fp ResponseOutputTextAnnotationFilePathParam
		if err := json.Unmarshal(data, &fp); err != nil {
			return err
		}
		r.OfFilePath = &fp
	default:
		return errors.New("unknown type for output text annotation: " + typ.String())
	}
	return nil
}

// A citation to a file.
//
// The properties FileID, Filename, Index, Type are required.
type ResponseOutputTextAnnotationFileCitationParam struct {
	// The ID of the file.
	FileID string `json:"file_id"`
	// The filename of the file cited.
	Filename string `json:"filename"`
	// The index of the file in the list of files.
	Index int64 `json:"index"`
	// The type of the file citation. Always `file_citation`.
	Type string `json:"type"`
}

// A citation for a web resource used to generate a model response.
//
// The properties EndIndex, StartIndex, Title, Type, URL are required.
type ResponseOutputTextAnnotationURLCitationParam struct {
	// The index of the last character of the URL citation in the message.
	EndIndex int64 `json:"end_index"`
	// The index of the first character of the URL citation in the message.
	StartIndex int64 `json:"start_index"`
	// The title of the web resource.
	Title string `json:"title"`
	// The URL of the web resource.
	URL string `json:"url"`
	// The type of the URL citation. Always `url_citation`.
	Type string `json:"type"`
}

// A citation for a container file used to generate a model response.
//
// The properties ContainerID, EndIndex, FileID, Filename, StartIndex, Type are
// required.
type ResponseOutputTextAnnotationContainerFileCitationParam struct {
	// The ID of the container file.
	ContainerID string `json:"container_id"`
	// The index of the last character of the container file citation in the message.
	EndIndex int64 `json:"end_index"`
	// The ID of the file.
	FileID string `json:"file_id"`
	// The filename of the container file cited.
	Filename string `json:"filename"`
	// The index of the first character of the container file citation in the message.
	StartIndex int64 `json:"start_index"`
	// The type of the container file citation. Always `container_file_citation`.
	Type string `json:"type"`
}

// A path to a file.
//
// The properties FileID, Index, Type are required.
type ResponseOutputTextAnnotationFilePathParam struct {
	// The ID of the file.
	FileID string `json:"file_id"`
	// The index of the file in the list of files.
	Index int64 `json:"index"`
	// The type of the file path. Always `file_path`.
	Type string `json:"type"`
}

// A refusal from the model.
//
// The properties Refusal, Type are required.
type ResponseOutputRefusalParam struct {
	// The refusal explanation from the model.
	Refusal string `json:"refusal"`
	// The type of the refusal. Always `refusal`.
	Type string `json:"type"`
}

// The results of a file search tool call. See the
// [file search guide](https://platform.openai.com/docs/guides/tools-file-search)
// for more information.
//
// The properties ID, Queries, Status, Type are required.
type ResponseFileSearchToolCall struct {
	// The unique ID of the file search tool call.
	ID string `json:"id"`
	// The queries used to search for files.
	Queries []string `json:"queries,omitzero"`
	// The status of the file search tool call. One of `in_progress`, `searching`,
	// `incomplete` or `failed`,
	//
	// Any of "in_progress", "searching", "completed", "incomplete", "failed".
	Status string `json:"status,omitzero"`
	// The results of the file search tool call.
	Results []ResponseFileSearchToolCallResultParam `json:"results,omitzero"`
	// The type of the file search tool call. Always `file_search_call`.
	Type string `json:"type"`
}

type ResponseFileSearchToolCallResultParam struct {
	// The unique ID of the file.
	FileID string `json:"file_id,omitzero"`
	// The name of the file.
	Filename string `json:"filename,omitzero"`
	// The relevance score of the file - a value between 0 and 1.
	Score *float64 `json:"score,omitempty"`
	// The text that was retrieved from the file.
	Text string `json:"text,omitzero"`
	// Set of 16 key-value pairs that can be attached to an object. This can be useful
	// for storing additional information about the object in a structured format, and
	// querying for objects via API or the dashboard. Keys are strings with a maximum
	// length of 64 characters. Values are strings with a maximum length of 512
	// characters, booleans, or numbers.
	Attributes map[string]ResponseFileSearchToolCallResultAttributeUnionParam `json:"attributes,omitzero"`
}

// ResponseFileSearchToolCallResultAttributeUnionParam is a union type for different file search tool call result attribute parameters.
// Only one field can be non-zero.
type ResponseFileSearchToolCallResultAttributeUnionParam struct {
	OfString *string
	OfFloat  *float64
	OfBool   *bool
}

func (r ResponseFileSearchToolCallResultAttributeUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfString != nil:
		return json.Marshal(r.OfString)
	case r.OfFloat != nil:
		return json.Marshal(r.OfFloat)
	case r.OfBool != nil:
		return json.Marshal(r.OfBool)
	default:
		return nil, errors.New("no attribute to marshal in response file search tool call result")
	}
}

func (r *ResponseFileSearchToolCallResultAttributeUnionParam) UnmarshalJSON(data []byte) error {
	// Try string
	var s string
	if err := json.Unmarshal(data, &s); err == nil {
		r.OfString = &s
		return nil
	}

	// Try float
	var f float64
	if err := json.Unmarshal(data, &f); err == nil {
		r.OfFloat = &f
		return nil
	}

	// Try bool
	var b bool
	if err := json.Unmarshal(data, &b); err == nil {
		r.OfBool = &b
		return nil
	}

	return errors.New("unknown attribute type in response file search tool call result")
}

// A tool call to a computer use tool. See the
// [computer use guide](https://platform.openai.com/docs/guides/tools-computer-use)
// for more information.
//
// The properties ID, Action, CallID, PendingSafetyChecks, Status, Type are
// required.
type ResponseComputerToolCall struct {
	// The unique ID of the computer call.
	ID string `json:"id"`
	// A click action.
	Action ResponseComputerToolCallActionUnionParam `json:"action,omitzero"`
	// An identifier used when responding to the tool call with output.
	CallID string `json:"call_id"`
	// The pending safety checks for the computer call.
	PendingSafetyChecks []ResponseComputerToolCallPendingSafetyCheckParam `json:"pending_safety_checks,omitzero"`
	// The status of the item. One of `in_progress`, `completed`, or `incomplete`.
	// Populated when items are returned via API.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the computer call. Always `computer_call`.
	Type string `json:"type,omitzero"`
}

// ResponseComputerToolCallActionUnionParam is a union type for different computer tool call action parameters.
// Only one field can be non-zero.
type ResponseComputerToolCallActionUnionParam struct {
	OfClick       *ResponseComputerToolCallActionClickParam
	OfDoubleClick *ResponseComputerToolCallActionDoubleClickParam
	OfDrag        *ResponseComputerToolCallActionDragParam
	OfKeypress    *ResponseComputerToolCallActionKeypressParam
	OfMove        *ResponseComputerToolCallActionMoveParam
	OfScreenshot  *ResponseComputerToolCallActionScreenshotParam
	OfScroll      *ResponseComputerToolCallActionScrollParam
	OfType        *ResponseComputerToolCallActionTypeParam
	OfWait        *ResponseComputerToolCallActionWaitParam
}

func (r ResponseComputerToolCallActionUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfClick != nil:
		return json.Marshal(r.OfClick)
	case r.OfDoubleClick != nil:
		return json.Marshal(r.OfDoubleClick)
	case r.OfDrag != nil:
		return json.Marshal(r.OfDrag)
	case r.OfKeypress != nil:
		return json.Marshal(r.OfKeypress)
	case r.OfMove != nil:
		return json.Marshal(r.OfMove)
	case r.OfScreenshot != nil:
		return json.Marshal(r.OfScreenshot)
	case r.OfScroll != nil:
		return json.Marshal(r.OfScroll)
	case r.OfType != nil:
		return json.Marshal(r.OfType)
	case r.OfWait != nil:
		return json.Marshal(r.OfWait)
	default:
		return nil, errors.New("no computer tool call action to marshal in computer tool call action")
	}
}

func (r *ResponseComputerToolCallActionUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "click":
		var c ResponseComputerToolCallActionClickParam
		if err := json.Unmarshal(data, &c); err != nil {
			return err
		}
		r.OfClick = &c
	case "double_click":
		var dc ResponseComputerToolCallActionDoubleClickParam
		if err := json.Unmarshal(data, &dc); err != nil {
			return err
		}
		r.OfDoubleClick = &dc
	case "drag":
		var d ResponseComputerToolCallActionDragParam
		if err := json.Unmarshal(data, &d); err != nil {
			return err
		}
		r.OfDrag = &d
	case "keypress":
		var k ResponseComputerToolCallActionKeypressParam
		if err := json.Unmarshal(data, &k); err != nil {
			return err
		}
		r.OfKeypress = &k
	case "move":
		var m ResponseComputerToolCallActionMoveParam
		if err := json.Unmarshal(data, &m); err != nil {
			return err
		}
		r.OfMove = &m
	case "screenshot":
		var s ResponseComputerToolCallActionScreenshotParam
		if err := json.Unmarshal(data, &s); err != nil {
			return err
		}
		r.OfScreenshot = &s
	case "scroll":
		var s ResponseComputerToolCallActionScrollParam
		if err := json.Unmarshal(data, &s); err != nil {
			return err
		}
		r.OfScroll = &s
	case "type":
		var t ResponseComputerToolCallActionTypeParam
		if err := json.Unmarshal(data, &t); err != nil {
			return err
		}
		r.OfType = &t
	case "wait":
		var w ResponseComputerToolCallActionWaitParam
		if err := json.Unmarshal(data, &w); err != nil {
			return err
		}
		r.OfWait = &w
	default:
		return errors.New("unknown type for computer tool call action: " + typ.String())
	}
	return nil
}

// A click action.
//
// The properties Button, Type, X, Y are required.
type ResponseComputerToolCallActionClickParam struct {
	// Indicates which mouse button was pressed during the click. One of `left`,
	// `right`, `wheel`, `back`, or `forward`.
	//
	// Any of "left", "right", "wheel", "back", "forward".
	Button string `json:"button,omitzero"`
	// The x-coordinate where the click occurred.
	X int64 `json:"x"`
	// The y-coordinate where the click occurred.
	Y int64 `json:"y"`
	// Specifies the event type. For a click action, this property is always `click`.
	Type string `json:"type"`
}

// A double click action.
//
// The properties Type, X, Y are required.
type ResponseComputerToolCallActionDoubleClickParam struct {
	// The x-coordinate where the double click occurred.
	X int64 `json:"x"`
	// The y-coordinate where the double click occurred.
	Y int64 `json:"y"`
	// Specifies the event type. For a double click action, this property is always set
	// to `double_click`.
	Type string `json:"type"`
}

// A drag action.
//
// The properties Path, Type are required.
type ResponseComputerToolCallActionDragParam struct {
	// An array of coordinates representing the path of the drag action. Coordinates
	// will appear as an array of objects, eg
	//
	// ```
	// [
	//
	//	{ x: 100, y: 200 },
	//	{ x: 200, y: 300 }
	//
	// ]
	// ```
	Path []ResponseComputerToolCallActionDragPathParam `json:"path,omitzero"`
	// Specifies the event type. For a drag action, this property is always set to
	// `drag`.
	Type string `json:"type"`
}

// An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.
//
// The properties X, Y are required.
type ResponseComputerToolCallActionDragPathParam struct {
	// The x-coordinate.
	X int64 `json:"x"`
	// The y-coordinate.
	Y int64 `json:"y"`
}

// A collection of keypresses the model would like to perform.
//
// The properties Keys, Type are required.
type ResponseComputerToolCallActionKeypressParam struct {
	// The combination of keys the model is requesting to be pressed. This is an array
	// of strings, each representing a key.
	Keys []string `json:"keys,omitzero"`
	// Specifies the event type. For a keypress action, this property is always set to
	// `keypress`.
	Type string `json:"type"`
}

// A mouse move action.
//
// The properties Type, X, Y are required.
type ResponseComputerToolCallActionMoveParam struct {
	// The x-coordinate to move to.
	X int64 `json:"x"`
	// The y-coordinate to move to.
	Y int64 `json:"y"`
	// Specifies the event type. For a move action, this property is always set to
	// `move`.
	Type string `json:"type"`
}

// A screenshot action.
type ResponseComputerToolCallActionScreenshotParam struct {
	// Specifies the event type. For a screenshot action, this property is always set
	// to `screenshot`.
	Type string `json:"type"`
}

// A scroll action.
//
// The properties ScrollX, ScrollY, Type, X, Y are required.
type ResponseComputerToolCallActionScrollParam struct {
	// The horizontal scroll distance.
	ScrollX int64 `json:"scroll_x"`
	// The vertical scroll distance.
	ScrollY int64 `json:"scroll_y"`
	// The x-coordinate where the scroll occurred.
	X int64 `json:"x"`
	// The y-coordinate where the scroll occurred.
	Y int64 `json:"y"`
	// Specifies the event type. For a scroll action, this property is always set to
	// `scroll`.
	Type string `json:"type"`
}

// An action to type in text.
//
// The properties Text, Type are required.
type ResponseComputerToolCallActionTypeParam struct {
	// The text to type.
	Text string `json:"text"`
	// Specifies the event type. For a type action, this property is always set to
	// `type`.
	Type string `json:"type"`
}

// A wait action.
//
// This struct has a constant value, construct it with
// [NewResponseComputerToolCallActionWaitParam].
type ResponseComputerToolCallActionWaitParam struct {
	// Specifies the event type. For a wait action, this property is always set to
	// `wait`.
	Type string `json:"type"`
}

// A pending safety check for the computer call.
//
// The property ID is required.
type ResponseComputerToolCallPendingSafetyCheckParam struct {
	// The ID of the pending safety check.
	ID string `json:"id"`
	// The type of the pending safety check.
	Code string `json:"code,omitzero"`
	// Details about the pending safety check.
	Message string `json:"message,omitzero"`
}

// The output of a computer tool call.
//
// The properties CallID, Output, Type are required.
type ResponseInputItemComputerCallOutputParam struct {
	// The ID of the computer tool call that produced the output.
	CallID string `json:"call_id"`
	// A computer screenshot image used with the computer use tool.
	Output ResponseComputerToolCallOutputScreenshotParam `json:"output,omitzero"`
	// The ID of the computer tool call output.
	ID string `json:"id,omitzero"`
	// The safety checks reported by the API that have been acknowledged by the
	// developer.
	AcknowledgedSafetyChecks []ResponseInputItemComputerCallOutputAcknowledgedSafetyCheckParam `json:"acknowledged_safety_checks,omitzero"`
	// The status of the message input. One of `in_progress`, `completed`, or
	// `incomplete`. Populated when input items are returned via API.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the computer tool call output. Always `computer_call_output`.
	Type string `json:"type"`
}

// A computer screenshot image used with the computer use tool.
//
// The property Type is required.
type ResponseComputerToolCallOutputScreenshotParam struct {
	// The identifier of an uploaded file that contains the screenshot.
	FileID string `json:"file_id,omitzero"`
	// The URL of the screenshot image.
	ImageURL string `json:"image_url,omitzero"`
	// Specifies the event type. For a computer screenshot, this property is always set
	// to `computer_screenshot`.
	Type string `json:"type"`
}

// A pending safety check for the computer call.
//
// The property ID is required.
type ResponseInputItemComputerCallOutputAcknowledgedSafetyCheckParam struct {
	// The ID of the pending safety check.
	ID string `json:"id"`
	// The type of the pending safety check.
	Code string `json:"code,omitzero"`
	// Details about the pending safety check.
	Message string `json:"message,omitzero"`
}

// The results of a web search tool call. See the
// [web search guide](https://platform.openai.com/docs/guides/tools-web-search) for
// more information.
//
// The properties ID, Action, Status, Type are required.
type ResponseFunctionWebSearch struct {
	// The unique ID of the web search tool call.
	ID string `json:"id"`
	// An object describing the specific action taken in this web search call. Includes
	// details on how the model used the web (search, open_page, find).
	Action ResponseFunctionWebSearchActionUnionParam `json:"action,omitzero"`
	// The status of the web search tool call.
	//
	// Any of "in_progress", "searching", "completed", "failed".
	Status string `json:"status,omitzero"`
	// The type of the web search tool call. Always `web_search_call`.
	Type string `json:"type"`
}

// ResponseFunctionWebSearchActionUnionParam is a union type for different web search action parameters.
// Only one field can be non-zero.
type ResponseFunctionWebSearchActionUnionParam struct {
	OfSearch   *ResponseFunctionWebSearchActionSearchParam
	OfOpenPage *ResponseFunctionWebSearchActionOpenPageParam
	OfFind     *ResponseFunctionWebSearchActionFindParam
}

func (r ResponseFunctionWebSearchActionUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfSearch != nil:
		return json.Marshal(r.OfSearch)
	case r.OfOpenPage != nil:
		return json.Marshal(r.OfOpenPage)
	case r.OfFind != nil:
		return json.Marshal(r.OfFind)
	default:
		return nil, errors.New("no web search action to marshal in websearch action")
	}
}

func (r *ResponseFunctionWebSearchActionUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "search":
		var s ResponseFunctionWebSearchActionSearchParam
		if err := json.Unmarshal(data, &s); err != nil {
			return err
		}
		r.OfSearch = &s
	case "open_page":
		var op ResponseFunctionWebSearchActionOpenPageParam
		if err := json.Unmarshal(data, &op); err != nil {
			return err
		}
		r.OfOpenPage = &op
	case "find":
		var f ResponseFunctionWebSearchActionFindParam
		if err := json.Unmarshal(data, &f); err != nil {
			return err
		}
		r.OfFind = &f
	default:
		return errors.New("unknown type for websearch action: " + typ.String())
	}
	return nil
}

// Action type "search" - Performs a web search query.
//
// The properties Query, Type are required.
type ResponseFunctionWebSearchActionSearchParam struct {
	// The search query.
	Query string `json:"query"`
	// The sources used in the search.
	Sources []ResponseFunctionWebSearchActionSearchSourceParam `json:"sources,omitzero"`
	// The action type. Always "search".
	Type string `json:"type"`
}

// A source used in the search.
//
// The properties Type, URL are required.
type ResponseFunctionWebSearchActionSearchSourceParam struct {
	// The URL of the source.
	URL string `json:"url"`
	// The type of source. Always `url`.
	Type string `json:"type"`
}

// Action type "open_page" - Opens a specific URL from search results.
//
// The properties Type, URL are required.
type ResponseFunctionWebSearchActionOpenPageParam struct {
	// The URL opened by the model.
	URL string `json:"url"`
	// The action type. Always "open_page".
	Type string `json:"type"`
}

// Action type "find": Searches for a pattern within a loaded page.
//
// The properties Pattern, Type, URL are required.
type ResponseFunctionWebSearchActionFindParam struct {
	// The pattern or text to search for within the page.
	Pattern string `json:"pattern"`
	// The URL of the page searched for the pattern.
	URL string `json:"url"`
	// The action type.
	Type string `json:"type"`
}

// A tool call to run a function. See the
// [function calling guide](https://platform.openai.com/docs/guides/function-calling)
// for more information.
//
// The properties Arguments, CallID, Name, Type are required.
type ResponseFunctionToolCall struct {
	// A JSON string of the arguments to pass to the function.
	Arguments string `json:"arguments"`
	// The unique ID of the function tool call generated by the model.
	CallID string `json:"call_id"`
	// The name of the function to run.
	Name string `json:"name"`
	// The unique ID of the function tool call.
	ID string `json:"id,omitzero"`
	// The status of the item. One of `in_progress`, `completed`, or `incomplete`.
	// Populated when items are returned via API.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the function tool call. Always `function_call`.
	Type string `json:"type"`
}

// The output of a function tool call.
//
// The properties CallID, Output, Type are required.
type ResponseInputItemFunctionCallOutputParam struct {
	// The unique ID of the function tool call generated by the model.
	CallID string `json:"call_id"`
	// Text, image, or file output of the function tool call.
	Output ResponseInputItemFunctionCallOutputOutputUnionParam `json:"output,omitzero"`
	// The unique ID of the function tool call output. Populated when this item is
	// returned via API.
	ID string `json:"id,omitzero"`
	// The status of the item. One of `in_progress`, `completed`, or `incomplete`.
	// Populated when items are returned via API.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the function tool call output. Always `function_call_output`.
	Type string `json:"type"`
}

// ResponseInputItemFunctionCallOutputOutputUnionParam is a union type for different function call output parameters.
// Only one field can be non-zero.
type ResponseInputItemFunctionCallOutputOutputUnionParam struct {
	OfString                              *string
	OfResponseFunctionCallOutputItemArray []ResponseFunctionCallOutputItemUnionParam
}

func (r ResponseInputItemFunctionCallOutputOutputUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfString != nil:
		return json.Marshal(r.OfString)
	case r.OfResponseFunctionCallOutputItemArray != nil:
		return json.Marshal(r.OfResponseFunctionCallOutputItemArray)
	default:
		return nil, errors.New("no function call output to marshal in input item function call output")
	}
}

func (r *ResponseInputItemFunctionCallOutputOutputUnionParam) UnmarshalJSON(data []byte) error {
	switch data[0] {
	case '"':
		var s string
		if err := json.Unmarshal(data, &s); err != nil {
			return err
		}
		r.OfString = &s
	case '[':
		var arr []ResponseFunctionCallOutputItemUnionParam
		if err := json.Unmarshal(data, &arr); err != nil {
			return err
		}
		r.OfResponseFunctionCallOutputItemArray = arr
	default:
		return errors.New("unknown type for function call output in input item function call output")
	}
	return nil
}

// ResponseFunctionCallOutputItemUnionParam is a union type for different function call output item parameters.
// Only one field can be non-zero.
type ResponseFunctionCallOutputItemUnionParam struct {
	OfInputText  *ResponseInputTextContentParam
	OfInputImage *ResponseInputImageContentParam
	OfInputFile  *ResponseInputFileContentParam
}

func (r ResponseFunctionCallOutputItemUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfInputText != nil:
		return json.Marshal(r.OfInputText)
	case r.OfInputImage != nil:
		return json.Marshal(r.OfInputImage)
	case r.OfInputFile != nil:
		return json.Marshal(r.OfInputFile)
	default:
		return nil, errors.New("no function call output item to marshal in function call output item")
	}
}

func (r *ResponseFunctionCallOutputItemUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "input_text":
		var it ResponseInputTextContentParam
		if err := json.Unmarshal(data, &it); err != nil {
			return err
		}
		r.OfInputText = &it
	case "input_image":
		var ii ResponseInputImageContentParam
		if err := json.Unmarshal(data, &ii); err != nil {
			return err
		}
		r.OfInputImage = &ii
	case "input_file":
		var ifp ResponseInputFileContentParam
		if err := json.Unmarshal(data, &ifp); err != nil {
			return err
		}
		r.OfInputFile = &ifp
	default:
		return errors.New("unknown type for function call output item: " + typ.String())
	}
	return nil
}

// A text input to the model.
//
// The properties Text, Type are required.
type ResponseInputTextContentParam struct {
	// The text input to the model.
	Text string `json:"text"`
	// The type of the input item. Always `input_text`.
	Type string `json:"type"`
}

// An image input to the model. Learn about
// [image inputs](https://platform.openai.com/docs/guides/vision)
//
// The property Type is required.
type ResponseInputImageContentParam struct {
	// The ID of the file to be sent to the model.
	FileID string `json:"file_id,omitzero"`
	// The URL of the image to be sent to the model. A fully qualified URL or base64
	// encoded image in a data URL.
	ImageURL string `json:"image_url,omitzero"`
	// The detail level of the image to be sent to the model. One of `high`, `low`, or
	// `auto`. Defaults to `auto`.
	//
	// Any of "low", "high", "auto".
	Detail string `json:"detail,omitzero"`
	// The type of the input item. Always `input_image`.
	Type string `json:"type"`
}

// A file input to the model.
//
// The property Type is required.
type ResponseInputFileContentParam struct {
	// The base64-encoded data of the file to be sent to the model.
	FileData string `json:"file_data,omitzero"`
	// The ID of the file to be sent to the model.
	FileID string `json:"file_id,omitzero"`
	// The URL of the file to be sent to the model.
	FileURL string `json:"file_url,omitzero"`
	// The name of the file to be sent to the model.
	Filename string `json:"filename,omitzero"`
	// The type of the input item. Always `input_file`.
	Type string `json:"type"`
}

// A description of the chain of thought used by a reasoning model while generating
// a response. Be sure to include these items in your `input` to the Responses API
// for subsequent turns of a conversation if you are manually
// [managing context](https://platform.openai.com/docs/guides/conversation-state).
//
// The properties ID, Summary, Type are required.
type ResponseReasoningItem struct {
	// The unique identifier of the reasoning content.
	ID string `json:"id"`
	// Reasoning summary content.
	Summary []ResponseReasoningItemSummaryParam `json:"summary,omitzero"`
	// The encrypted content of the reasoning item - populated when a response is
	// generated with `reasoning.encrypted_content` in the `include` parameter.
	EncryptedContent string `json:"encrypted_content,omitzero"`
	// Reasoning text content.
	Content []ResponseReasoningItemContentParam `json:"content,omitzero"`
	// The status of the item. One of `in_progress`, `completed`, or `incomplete`.
	// Populated when items are returned via API.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the object. Always `reasoning`.
	Type string `json:"type"`
}

// A summary text from the model.
//
// The properties Text, Type are required.
type ResponseReasoningItemSummaryParam struct {
	// A summary of the reasoning output from the model so far.
	Text string `json:"text"`
	// The type of the object. Always `summary_text`.
	Type string `json:"type"`
}

// Reasoning text from the model.
//
// The properties Text, Type are required.
type ResponseReasoningItemContentParam struct {
	// The reasoning text from the model.
	Text string `json:"text"`
	// The type of the reasoning text. Always `reasoning_text`.
	Type string `json:"type"`
}

// A compaction item generated by the
// [`v1/responses/compact` API](https://platform.openai.com/docs/api-reference/responses/compact).
//
// The properties EncryptedContent, Type are required.
type ResponseCompactionItemParam struct {
	EncryptedContent string `json:"encrypted_content"`
	// The ID of the compaction item.
	ID string `json:"id,omitzero"`
	// The type of the item. Always `compaction`.
	Type string `json:"type"`
}

// An image generation request made by the model.
//
// The properties ID, Result, Status, Type are required.
type ResponseInputItemImageGenerationCallParam struct {
	// The generated image encoded in base64.
	Result string `json:"result,omitzero"`
	// The unique ID of the image generation call.
	ID string `json:"id"`
	// The status of the image generation call.
	//
	// Any of "in_progress", "completed", "generating", "failed".
	Status string `json:"status,omitzero"`
	// The type of the image generation call. Always `image_generation_call`.
	Type string `json:"type"`
}

// A tool call to run code.
//
// The properties ID, Code, ContainerID, Outputs, Status, Type are required.
type ResponseCodeInterpreterToolCallParam struct {
	// The code to run, or null if not available.
	Code string `json:"code,omitzero"`
	// The outputs generated by the code interpreter, such as logs or images. Can be
	// null if no outputs are available.
	Outputs []ResponseCodeInterpreterToolCallOutputUnionParam `json:"outputs,omitzero"`
	// The unique ID of the code interpreter tool call.
	ID string `json:"id"`
	// The ID of the container used to run the code.
	ContainerID string `json:"container_id"`
	// The status of the code interpreter tool call. Valid values are `in_progress`,
	// `completed`, `incomplete`, `interpreting`, and `failed`.
	//
	// Any of "in_progress", "completed", "incomplete", "interpreting", "failed".
	Status string `json:"status,omitzero"`
	// The type of the code interpreter tool call. Always `code_interpreter_call`.
	Type string `json:"type"`
}

// ResponseCodeInterpreterToolCallOutputUnionParam is a union type for different code interpreter tool call output parameters.
// Only one field can be non-zero.
type ResponseCodeInterpreterToolCallOutputUnionParam struct {
	OfLogs  *ResponseCodeInterpreterToolCallOutputLogsParam
	OfImage *ResponseCodeInterpreterToolCallOutputImageParam
}

func (r ResponseCodeInterpreterToolCallOutputUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfLogs != nil:
		return json.Marshal(r.OfLogs)
	case r.OfImage != nil:
		return json.Marshal(r.OfImage)
	default:
		return nil, errors.New("no code interpreter tool call output to marshal")
	}
}

func (r *ResponseCodeInterpreterToolCallOutputUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "logs":
		var logs ResponseCodeInterpreterToolCallOutputLogsParam
		if err := json.Unmarshal(data, &logs); err != nil {
			return err
		}
		r.OfLogs = &logs
	case "image":
		var image ResponseCodeInterpreterToolCallOutputImageParam
		if err := json.Unmarshal(data, &image); err != nil {
			return err
		}
		r.OfImage = &image
	default:
		return errors.New("unknown type for code interpreter tool call output: " + typ.String())
	}
	return nil
}

// The logs output from the code interpreter.
//
// The properties Logs, Type are required.
type ResponseCodeInterpreterToolCallOutputLogsParam struct {
	// The logs output from the code interpreter.
	Logs string `json:"logs"`
	// The type of the output. Always `logs`.
	Type string `json:"type"`
}

// The image output from the code interpreter.
//
// The properties Type, URL are required.
type ResponseCodeInterpreterToolCallOutputImageParam struct {
	// The URL of the image output from the code interpreter.
	URL string `json:"url"`
	// The type of the output. Always `image`.
	Type string `json:"type"`
}

// A tool call to run a command on the local shell.
//
// The properties ID, Action, CallID, Status, Type are required.
type ResponseInputItemLocalShellCallParam struct {
	// The unique ID of the local shell call.
	ID string `json:"id"`
	// Execute a shell command on the server.
	Action ResponseInputItemLocalShellCallActionParam `json:"action,omitzero"`
	// The unique ID of the local shell tool call generated by the model.
	CallID string `json:"call_id"`
	// The status of the local shell call.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the local shell call. Always `local_shell_call`.
	Type string `json:"type"`
}

// Execute a shell command on the server.
//
// The properties Command, Env, Type are required.
type ResponseInputItemLocalShellCallActionParam struct {
	// The command to run.
	Command []string `json:"command,omitzero"`
	// Environment variables to set for the command.
	Env map[string]string `json:"env,omitzero"`
	// Optional timeout in milliseconds for the command.
	TimeoutMs int64 `json:"timeout_ms,omitzero"`
	// Optional user to run the command as.
	User string `json:"user,omitzero"`
	// Optional working directory to run the command in.
	WorkingDirectory string `json:"working_directory,omitzero"`
	// The type of the local shell action. Always `exec`.
	Type string `json:"type"`
}

// The output of a local shell tool call.
//
// The properties ID, Output, Type are required.
type ResponseInputItemLocalShellCallOutputParam struct {
	// The unique ID of the local shell tool call generated by the model.
	ID string `json:"id"`
	// A JSON string of the output of the local shell tool call.
	Output string `json:"output"`
	// The status of the item. One of `in_progress`, `completed`, or `incomplete`.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the local shell tool call output. Always `local_shell_call_output`.
	Type string `json:"type"`
}

// A tool representing a request to execute one or more shell commands.
//
// The properties Action, CallID, Type are required.
type ResponseInputItemShellCallParam struct {
	// The shell commands and limits that describe how to run the tool call.
	Action ResponseInputItemShellCallActionParam `json:"action,omitzero"`
	// The unique ID of the shell tool call generated by the model.
	CallID string `json:"call_id"`
	// The unique ID of the shell tool call. Populated when this item is returned via
	// API.
	ID string `json:"id,omitzero"`
	// The status of the shell call. One of `in_progress`, `completed`, or
	// `incomplete`.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status,omitzero"`
	// The type of the item. Always `shell_call`.
	Type string `json:"type"`
}

// The shell commands and limits that describe how to run the tool call.
//
// The property Commands is required.
type ResponseInputItemShellCallActionParam struct {
	// Ordered shell commands for the execution environment to run.
	Commands []string `json:"commands,omitzero"`
	// Maximum number of UTF-8 characters to capture from combined stdout and stderr
	// output.
	MaxOutputLength int64 `json:"max_output_length,omitzero"`
	// Maximum wall-clock time in milliseconds to allow the shell commands to run.
	TimeoutMs int64 `json:"timeout_ms,omitzero"`
}

// The streamed output items emitted by a shell tool call.
//
// The properties CallID, Output, Type are required.
type ResponseInputItemShellCallOutputParam struct {
	// The unique ID of the shell tool call generated by the model.
	CallID string `json:"call_id"`
	// Captured chunks of stdout and stderr output, along with their associated
	// outcomes.
	Output []ResponseFunctionShellCallOutputContentParam `json:"output,omitzero"`
	// The unique ID of the shell tool call output. Populated when this item is
	// returned via API.
	ID string `json:"id,omitzero"`
	// The maximum number of UTF-8 characters captured for this shell call's combined
	// output.
	MaxOutputLength *int64 `json:"max_output_length,omitempty"`
	// The type of the item. Always `shell_call_output`.
	Type string `json:"type"`
}

// Captured stdout and stderr for a portion of a shell tool call output.
//
// The properties Outcome, Stderr, Stdout are required.
type ResponseFunctionShellCallOutputContentParam struct {
	// The exit or timeout outcome associated with this shell call.
	Outcome ResponseFunctionShellCallOutputContentOutcomeUnionParam `json:"outcome,omitzero"`
	// Captured stderr output for the shell call.
	Stderr string `json:"stderr"`
	// Captured stdout output for the shell call.
	Stdout string `json:"stdout"`
}

// ResponseFunctionShellCallOutputContentOutcomeUnionParam is a union type for different shell call output content
// outcome parameters.
// Only one field can be non-zero.
type ResponseFunctionShellCallOutputContentOutcomeUnionParam struct {
	OfTimeout *ResponseFunctionShellCallOutputContentOutcomeTimeoutParam
	OfExit    *ResponseFunctionShellCallOutputOutputContentOutcomeExitParam
}

func (r ResponseFunctionShellCallOutputContentOutcomeUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfTimeout != nil:
		return json.Marshal(r.OfTimeout)
	case r.OfExit != nil:
		return json.Marshal(r.OfExit)
	default:
		return nil, errors.New("no shell call output content outcome to marshal")
	}
}

func (r *ResponseFunctionShellCallOutputContentOutcomeUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "timeout":
		var to ResponseFunctionShellCallOutputContentOutcomeTimeoutParam
		if err := json.Unmarshal(data, &to); err != nil {
			return err
		}
		r.OfTimeout = &to
	case "exit":
		var eo ResponseFunctionShellCallOutputOutputContentOutcomeExitParam
		if err := json.Unmarshal(data, &eo); err != nil {
			return err
		}
		r.OfExit = &eo
	default:
		return errors.New("unknown type for function shell call output content outcome: " + typ.String())
	}
	return nil
}

// Indicates that the shell call exceeded its configured time limit.
type ResponseFunctionShellCallOutputContentOutcomeTimeoutParam struct {
	// The outcome type. Always `timeout`.
	Type string `json:"type"`
}

// Indicates that the shell commands finished and returned an exit code.
//
// The properties ExitCode, Type are required.
type ResponseFunctionShellCallOutputOutputContentOutcomeExitParam struct {
	// The exit code returned by the shell process.
	ExitCode int64 `json:"exit_code"`
	// The outcome type. Always `exit`.
	Type string `json:"type"`
}

// A tool call representing a request to create, delete, or update files using diff
// patches.
//
// The properties CallID, Operation, Status, Type are required.
type ResponseInputItemApplyPatchCallParam struct {
	// The unique ID of the apply patch tool call generated by the model.
	CallID string `json:"call_id"`
	// The specific create, delete, or update instruction for the apply_patch tool
	// call.
	Operation ResponseInputItemApplyPatchCallOperationUnionParam `json:"operation,omitzero"`
	// The status of the apply patch tool call. One of `in_progress` or `completed`.
	//
	// Any of "in_progress", "completed".
	Status string `json:"status,omitzero"`
	// The unique ID of the apply patch tool call. Populated when this item is returned
	// via API.
	ID string `json:"id,omitzero"`
	// The type of the item. Always `apply_patch_call`.
	Type string `json:"type"`
}

// ResponseInputItemApplyPatchCallOperationUnionParam is a union type for different apply patch call operation parameters.
// Only one field can be non-zero.
type ResponseInputItemApplyPatchCallOperationUnionParam struct {
	OfCreateFile *ResponseInputItemApplyPatchCallOperationCreateFileParam
	OfDeleteFile *ResponseInputItemApplyPatchCallOperationDeleteFileParam
	OfUpdateFile *ResponseInputItemApplyPatchCallOperationUpdateFileParam
}

func (r ResponseInputItemApplyPatchCallOperationUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfCreateFile != nil:
		return json.Marshal(r.OfCreateFile)
	case r.OfDeleteFile != nil:
		return json.Marshal(r.OfDeleteFile)
	case r.OfUpdateFile != nil:
		return json.Marshal(r.OfUpdateFile)
	default:
		return nil, errors.New("no apply patch call operation to marshal")
	}
}

func (r *ResponseInputItemApplyPatchCallOperationUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "create_file":
		var cf ResponseInputItemApplyPatchCallOperationCreateFileParam
		if err := json.Unmarshal(data, &cf); err != nil {
			return err
		}
		r.OfCreateFile = &cf
	case "delete_file":
		var df ResponseInputItemApplyPatchCallOperationDeleteFileParam
		if err := json.Unmarshal(data, &df); err != nil {
			return err
		}
		r.OfDeleteFile = &df
	case "update_file":
		var uf ResponseInputItemApplyPatchCallOperationUpdateFileParam
		if err := json.Unmarshal(data, &uf); err != nil {
			return err
		}
		r.OfUpdateFile = &uf
	default:
		return errors.New("unknown type for input item apply patch call operation: " + typ.String())
	}
	return nil
}

// Instruction for creating a new file via the apply_patch tool.
//
// The properties Diff, Path, Type are required.
type ResponseInputItemApplyPatchCallOperationCreateFileParam struct {
	// Unified diff content to apply when creating the file.
	Diff string `json:"diff"`
	// Path of the file to create relative to the workspace root.
	Path string `json:"path"`
	// The operation type. Always `create_file`.
	Type string `json:"type"`
}

// Instruction for deleting an existing file via the apply_patch tool.
//
// The properties Path, Type are required.
type ResponseInputItemApplyPatchCallOperationDeleteFileParam struct {
	// Path of the file to delete relative to the workspace root.
	Path string `json:"path"`
	// The operation type. Always `delete_file`.
	Type string `json:"type"`
}

// Instruction for updating an existing file via the apply_patch tool.
//
// The properties Diff, Path, Type are required.
type ResponseInputItemApplyPatchCallOperationUpdateFileParam struct {
	// Unified diff content to apply to the existing file.
	Diff string `json:"diff"`
	// Path of the file to update relative to the workspace root.
	Path string `json:"path"`
	// The operation type. Always `update_file`.
	Type string `json:"type"`
}

// The streamed output emitted by an apply patch tool call.
//
// The properties CallID, Status, Type are required.
type ResponseInputItemApplyPatchCallOutputParam struct {
	// The unique ID of the apply patch tool call generated by the model.
	CallID string `json:"call_id"`
	// The status of the apply patch tool call output. One of `completed` or `failed`.
	//
	// Any of "completed", "failed".
	Status string `json:"status,omitzero"`
	// The unique ID of the apply patch tool call output. Populated when this item is
	// returned via API.
	ID string `json:"id,omitzero"`
	// Optional human-readable log text from the apply patch tool (e.g., patch results
	// or errors).
	Output string `json:"output,omitzero"`
	// The type of the item. Always `apply_patch_call_output`.
	Type string `json:"type"`
}

// A tool available on an MCP server.

// The properties InputSchema, Name are required.
type ResponseOutputItemMcpListTools = ResponseInputItemMcpListToolsToolParam

// A list of tools available on an MCP server.
//
// The properties ID, ServerLabel, Tools, Type are required.
type ResponseMcpListTools struct {
	// The unique ID of the list.
	ID string `json:"id"`
	// The label of the MCP server.
	ServerLabel string `json:"server_label"`
	// The tools available on the server.
	Tools []ResponseOutputItemMcpListTools `json:"tools,omitzero"`
	// Error message if the server could not list tools.
	Error string `json:"error,omitzero"`
	// The type of the item. Always `mcp_list_tools`.
	Type string `json:"type"`
}

// A tool available on an MCP server.
//
// The properties InputSchema, Name are required.
type ResponseInputItemMcpListToolsToolParam struct {
	// The JSON schema describing the tool's input.
	InputSchema any `json:"input_schema,omitzero"`
	// The name of the tool.
	Name string `json:"name"`
	// The description of the tool.
	Description string `json:"description,omitzero"`
	// Additional annotations about the tool.
	Annotations any `json:"annotations,omitzero"`
}

// A request for human approval of a tool invocation.
//
// The properties ID, Arguments, Name, ServerLabel, Type are required.
type ResponseMcpApprovalRequest struct {
	// The unique ID of the approval request.
	ID string `json:"id"`
	// A JSON string of arguments for the tool.
	Arguments string `json:"arguments"`
	// The name of the tool to run.
	Name string `json:"name"`
	// The label of the MCP server making the request.
	ServerLabel string `json:"server_label"`
	// The type of the item. Always `mcp_approval_request`.
	Type string `json:"type"`
}

// A response to an MCP approval request.
//
// The properties ApprovalRequestID, Approve, Type are required.
type ResponseInputItemMcpApprovalResponseParam struct {
	// The ID of the approval request being answered.
	ApprovalRequestID string `json:"approval_request_id"`
	// Whether the request was approved.
	Approve bool `json:"approve"`
	// The unique ID of the approval response
	ID string `json:"id,omitzero"`
	// Optional reason for the decision.
	Reason string `json:"reason,omitzero"`
	// The type of the item. Always `mcp_approval_response`.
	Type string `json:"type"`
}

// An invocation of a tool on an MCP server.
//
// The properties ID, Arguments, Name, ServerLabel, Type are required.
type ResponseMcpCall struct {
	// The unique ID of the tool call.
	ID string `json:"id"`
	// A JSON string of the arguments passed to the tool.
	Arguments string `json:"arguments"`
	// The name of the tool that was run.
	Name string `json:"name"`
	// The label of the MCP server running the tool.
	ServerLabel string `json:"server_label"`
	// Unique identifier for the MCP tool call approval request. Include this value in
	// a subsequent `mcp_approval_response` input to approve or reject the
	// corresponding tool call.
	ApprovalRequestID string `json:"approval_request_id,omitzero"`
	// The error from the tool call, if any.
	Error string `json:"error,omitzero"`
	// The output from the tool call.
	Output string `json:"output,omitzero"`
	// The status of the tool call. One of `in_progress`, `completed`, `incomplete`,
	// `calling`, or `failed`.
	//
	// Any of "in_progress", "completed", "incomplete", "calling", "failed".
	Status string `json:"status,omitzero"`
	// The type of the item. Always `mcp_call`.
	Type string `json:"type"`
}

// The output of a custom tool call from your code, being sent back to the model.
//
// The properties CallID, Output, Type are required.
type ResponseCustomToolCallOutputParam struct {
	// The call ID, used to map this custom tool call output to a custom tool call.
	CallID string `json:"call_id"`
	// The output from the custom tool call generated by your code. Can be a string or
	// an list of output content.
	Output ResponseCustomToolCallOutputOutputUnionParam `json:"output,omitzero"`
	// The unique ID of the custom tool call output in the OpenAI platform.
	ID string `json:"id,omitzero"`
	// The type of the custom tool call output. Always `custom_tool_call_output`.
	Type string `json:"type"`
}

// ResponseCustomToolCallOutputOutputUnionParam is a union type for different custom tool call output parameters.
// Only one field can be non-zero.
type ResponseCustomToolCallOutputOutputUnionParam struct {
	OfString            *string
	OfOutputContentList []ResponseCustomToolCallOutputContentListItemUnionParam
}

func (r ResponseCustomToolCallOutputOutputUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfString != nil:
		return json.Marshal(r.OfString)
	case r.OfOutputContentList != nil:
		return json.Marshal(r.OfOutputContentList)
	default:
		return nil, errors.New("no custom tool call output to marshal")
	}
}

func (r *ResponseCustomToolCallOutputOutputUnionParam) UnmarshalJSON(data []byte) error {
	// Check if data is a string
	if data[0] == '"' {
		var str string
		if err := json.Unmarshal(data, &str); err != nil {
			return err
		}
		r.OfString = &str
		return nil
	}
	var arr []ResponseCustomToolCallOutputContentListItemUnionParam
	if err := json.Unmarshal(data, &arr); err != nil {
		return err
	}
	r.OfOutputContentList = arr
	return nil
}

// ResponseCustomToolCallOutputContentListItemUnionParam is a union type for different custom tool call output content list item parameters.
// Only one field can be non-zero.
type ResponseCustomToolCallOutputContentListItemUnionParam struct {
	OfInputText  *ResponseInputTextParam
	OfInputImage *ResponseInputImageParam
	OfInputFile  *ResponseInputFileParam
}

func (r ResponseCustomToolCallOutputContentListItemUnionParam) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfInputText != nil:
		return json.Marshal(r.OfInputText)
	case r.OfInputImage != nil:
		return json.Marshal(r.OfInputImage)
	case r.OfInputFile != nil:
		return json.Marshal(r.OfInputFile)
	default:
		return nil, errors.New("no custom tool call output content list item to marshal")
	}
}

func (r *ResponseCustomToolCallOutputContentListItemUnionParam) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "input_text":
		var it ResponseInputTextParam
		if err := json.Unmarshal(data, &it); err != nil {
			return err
		}
		r.OfInputText = &it
	case "input_image":
		var ii ResponseInputImageParam
		if err := json.Unmarshal(data, &ii); err != nil {
			return err
		}
		r.OfInputImage = &ii
	case "input_file":
		var ifile ResponseInputFileParam
		if err := json.Unmarshal(data, &ifile); err != nil {
			return err
		}
		r.OfInputFile = &ifile
	default:
		return errors.New("unknown type for custom tool call output content list item: " + typ.String())
	}
	return nil
}

// A call to a custom tool created by the model.
//
// The properties CallID, Input, Name, Type are required.
type ResponseCustomToolCall struct {
	// An identifier used to map this custom tool call to a tool call output.
	CallID string `json:"call_id"`
	// The input for the custom tool call generated by the model.
	Input string `json:"input"`
	// The name of the custom tool being called.
	Name string `json:"name"`
	// The unique ID of the custom tool call in the OpenAI platform.
	ID string `json:"id,omitzero"`
	// The type of the custom tool call. Always `custom_tool_call`.
	Type string `json:"type"`
}

// An internal identifier for an item to reference.
//
// The property ID is required.
type ResponseInputItemItemReferenceParam struct {
	// The ID of the item to reference.
	ID string `json:"id"`
	// The type of item to reference. Always `item_reference`.
	Type string `json:"type,omitzero"`
}

// ResponseToolChoiceUnion is a union type for tool choice configuration in Responses API.
// Only one of the fields should be set.
type ResponseToolChoiceUnion struct {
	OfToolChoiceMode *string
	OfAllowedTools   *ToolChoiceAllowed
	OfHostedTool     *ToolChoiceTypes
	OfFunctionTool   *ToolChoiceFunction
	OfMcpTool        *ToolChoiceMcp
	OfCustomTool     *ToolChoiceCustom
	OfApplyPatchTool *ToolChoiceApplyPatch
	OfShellTool      *ToolChoiceShell
}

func (r *ResponseToolChoiceUnion) UnmarshalJSON(data []byte) error {
	// Try to unmarshal as ToolChoiceMode (string)
	var mode string
	if err := json.Unmarshal(data, &mode); err == nil {
		r.OfToolChoiceMode = &mode
		return nil
	}
	typ := gjson.GetBytes(data, "type")
	if !typ.Exists() {
		return errors.New("missing type field in tool choice")
	}

	switch typ.String() {
	case "allowed_tools":
		// Try to unmarshal as ToolChoiceAllowed
		var allowedTools ToolChoiceAllowed
		if err := json.Unmarshal(data, &allowedTools); err != nil {
			return err
		}
		r.OfAllowedTools = &allowedTools
	case "file_search", "web_search_preview", "computer_use_preview", "web_search_preview_2025_03_11", "image_generation", "code_interpreter":
		// Try to unmarshal as ToolChoiceTypes
		var hostedTool ToolChoiceTypes
		if err := json.Unmarshal(data, &hostedTool); err != nil {
			return err
		}
		r.OfHostedTool = &hostedTool
	case "function":
		// Try to unmarshal as ToolChoiceFunction
		var functionTool ToolChoiceFunction
		if err := json.Unmarshal(data, &functionTool); err != nil {
			return err
		}
		r.OfFunctionTool = &functionTool
	case "mcp":
		// Try to unmarshal as ToolChoiceMcp
		var mcpTool ToolChoiceMcp
		if err := json.Unmarshal(data, &mcpTool); err != nil {
			return err
		}
		r.OfMcpTool = &mcpTool
	case "custom":
		// Try to unmarshal as ToolChoiceCustom
		var customTool ToolChoiceCustom
		if err := json.Unmarshal(data, &customTool); err != nil {
			return err
		}
		r.OfCustomTool = &customTool
	case "apply_patch":
		// Try to unmarshal as ToolChoiceApplyPatch
		var applyPatchTool ToolChoiceApplyPatch
		if err := json.Unmarshal(data, &applyPatchTool); err != nil {
			return err
		}
		r.OfApplyPatchTool = &applyPatchTool
	case "shell":
		// Try to unmarshal as ToolChoiceShell
		var shellTool ToolChoiceShell
		if err := json.Unmarshal(data, &shellTool); err != nil {
			return err
		}
		r.OfShellTool = &shellTool
	default:
		return fmt.Errorf("unknown tool choice type: %s", typ.String())
	}
	return nil
}

func (r ResponseToolChoiceUnion) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfToolChoiceMode != nil:
		return json.Marshal(r.OfToolChoiceMode)
	case r.OfAllowedTools != nil:
		return json.Marshal(r.OfAllowedTools)
	case r.OfHostedTool != nil:
		return json.Marshal(r.OfHostedTool)
	case r.OfFunctionTool != nil:
		return json.Marshal(r.OfFunctionTool)
	case r.OfMcpTool != nil:
		return json.Marshal(r.OfMcpTool)
	case r.OfCustomTool != nil:
		return json.Marshal(r.OfCustomTool)
	case r.OfApplyPatchTool != nil:
		return json.Marshal(r.OfApplyPatchTool)
	case r.OfShellTool != nil:
		return json.Marshal(r.OfShellTool)
	default:
		return nil, errors.New("no tool choice to marshal")
	}
}

// Constrains the tools available to the model to a pre-defined set.
//
// The properties Mode, Tools, Type are required.
type ToolChoiceAllowed struct {
	// Constrains the tools available to the model to a pre-defined set.
	//
	// `auto` allows the model to pick from among the allowed tools and generate a
	// message.
	//
	// `required` requires the model to call one or more of the allowed tools.
	//
	// Any of "auto", "required".
	Mode string `json:"mode,omitzero"`
	// A list of tool definitions that the model should be allowed to call.
	//
	// For the Responses API, the list of tool definitions might look like:
	//
	// ```json
	// [
	//
	//	{ "type": "function", "name": "get_weather" },
	//	{ "type": "mcp", "server_label": "deepwiki" },
	//	{ "type": "image_generation" }
	//
	// ]
	// ```
	Tools []map[string]any `json:"tools,omitzero"`
	// Allowed tool configuration type. Always `allowed_tools`.
	Type string `json:"type,omitzero"`
}

// Indicates that the model should use a built-in tool to generate a response.
// [Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).
//
// The property Type is required.
type ToolChoiceTypes struct {
	// The type of hosted tool the model should to use. Learn more about
	// [built-in tools](https://platform.openai.com/docs/guides/tools).
	//
	// Allowed values are:
	//
	// - `file_search`
	// - `web_search_preview`
	// - `computer_use_preview`
	// - `code_interpreter`
	// - `image_generation`
	// - `apply_patch`
	//
	// Any of "file_search", "web_search_preview", "computer_use_preview",
	// "web_search_preview_2025_03_11", "image_generation", "code_interpreter".
	Type string `json:"type,omitzero"`
}

// Use this option to force the model to call a specific function.
//
// The properties Name, Type are required.
type ToolChoiceFunction struct {
	// The name of the function to call.
	Name string `json:"name"`
	// For function calling, the type is always `function`.
	Type string `json:"type,omitzero"`
}

// Use this option to force the model to call a specific tool on a remote MCP
// server.
//
// The properties ServerLabel, Type are required.
type ToolChoiceMcp struct {
	// The label of the MCP server to use.
	ServerLabel string `json:"server_label"`
	// The name of the tool to call on the server.
	Name string `json:"name,omitzero"`
	// For MCP tools, the type is always `mcp`.
	Type string `json:"type,omitzero"`
}

// Use this option to force the model to call a specific custom tool.
//
// The properties Name, Type are required.
type ToolChoiceCustom struct {
	// The name of the custom tool to call.
	Name string `json:"name"`
	// For custom tool calling, the type is always `custom`.
	Type string `json:"type,omitzero"`
}

// Forces the model to call the apply_patch tool when executing a tool call.
type ToolChoiceApplyPatch struct {
	// The tool to call. Always `apply_patch`.
	Type string `json:"type"`
}

// Forces the model to call the shell tool when a tool call is required.
type ToolChoiceShell struct {
	// The tool to call. Always `shell`.
	Type string `json:"type,omitzero"`
}

// Response represents a response from the /v1/responses endpoint.
// Docs: https://platform.openai.com/docs/api-reference/responses/object
type Response struct {
	// Unique identifier for this Response.
	ID string `json:"id"`

	// Unix timestamp (in seconds) of when this Response was created.
	CreatedAt JSONUNIXTime `json:"created_at"`

	// Unix timestamp (in seconds) of when this Response was completed. Only present when the status is `completed`.
	CompletedAt *JSONUNIXTime `json:"completed_at,omitempty"`

	// An error object returned when the model fails to generate a Response.
	Error ResponseError `json:"error,omitzero"`

	// Details about why the response is incomplete.
	IncompleteDetails ResponseIncompleteDetails `json:"incomplete_details,omitzero"`

	// A system (or developer) message inserted into the model's context.
	//
	// When using along with `previous_response_id`, the instructions from a previous
	// response will not be carried over to the next response. This makes it simple to
	// swap out system (or developer) messages in new responses.
	Instructions ResponseInstructionsUnion `json:"instructions,omitzero"`

	// Set of 16 key-value pairs that can be attached to an object. This can be useful
	// for storing additional information about the object in a structured format, and
	// querying for objects via API or the dashboard.
	//
	// Keys are strings with a maximum length of 64 characters. Values are strings with
	// a maximum length of 512 characters.
	Metadata map[string]string `json:"metadata,omitzero"`

	// Model ID used to generate the response, like `gpt-4o` or `o3`.
	Model string `json:"model"`

	// The object type of this resource - always set to `response`.
	Object string `json:"object"`

	// An array of content items generated by the model.
	//
	//   - The length and order of items in the `output` array is dependent on the
	//     model's response.
	//   - Rather than accessing the first item in the `output` array and assuming it's
	//     an `assistant` message with the content generated by the model, you might
	//     consider using the `output_text` property where supported in SDKs.
	Output []ResponseOutputItemUnion `json:"output,omitzero"`

	// Whether to allow the model to run tool calls in parallel.
	ParallelToolCalls *bool `json:"parallel_tool_calls,omitempty"`

	// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will
	// make the output more random, while lower values like 0.2 will make it more
	// focused and deterministic. We generally recommend altering this or `top_p` but
	// not both.
	Temperature float64 `json:"temperature"`

	// How the model should select which tool (or tools) to use when generating a
	// response. See the `tools` parameter to see how to specify which tools the model
	// can call.
	ToolChoice ResponseToolChoiceUnion `json:"tool_choice,omitzero"`

	// An array of tools the model may call while generating a response. You can
	// specify which tool to use by setting the `tool_choice` parameter.
	Tools []ResponseToolUnion `json:"tools,omitzero"`

	// An alternative to sampling with temperature, called nucleus sampling, where the
	// model considers the results of the tokens with top_p probability mass. So 0.1
	// means only the tokens comprising the top 10% probability mass are considered.
	//
	// We generally recommend altering this or `temperature` but not both.
	TopP float64 `json:"top_p"`

	// Whether to run the model response in the background.
	// [Learn more](https://platform.openai.com/docs/guides/background).
	Background *bool `json:"background,omitempty"`

	// The conversation that this response belongs to. Input items and output items
	// from this response are automatically added to this conversation.
	Conversation ResponseConversation `json:"conversation,omitzero"`

	// An upper bound for the number of tokens that can be generated for a response,
	// including visible output tokens and
	// [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).
	MaxOutputTokens *int64 `json:"max_output_tokens,omitempty"`

	// The maximum number of total calls to built-in tools that can be processed in a
	// response. This maximum number applies across all built-in tool calls, not per
	// individual tool. Any further attempts to call a tool by the model will be
	// ignored.
	MaxToolCalls *int64 `json:"max_tool_calls,omitempty"`

	// The unique ID of the previous response to the model. Use this to create
	// multi-turn conversations. Learn more about
	// [conversation state](https://platform.openai.com/docs/guides/conversation-state).
	// Cannot be used in conjunction with `conversation`.
	PreviousResponseID string `json:"previous_response_id,omitzero"`

	// Reference to a prompt template and its variables.
	// [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).
	Prompt ResponsePrompt `json:"prompt,omitzero"`

	// Used by OpenAI to cache responses for similar requests to optimize your cache
	// hit rates. Replaces the `user` field.
	// [Learn more](https://platform.openai.com/docs/guides/prompt-caching).
	PromptCacheKey string `json:"prompt_cache_key,omitzero"`

	// The retention policy for the prompt cache. Set to `24h` to enable extended
	// prompt caching, which keeps cached prefixes active for longer, up to a maximum
	// of 24 hours.
	// [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).
	//
	// Any of "in-memory", "24h".
	PromptCacheRetention string `json:"prompt_cache_retention,omitzero"`

	// Configuration options for
	// [reasoning models](https://platform.openai.com/docs/guides/reasoning).
	Reasoning ReasoningParam `json:"reasoning,omitzero"`

	// A stable identifier used to help detect users of your application that may be
	// violating OpenAI's usage policies. The IDs should be a string that uniquely
	// identifies each user. We recommend hashing their username or email address, in
	// order to avoid sending us any identifying information.
	// [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).
	SafetyIdentifier string `json:"safety_identifier,omitzero"`

	// Specifies the processing type used for serving the request.
	//
	//   - If set to 'auto', then the request will be processed with the service tier
	//     configured in the Project settings. Unless otherwise configured, the Project
	//     will use 'default'.
	//   - If set to 'default', then the request will be processed with the standard
	//     pricing and performance for the selected model.
	//   - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or
	//     '[priority](https://openai.com/api-priority-processing/)', then the request
	//     will be processed with the corresponding service tier.
	//   - When not set, the default behavior is 'auto'.
	//
	// When the `service_tier` parameter is set, the response body will include the
	// `service_tier` value based on the processing mode actually used to serve the
	// request. This response value may be different from the value set in the
	// parameter.
	//
	// Any of "auto", "default", "flex", "scale", "priority".
	ServiceTier string `json:"service_tier,omitzero"`

	// The status of the response generation. One of `completed`, `failed`,
	// `in_progress`, `cancelled`, `queued`, or `incomplete`.
	//
	// Any of "completed", "failed", "in_progress", "cancelled", "queued",
	// "incomplete".
	Status string `json:"status"`

	// Configuration options for a text response from the model. Can be plain text or
	// structured JSON data. Learn more:
	//
	// - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
	// - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
	Text ResponseTextConfig `json:"text"`

	// An integer between 0 and 20 specifying the number of most likely tokens to
	// return at each token position, each with an associated log probability.
	TopLogprobs *int64 `json:"top_logprobs,omitempty"`

	// The truncation strategy to use for the model response.
	//
	//   - `auto`: If the input to this Response exceeds the model's context window size,
	//     the model will truncate the response to fit the context window by dropping
	//     items from the beginning of the conversation.
	//   - `disabled` (default): If the input size will exceed the context window size
	//     for a model, the request will fail with a 400 error.
	//
	// Any of "auto", "disabled".
	Truncation string `json:"truncation,omitzero"`

	// Represents token usage details including input tokens, output tokens, a
	// breakdown of output tokens, and the total tokens used.
	Usage *ResponseUsage `json:"usage,omitempty"`

	// This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use
	// `prompt_cache_key` instead to maintain caching optimizations. A stable
	// identifier for your end-users. Used to boost cache hit rates by better bucketing
	// similar requests and to help OpenAI detect and prevent abuse.
	// [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).
	//
	// Deprecated: deprecated
	User string `json:"user,omitzero"`
}

// ResponseInstructionsUnion contains all possible properties and values from
// [string], [[]ResponseInputItemUnion].
type ResponseInstructionsUnion struct {
	// This field will be present if the value is a [string] instead of an object.
	OfString *string
	// This field will be present if the value is a [[]ResponseInputItemUnion] instead
	// of an object.
	OfInputItemList []ResponseInputItemUnionParam
}

func (r ResponseInstructionsUnion) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfString != nil:
		return json.Marshal(r.OfString)
	case r.OfInputItemList != nil:
		return json.Marshal(r.OfInputItemList)
	default:
		return nil, errors.New("no instructions to marshal")
	}
}

func (r *ResponseInstructionsUnion) UnmarshalJSON(data []byte) error {
	// Check if data is a string
	if data[0] == '"' {
		var str string
		if err := json.Unmarshal(data, &str); err != nil {
			return err
		}
		r.OfString = &str
		return nil
	}
	var arr []ResponseInputItemUnionParam
	if err := json.Unmarshal(data, &arr); err != nil {
		return err
	}
	r.OfInputItemList = arr
	return nil
}

type ResponseOutputItemUnion struct {
	OfOutputMessage        *ResponseOutputMessage
	OfFileSearchCall       *ResponseFileSearchToolCall
	OfComputerCall         *ResponseComputerToolCall
	OfFunctionCall         *ResponseFunctionToolCall
	OfWebSearchCall        *ResponseFunctionWebSearch
	OfReasoning            *ResponseReasoningItem
	OfCompaction           *ResponseCompactionItem
	OfImageGenerationCall  *ResponseOutputItemImageGenerationCall
	OfCodeInterpreterCall  *ResponseCodeInterpreterToolCall
	OfLocalShellCall       *ResponseOutputItemLocalShellCall
	OfShellCall            *ResponseFunctionShellToolCall
	OfShellCallOutput      *ResponseFunctionShellToolCallOutput
	OfApplyPatchCall       *ResponseApplyPatchToolCall
	OfApplyPatchCallOutput *ResponseApplyPatchToolCallOutput
	OfMcpCall              *ResponseMcpCall
	OfMcpListTools         *ResponseMcpListTools
	OfMcpApprovalRequest   *ResponseMcpApprovalRequest
	OfCustomToolCall       *ResponseCustomToolCall
}

func (r ResponseOutputItemUnion) MarshalJSON() ([]byte, error) { // nolint:gocritic
	switch {
	case r.OfOutputMessage != nil:
		return json.Marshal(r.OfOutputMessage)
	case r.OfFileSearchCall != nil:
		return json.Marshal(r.OfFileSearchCall)
	case r.OfComputerCall != nil:
		return json.Marshal(r.OfComputerCall)
	case r.OfFunctionCall != nil:
		return json.Marshal(r.OfFunctionCall)
	case r.OfWebSearchCall != nil:
		return json.Marshal(r.OfWebSearchCall)
	case r.OfReasoning != nil:
		return json.Marshal(r.OfReasoning)
	case r.OfCompaction != nil:
		return json.Marshal(r.OfCompaction)
	case r.OfImageGenerationCall != nil:
		return json.Marshal(r.OfImageGenerationCall)
	case r.OfCodeInterpreterCall != nil:
		return json.Marshal(r.OfCodeInterpreterCall)
	case r.OfLocalShellCall != nil:
		return json.Marshal(r.OfLocalShellCall)
	case r.OfShellCall != nil:
		return json.Marshal(r.OfShellCall)
	case r.OfShellCallOutput != nil:
		return json.Marshal(r.OfShellCallOutput)
	case r.OfApplyPatchCall != nil:
		return json.Marshal(r.OfApplyPatchCall)
	case r.OfApplyPatchCallOutput != nil:
		return json.Marshal(r.OfApplyPatchCallOutput)
	case r.OfMcpCall != nil:
		return json.Marshal(r.OfMcpCall)
	case r.OfMcpListTools != nil:
		return json.Marshal(r.OfMcpListTools)
	case r.OfMcpApprovalRequest != nil:
		return json.Marshal(r.OfMcpApprovalRequest)
	case r.OfCustomToolCall != nil:
		return json.Marshal(r.OfCustomToolCall)
	default:
		return nil, errors.New("no output item to marshal")
	}
}

func (r *ResponseOutputItemUnion) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "message":
		var msg ResponseOutputMessage
		if err := json.Unmarshal(data, &msg); err != nil {
			return err
		}
		r.OfOutputMessage = &msg
	case "file_search_call":
		var f ResponseFileSearchToolCall
		if err := json.Unmarshal(data, &f); err != nil {
			return err
		}
		r.OfFileSearchCall = &f
	case "function_call":
		var f ResponseFunctionToolCall
		if err := json.Unmarshal(data, &f); err != nil {
			return err
		}
		r.OfFunctionCall = &f
	case "web_search_call":
		var w ResponseFunctionWebSearch
		if err := json.Unmarshal(data, &w); err != nil {
			return err
		}
		r.OfWebSearchCall = &w
	case "computer_call":
		var c ResponseComputerToolCall
		if err := json.Unmarshal(data, &c); err != nil {
			return err
		}
		r.OfComputerCall = &c
	case "reasoning":
		var rr ResponseReasoningItem
		if err := json.Unmarshal(data, &rr); err != nil {
			return err
		}
		r.OfReasoning = &rr
	case "compaction":
		var c ResponseCompactionItem
		if err := json.Unmarshal(data, &c); err != nil {
			return err
		}
		r.OfCompaction = &c
	case "image_generation_call":
		var i ResponseOutputItemImageGenerationCall
		if err := json.Unmarshal(data, &i); err != nil {
			return err
		}
		r.OfImageGenerationCall = &i
	case "code_interpreter_call":
		var c ResponseCodeInterpreterToolCall
		if err := json.Unmarshal(data, &c); err != nil {
			return err
		}
		r.OfCodeInterpreterCall = &c
	case "local_shell_call":
		var l ResponseOutputItemLocalShellCall
		if err := json.Unmarshal(data, &l); err != nil {
			return err
		}
		r.OfLocalShellCall = &l
	case "shell_call":
		var s ResponseFunctionShellToolCall
		if err := json.Unmarshal(data, &s); err != nil {
			return err
		}
		r.OfShellCall = &s
	case "shell_call_output":
		var s ResponseFunctionShellToolCallOutput
		if err := json.Unmarshal(data, &s); err != nil {
			return err
		}
		r.OfShellCallOutput = &s
	case "apply_patch_call":
		var p ResponseApplyPatchToolCall
		if err := json.Unmarshal(data, &p); err != nil {
			return err
		}
		r.OfApplyPatchCall = &p
	case "apply_patch_call_output":
		var p ResponseApplyPatchToolCallOutput
		if err := json.Unmarshal(data, &p); err != nil {
			return err
		}
		r.OfApplyPatchCallOutput = &p
	case "mcp_call":
		var m ResponseMcpCall
		if err := json.Unmarshal(data, &m); err != nil {
			return err
		}
		r.OfMcpCall = &m
	case "mcp_list_tools":
		var m ResponseMcpListTools
		if err := json.Unmarshal(data, &m); err != nil {
			return err
		}
		r.OfMcpListTools = &m
	case "mcp_approval_request":
		var m ResponseMcpApprovalRequest
		if err := json.Unmarshal(data, &m); err != nil {
			return err
		}
		r.OfMcpApprovalRequest = &m
	case "custom_tool_call":
		var c ResponseCustomToolCall
		if err := json.Unmarshal(data, &c); err != nil {
			return err
		}
		r.OfCustomToolCall = &c
	default:
		return fmt.Errorf("unknown type field value '%s' for response output item union", typ.String())
	}
	return nil
}

// A compaction item generated by the
// [`v1/responses/compact` API](https://platform.openai.com/docs/api-reference/responses/compact).
type ResponseCompactionItem struct {
	// The unique ID of the compaction item.
	ID               string `json:"id"`
	EncryptedContent string `json:"encrypted_content"`
	// The type of the item. Always `compaction`.
	Type      string `json:"type"`
	CreatedBy string `json:"created_by,omitzero"`
}

// An image generation request made by the model.
type ResponseOutputItemImageGenerationCall struct {
	// The unique ID of the image generation call.
	ID string `json:"id"`
	// The generated image encoded in base64.
	Result string `json:"result"`
	// The status of the image generation call.
	//
	// Any of "in_progress", "completed", "generating", "failed".
	Status string `json:"status"`
	// The type of the image generation call. Always `image_generation_call`.
	Type string `json:"type"`
}

// A tool call to run a command on the local shell.
type ResponseOutputItemLocalShellCall struct {
	// The unique ID of the local shell call.
	ID string `json:"id"`
	// Execute a shell command on the server.
	Action ResponseOutputItemLocalShellCallAction `json:"action"`
	// The unique ID of the local shell tool call generated by the model.
	CallID string `json:"call_id"`
	// The status of the local shell call.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status"`
	// The type of the local shell call. Always `local_shell_call`.
	Type string `json:"type"`
}

// Execute a shell command on the server.
type ResponseOutputItemLocalShellCallAction struct {
	// The command to run.
	Command []string `json:"command"`
	// Environment variables to set for the command.
	Env map[string]string `json:"env"`
	// The type of the local shell action. Always `exec`.
	Type string `json:"type"`
	// Optional timeout in milliseconds for the command.
	TimeoutMs int64 `json:"timeout_ms,omitempty"`
	// Optional user to run the command as.
	User string `json:"user,omitzero"`
	// Optional working directory to run the command in.
	WorkingDirectory string `json:"working_directory,omitzero"`
}

// The output of a shell tool call.
type ResponseFunctionShellToolCallOutput struct {
	// The unique ID of the shell call output. Populated when this item is returned via
	// API.
	ID string `json:"id"`
	// The unique ID of the shell tool call generated by the model.
	CallID string `json:"call_id"`
	// The maximum length of the shell command output. This is generated by the model
	// and should be passed back with the raw output.
	MaxOutputLength int64 `json:"max_output_length"`
	// An array of shell call output contents
	Output []ResponseFunctionShellToolCallOutputOutput `json:"output"`
	// The type of the shell call output. Always `shell_call_output`.
	Type      string `json:"type"`
	CreatedBy string `json:"created_by,omitzero"`
}

// The content of a shell call output.
type ResponseFunctionShellToolCallOutputOutput struct {
	// Represents either an exit outcome (with an exit code) or a timeout outcome for a
	// shell call output chunk.
	Outcome   ResponseFunctionShellToolCallOutputOutputOutcomeUnion `json:"outcome"`
	Stderr    string                                                `json:"stderr"`
	Stdout    string                                                `json:"stdout"`
	CreatedBy string                                                `json:"created_by,omitzero"`
}

// ResponseFunctionShellToolCallOutputOutputOutcomeUnion contains all possible
// properties and values from
// [ResponseFunctionShellToolCallOutputOutcomeTimeout],
// [ResponseFunctionShellToolCallOutputOutcomeExit].
type ResponseFunctionShellToolCallOutputOutputOutcomeUnion struct {
	OfResponseFunctionShellToolCallOutputOutputOutcomeTimeout *ResponseFunctionShellToolCallOutputOutputOutcomeTimeout
	OfResponseFunctionShellToolCallOutputOutputOutcomeExit    *ResponseFunctionShellToolCallOutputOutputOutcomeExit
}

func (r ResponseFunctionShellToolCallOutputOutputOutcomeUnion) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfResponseFunctionShellToolCallOutputOutputOutcomeExit != nil:
		return json.Marshal(r.OfResponseFunctionShellToolCallOutputOutputOutcomeExit)
	case r.OfResponseFunctionShellToolCallOutputOutputOutcomeTimeout != nil:
		return json.Marshal(r.OfResponseFunctionShellToolCallOutputOutputOutcomeTimeout)
	default:
		return nil, errors.New("no function tool call output outcome to marshal")
	}
}

func (r *ResponseFunctionShellToolCallOutputOutputOutcomeUnion) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "timeout":
		var t ResponseFunctionShellToolCallOutputOutputOutcomeTimeout
		if err := json.Unmarshal(data, &t); err != nil {
			return err
		}
		r.OfResponseFunctionShellToolCallOutputOutputOutcomeTimeout = &t
	case "exit":
		var e ResponseFunctionShellToolCallOutputOutputOutcomeExit
		if err := json.Unmarshal(data, &e); err != nil {
			return err
		}
		r.OfResponseFunctionShellToolCallOutputOutputOutcomeExit = &e
	default:
		return fmt.Errorf("unknown type field value '%s' for function shell tool call output outcome", typ.String())
	}
	return nil
}

// Indicates that the shell call exceeded its configured time limit.
type ResponseFunctionShellToolCallOutputOutputOutcomeTimeout struct {
	// The outcome type. Always `timeout`.
	Type string `json:"type"`
}

// Indicates that the shell commands finished and returned an exit code.
type ResponseFunctionShellToolCallOutputOutputOutcomeExit struct {
	// Exit code from the shell process.
	ExitCode int64 `json:"exit_code"`
	// The outcome type. Always `exit`.
	Type string `json:"type"`
}

// A tool call that applies file diffs by creating, deleting, or updating files.
type ResponseApplyPatchToolCall struct {
	// The unique ID of the apply patch tool call. Populated when this item is returned
	// via API.
	ID string `json:"id"`
	// The unique ID of the apply patch tool call generated by the model.
	CallID string `json:"call_id"`
	// One of the create_file, delete_file, or update_file operations applied via
	// apply_patch.
	Operation ResponseApplyPatchToolCallOperationUnion `json:"operation"`
	// The status of the apply patch tool call. One of `in_progress` or `completed`.
	//
	// Any of "in_progress", "completed".
	Status string `json:"status"`
	// The type of the item. Always `apply_patch_call`.
	Type string `json:"type"`
	// The ID of the entity that created this tool call.
	CreatedBy string `json:"created_by,omitzero"`
}

// ResponseApplyPatchToolCallOperationUnion contains all possible properties and
// values from [ResponseApplyPatchToolCallOperationCreateFile],
// [ResponseApplyPatchToolCallOperationDeleteFile],
// [ResponseApplyPatchToolCallOperationUpdateFile].
type ResponseApplyPatchToolCallOperationUnion struct {
	OfResponseApplyPatchToolCallOperationCreateFile *ResponseApplyPatchToolCallOperationCreateFile
	OfResponseApplyPatchToolCallOperationDeleteFile *ResponseApplyPatchToolCallOperationDeleteFile
	OfResponseApplyPatchToolCallOperationUpdateFile *ResponseApplyPatchToolCallOperationUpdateFile
}

func (r ResponseApplyPatchToolCallOperationUnion) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfResponseApplyPatchToolCallOperationCreateFile != nil:
		return json.Marshal(r.OfResponseApplyPatchToolCallOperationCreateFile)
	case r.OfResponseApplyPatchToolCallOperationDeleteFile != nil:
		return json.Marshal(r.OfResponseApplyPatchToolCallOperationDeleteFile)
	case r.OfResponseApplyPatchToolCallOperationUpdateFile != nil:
		return json.Marshal(r.OfResponseApplyPatchToolCallOperationUpdateFile)
	default:
		return nil, errors.New("no apply patch tool call operation to marshal")
	}
}

func (r *ResponseApplyPatchToolCallOperationUnion) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "create_file":
		var c ResponseApplyPatchToolCallOperationCreateFile
		if err := json.Unmarshal(data, &c); err != nil {
			return err
		}
		r.OfResponseApplyPatchToolCallOperationCreateFile = &c
	case "delete_file":
		var d ResponseApplyPatchToolCallOperationDeleteFile
		if err := json.Unmarshal(data, &d); err != nil {
			return err
		}
		r.OfResponseApplyPatchToolCallOperationDeleteFile = &d
	case "update_file":
		var u ResponseApplyPatchToolCallOperationUpdateFile
		if err := json.Unmarshal(data, &u); err != nil {
			return err
		}
		r.OfResponseApplyPatchToolCallOperationUpdateFile = &u
	default:
		return fmt.Errorf("unknown type field value '%s' for apply patch tool call operation", typ.String())
	}
	return nil
}

// Instruction describing how to create a file via the apply_patch tool.
type ResponseApplyPatchToolCallOperationCreateFile struct {
	// Diff to apply.
	Diff string `json:"diff"`
	// Path of the file to create.
	Path string `json:"path"`
	// Create a new file with the provided diff. Always "create_file"
	Type string `json:"type"`
}

// Instruction describing how to delete a file via the apply_patch tool.
type ResponseApplyPatchToolCallOperationDeleteFile struct {
	// Path of the file to delete.
	Path string `json:"path"`
	// Delete the specified file. Always "delete_file"
	Type string `json:"type"`
}

// Instruction describing how to update a file via the apply_patch tool.
type ResponseApplyPatchToolCallOperationUpdateFile struct {
	// Diff to apply.
	Diff string `json:"diff"`
	// Path of the file to update.
	Path string `json:"path"`
	// Update an existing file with the provided diff. Always "update_file"
	Type string `json:"type"`
}

// The output emitted by an apply patch tool call.
type ResponseApplyPatchToolCallOutput struct {
	// The unique ID of the apply patch tool call output. Populated when this item is
	// returned via API.
	ID string `json:"id"`
	// The unique ID of the apply patch tool call generated by the model.
	CallID string `json:"call_id"`
	// The status of the apply patch tool call output. One of `completed` or `failed`.
	//
	// Any of "completed", "failed".
	Status string `json:"status"`
	// The type of the item. Always `apply_patch_call_output`.
	Type string `json:"type"`
	// The ID of the entity that created this tool call output.
	CreatedBy string `json:"created_by,omitzero"`
	// Optional textual output returned by the apply patch tool.
	Output string `json:"output"`
}

// A tool call that executes one or more shell commands in a managed environment.
type ResponseFunctionShellToolCall struct {
	// The unique ID of the shell tool call. Populated when this item is returned via
	// API.
	ID string `json:"id"`
	// The shell commands and limits that describe how to run the tool call.
	Action ResponseFunctionShellToolCallAction `json:"action"`
	// The unique ID of the shell tool call generated by the model.
	CallID string `json:"call_id"`
	// The status of the shell call. One of `in_progress`, `completed`, or
	// `incomplete`.
	//
	// Any of "in_progress", "completed", "incomplete".
	Status string `json:"status"`
	// The type of the item. Always `shell_call`.
	Type string `json:"type"`
	// The ID of the entity that created this tool call.
	CreatedBy string `json:"created_by,omitzero"`
}

// The shell commands and limits that describe how to run the tool call.
type ResponseFunctionShellToolCallAction struct {
	Commands []string `json:"commands"`
	// Optional maximum number of characters to return from each command.
	MaxOutputLength int64 `json:"max_output_length,omitempty"`
	// Optional timeout in milliseconds for the commands.
	TimeoutMs int64 `json:"timeout_ms,omitempty"`
}

// Represents token usage details including input tokens, output tokens, a
// breakdown of output tokens, and the total tokens used.
type ResponseUsage struct {
	// The number of input tokens.
	InputTokens int64 `json:"input_tokens"`

	// A detailed breakdown of the input tokens.
	InputTokensDetails ResponseUsageInputTokensDetails `json:"input_tokens_details"`

	// The number of output tokens.
	OutputTokens int64 `json:"output_tokens"`

	// A detailed breakdown of the output tokens.
	OutputTokensDetails ResponseUsageOutputTokensDetails `json:"output_tokens_details"`

	// The total number of tokens used.
	TotalTokens int64 `json:"total_tokens"`
}

// A detailed breakdown of the input tokens.
type ResponseUsageInputTokensDetails struct {
	// The number of tokens that were retrieved from the cache.
	// [More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).
	CachedTokens int64 `json:"cached_tokens"`

	// The number of tokens that were written to the cache.
	CacheCreationTokens int64 `json:"cache_creation_input_tokens"`
}

// A detailed breakdown of the output tokens.
type ResponseUsageOutputTokensDetails struct {
	// The number of reasoning tokens.
	ReasoningTokens int64 `json:"reasoning_tokens"`
}

// ResponseTokensDetails represents detailed token usage breakdown.
type ResponseTokensDetails struct {
	// CachedTokens: Number of cached tokens.
	CachedTokens int `json:"cached_tokens,omitempty"` //nolint:tagliatelle //follow openai api

	// CacheCreationTokens: number of tokens that were written to the cache.
	CacheCreationTokens int64 `json:"cache_creation_input_tokens"` //nolint:tagliatelle

	// ReasoningTokens: Number of reasoning tokens (for reasoning models).
	ReasoningTokens int `json:"reasoning_tokens,omitempty"` //nolint:tagliatelle //follow openai api

	// AudioTokens: Number of audio tokens.
	AudioTokens int `json:"audio_tokens,omitempty"` //nolint:tagliatelle //follow openai api
}

// An error object returned when the model fails to generate a Response.
type ResponseError struct {
	// The error code for the response.
	//
	// Any of "server_error", "rate_limit_exceeded", "invalid_prompt",
	// "vector_store_timeout", "invalid_image", "invalid_image_format",
	// "invalid_base64_image", "invalid_image_url", "image_too_large",
	// "image_too_small", "image_parse_error", "image_content_policy_violation",
	// "invalid_image_mode", "image_file_too_large", "unsupported_image_media_type",
	// "empty_image_file", "failed_to_download_image", "image_file_not_found".
	Code string `json:"code"`
	// A human-readable description of the error.
	Message string `json:"message"`
}

// Details about why the response is incomplete.
type ResponseIncompleteDetails struct {
	// The reason why the response is incomplete.
	//
	// Any of "max_output_tokens", "content_filter".
	Reason string `json:"reason"`
}

// The conversation that this response belongs to. Input items and output items
// from this response are automatically added to this conversation.
type ResponseConversation struct {
	// The unique ID of the conversation.
	ID string `json:"id"`
}

// Reference to a prompt template and its variables.
// [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).
type ResponsePrompt struct {
	// The unique identifier of the prompt template to use.
	ID string `json:"id"`
	// Optional map of values to substitute in for variables in your prompt. The
	// substitution values can either be strings, or other Response input types like
	// images or files.
	Variables map[string]ResponsePromptVariableUnionParam `json:"variables,omitzero"`
	// Optional version of the prompt template.
	Version string `json:"version,omitzero"`
}

// Configuration options for a text response from the model. Can be plain text or
// structured JSON data. Learn more:
//
// - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
// - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
type ResponseTextConfig struct {
	// An object specifying the format that the model must output.
	//
	// Configuring `{ "type": "json_schema" }` enables Structured Outputs, which
	// ensures the model will match your supplied JSON schema. Learn more in the
	// [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).
	//
	// The default format is `{ "type": "text" }` with no additional options.
	//
	//
	// Setting to `{ "type": "json_object" }` enables the older JSON mode, which
	// ensures the message the model generates is valid JSON. Using `json_schema` is
	// preferred for models that support it.
	Format ResponseFormatTextConfigUnionParam `json:"format"`
	// Constrains the verbosity of the model's response. Lower values will result in
	// more concise responses, while higher values will result in more verbose
	// responses. Currently supported values are `low`, `medium`, and `high`.
	//
	// Any of "low", "medium", "high".
	Verbosity string `json:"verbosity,omitzero"`
}

// ResponseStreamEventUnion contains all possible properties and values for response events
// Any one of the fields should be set.
type ResponseStreamEventUnion struct {
	OfAudioDelta                         *ResponseAudioDeltaEvent
	OfAudioDone                          *ResponseAudioDoneEvent
	OfAudioTranscriptDelta               *ResponseAudioTranscriptDeltaEvent
	OfAudioTranscriptDone                *ResponseAudioTranscriptDoneEvent
	OfCodeInterpreterCallCodeDelta       *ResponseCodeInterpreterCallCodeDeltaEvent
	OfCodeInterpreterCallCodeDone        *ResponseCodeInterpreterCallCodeDoneEvent
	OfCodeInterpreterCallCompleted       *ResponseCodeInterpreterCallCompletedEvent
	OfCodeInterpreterCallInprogress      *ResponseCodeInterpreterCallInProgressEvent
	OfCodeInterpreterCallInterpreting    *ResponseCodeInterpreterCallInterpretingEvent
	OfResponseCompleted                  *ResponseCompletedEvent
	OfResponseContentPartAdded           *ResponseContentPartAddedEvent
	OfResponseContentPartDone            *ResponseContentPartDoneEvent
	OfResponseCreated                    *ResponseCreatedEvent
	OfError                              *ResponseErrorEvent
	OfResponseFileSearchCallCompleted    *ResponseFileSearchCallCompletedEvent
	OfResponseFileSearchCallInProgress   *ResponseFileSearchCallInProgressEvent
	OfResponseFileSearchCallSearching    *ResponseFileSearchCallSearchingEvent
	OfResponseFunctionCallArgumentsDelta *ResponseFunctionCallArgumentsDeltaEvent
	OfResponseFunctionCallArgumentsDone  *ResponseFunctionCallArgumentsDoneEvent
	OfResponseInProgress                 *ResponseInProgressEvent
	OfResponseFailed                     *ResponseFailedEvent
	OfResponseIncomplete                 *ResponseIncompleteEvent
	OfResponseOutputItemAdded            *ResponseOutputItemAddedEvent
	OfResponseOutputItemDone             *ResponseOutputItemDoneEvent
	OfResponseReasoningSummaryPartAdded  *ResponseReasoningSummaryPartAddedEvent
	OfResponseReasoningSummaryPartDone   *ResponseReasoningSummaryPartDoneEvent
	OfResponseReasoningSummaryTextDelta  *ResponseReasoningSummaryTextDeltaEvent
	OfResponseReasoningSummaryTextDone   *ResponseReasoningSummaryTextDoneEvent
	OfResponseReasoningTextDelta         *ResponseReasoningTextDeltaEvent
	OfResponseReasoningTextDone          *ResponseReasoningTextDoneEvent
	OfResponseRefusalDelta               *ResponseRefusalDeltaEvent
	OfResponseRefusalDone                *ResponseRefusalDoneEvent
	OfResponseTextDelta                  *ResponseTextDeltaEvent
	OfResponseTextDone                   *ResponseTextDoneEvent
	OfResponseWebSearchCallCompleted     *ResponseWebSearchCallCompletedEvent
	OfResponseWebSearchCallInProgress    *ResponseWebSearchCallInProgressEvent
	OfResponseWebSearchCallSearching     *ResponseWebSearchCallSearchingEvent
	OfResponseImageGenCallCompleted      *ResponseImageGenCallCompletedEvent
	OfResponseImageGenCallGenerating     *ResponseImageGenCallGeneratingEvent
	OfResponseImageGenCallInProgress     *ResponseImageGenCallInProgressEvent
	OfResponseImageGenCallPartialImage   *ResponseImageGenCallPartialImageEvent
	OfResponseMcpCallArgumentsDelta      *ResponseMcpCallArgumentsDeltaEvent
	OfResponseMcpCallArgumentsDone       *ResponseMcpCallArgumentsDoneEvent
	OfResponseMcpCallCompleted           *ResponseMcpCallCompletedEvent
	OfResponseMcpCallFailed              *ResponseMcpCallFailedEvent
	OfResponseMcpCallInProgress          *ResponseMcpCallInProgressEvent
	OfResponseMcpListToolsCompleted      *ResponseMcpListToolsCompletedEvent
	OfResponseMcpListToolsFailed         *ResponseMcpListToolsFailedEvent
	OfResponseMcpListToolsInProgress     *ResponseMcpListToolsInProgressEvent
	OfResponseOutputTextAnnotationAdded  *ResponseOutputTextAnnotationAddedEvent
	OfResponseQueued                     *ResponseQueuedEvent
	OfResponseCustomToolCallInputDelta   *ResponseCustomToolCallInputDeltaEvent
	OfResponseCustomToolCallInputDone    *ResponseCustomToolCallInputDoneEvent
}

func (r ResponseStreamEventUnion) MarshalJSON() ([]byte, error) { // nolint:gocritic
	switch {
	case r.OfAudioDelta != nil:
		return json.Marshal(r.OfAudioDelta)
	case r.OfAudioDone != nil:
		return json.Marshal(r.OfAudioDone)
	case r.OfAudioTranscriptDelta != nil:
		return json.Marshal(r.OfAudioTranscriptDelta)
	case r.OfAudioTranscriptDone != nil:
		return json.Marshal(r.OfAudioTranscriptDone)
	case r.OfCodeInterpreterCallCodeDelta != nil:
		return json.Marshal(r.OfCodeInterpreterCallCodeDelta)
	case r.OfCodeInterpreterCallCodeDone != nil:
		return json.Marshal(r.OfCodeInterpreterCallCodeDone)
	case r.OfCodeInterpreterCallCompleted != nil:
		return json.Marshal(r.OfCodeInterpreterCallCompleted)
	case r.OfCodeInterpreterCallInprogress != nil:
		return json.Marshal(r.OfCodeInterpreterCallInprogress)
	case r.OfCodeInterpreterCallInterpreting != nil:
		return json.Marshal(r.OfCodeInterpreterCallInterpreting)
	case r.OfResponseCompleted != nil:
		return json.Marshal(r.OfResponseCompleted)
	case r.OfResponseContentPartAdded != nil:
		return json.Marshal(r.OfResponseContentPartAdded)
	case r.OfResponseContentPartDone != nil:
		return json.Marshal(r.OfResponseContentPartDone)
	case r.OfResponseCreated != nil:
		return json.Marshal(r.OfResponseCreated)
	case r.OfError != nil:
		return json.Marshal(r.OfError)
	case r.OfResponseFileSearchCallCompleted != nil:
		return json.Marshal(r.OfResponseFileSearchCallCompleted)
	case r.OfResponseFileSearchCallInProgress != nil:
		return json.Marshal(r.OfResponseFileSearchCallInProgress)
	case r.OfResponseFileSearchCallSearching != nil:
		return json.Marshal(r.OfResponseFileSearchCallSearching)
	case r.OfResponseFunctionCallArgumentsDelta != nil:
		return json.Marshal(r.OfResponseFunctionCallArgumentsDelta)
	case r.OfResponseFunctionCallArgumentsDone != nil:
		return json.Marshal(r.OfResponseFunctionCallArgumentsDone)
	case r.OfResponseInProgress != nil:
		return json.Marshal(r.OfResponseInProgress)
	case r.OfResponseFailed != nil:
		return json.Marshal(r.OfResponseFailed)
	case r.OfResponseIncomplete != nil:
		return json.Marshal(r.OfResponseIncomplete)
	case r.OfResponseOutputItemAdded != nil:
		return json.Marshal(r.OfResponseOutputItemAdded)
	case r.OfResponseOutputItemDone != nil:
		return json.Marshal(r.OfResponseOutputItemDone)
	case r.OfResponseReasoningSummaryPartAdded != nil:
		return json.Marshal(r.OfResponseReasoningSummaryPartAdded)
	case r.OfResponseReasoningSummaryPartDone != nil:
		return json.Marshal(r.OfResponseReasoningSummaryPartDone)
	case r.OfResponseReasoningSummaryTextDelta != nil:
		return json.Marshal(r.OfResponseReasoningSummaryTextDelta)
	case r.OfResponseReasoningSummaryTextDone != nil:
		return json.Marshal(r.OfResponseReasoningSummaryTextDone)
	case r.OfResponseReasoningTextDelta != nil:
		return json.Marshal(r.OfResponseReasoningTextDelta)
	case r.OfResponseReasoningTextDone != nil:
		return json.Marshal(r.OfResponseReasoningTextDone)
	case r.OfResponseRefusalDelta != nil:
		return json.Marshal(r.OfResponseRefusalDelta)
	case r.OfResponseRefusalDone != nil:
		return json.Marshal(r.OfResponseRefusalDone)
	case r.OfResponseTextDelta != nil:
		return json.Marshal(r.OfResponseTextDelta)
	case r.OfResponseTextDone != nil:
		return json.Marshal(r.OfResponseTextDone)
	case r.OfResponseWebSearchCallCompleted != nil:
		return json.Marshal(r.OfResponseWebSearchCallCompleted)
	case r.OfResponseWebSearchCallInProgress != nil:
		return json.Marshal(r.OfResponseWebSearchCallInProgress)
	case r.OfResponseWebSearchCallSearching != nil:
		return json.Marshal(r.OfResponseWebSearchCallSearching)
	case r.OfResponseImageGenCallCompleted != nil:
		return json.Marshal(r.OfResponseImageGenCallCompleted)
	case r.OfResponseImageGenCallGenerating != nil:
		return json.Marshal(r.OfResponseImageGenCallGenerating)
	case r.OfResponseImageGenCallInProgress != nil:
		return json.Marshal(r.OfResponseImageGenCallInProgress)
	case r.OfResponseImageGenCallPartialImage != nil:
		return json.Marshal(r.OfResponseImageGenCallPartialImage)
	case r.OfResponseMcpCallArgumentsDelta != nil:
		return json.Marshal(r.OfResponseMcpCallArgumentsDelta)
	case r.OfResponseMcpCallArgumentsDone != nil:
		return json.Marshal(r.OfResponseMcpCallArgumentsDone)
	case r.OfResponseMcpCallCompleted != nil:
		return json.Marshal(r.OfResponseMcpCallCompleted)
	case r.OfResponseMcpCallFailed != nil:
		return json.Marshal(r.OfResponseMcpCallFailed)
	case r.OfResponseMcpCallInProgress != nil:
		return json.Marshal(r.OfResponseMcpCallInProgress)
	case r.OfResponseMcpListToolsCompleted != nil:
		return json.Marshal(r.OfResponseMcpListToolsCompleted)
	case r.OfResponseMcpListToolsFailed != nil:
		return json.Marshal(r.OfResponseMcpListToolsFailed)
	case r.OfResponseMcpListToolsInProgress != nil:
		return json.Marshal(r.OfResponseMcpListToolsInProgress)
	case r.OfResponseOutputTextAnnotationAdded != nil:
		return json.Marshal(r.OfResponseOutputTextAnnotationAdded)
	case r.OfResponseQueued != nil:
		return json.Marshal(r.OfResponseQueued)
	case r.OfResponseCustomToolCallInputDelta != nil:
		return json.Marshal(r.OfResponseCustomToolCallInputDelta)
	case r.OfResponseCustomToolCallInputDone != nil:
		return json.Marshal(r.OfResponseCustomToolCallInputDone)
	default:
		return nil, errors.New("no response stream event to marshal")
	}
}

func (r *ResponseStreamEventUnion) UnmarshalJSON(data []byte) error {
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "response.audio.delta":
		// Try to unmarshal as ResponseAudioDeltaEvent
		var event ResponseAudioDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfAudioDelta = &event
	case "response.audio.done":
		var event ResponseAudioDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfAudioDone = &event
	case "response.audio.transcript.delta":
		var event ResponseAudioTranscriptDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfAudioTranscriptDelta = &event
	case "response.audio.transcript.done":
		var event ResponseAudioTranscriptDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfAudioTranscriptDone = &event
	case "response.code_interpreter_call_code.delta":
		var event ResponseCodeInterpreterCallCodeDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfCodeInterpreterCallCodeDelta = &event
	case "response.code_interpreter_call_code.done":
		var event ResponseCodeInterpreterCallCodeDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfCodeInterpreterCallCodeDone = &event
	case "response.code_interpreter_call.completed":
		var event ResponseCodeInterpreterCallCompletedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfCodeInterpreterCallCompleted = &event
	case "response.code_interpreter_call.in_progress":
		var event ResponseCodeInterpreterCallInProgressEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfCodeInterpreterCallInprogress = &event
	case "response.code_interpreter_call.interpreting":
		var event ResponseCodeInterpreterCallInterpretingEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfCodeInterpreterCallInterpreting = &event
	case "response.completed":
		var event ResponseCompletedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseCompleted = &event
	case "response.content_part.added":
		var event ResponseContentPartAddedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseContentPartAdded = &event
	case "response.content_part.done":
		var event ResponseContentPartDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseContentPartDone = &event
	case "response.created":
		var event ResponseCreatedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseCreated = &event
	case "error":
		var event ResponseErrorEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfError = &event
	case "response.file_search_call.completed":
		var event ResponseFileSearchCallCompletedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseFileSearchCallCompleted = &event
	case "response.file_search_call.in_progress":
		var event ResponseFileSearchCallInProgressEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseFileSearchCallInProgress = &event
	case "response.file_search_call.searching":
		var event ResponseFileSearchCallSearchingEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseFileSearchCallSearching = &event
	case "response.function_call_arguments.delta":
		var event ResponseFunctionCallArgumentsDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseFunctionCallArgumentsDelta = &event
	case "response.function_call_arguments.done":
		var event ResponseFunctionCallArgumentsDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseFunctionCallArgumentsDone = &event
	case "response.in_progress":
		var event ResponseInProgressEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseInProgress = &event
	case "response.failed":
		var event ResponseFailedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseFailed = &event
	case "response.incomplete":
		var event ResponseIncompleteEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseIncomplete = &event
	case "response.output_item.added":
		var event ResponseOutputItemAddedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseOutputItemAdded = &event
	case "response.output_item.done":
		var event ResponseOutputItemDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseOutputItemDone = &event
	case "response.reasoning_summary_part.added":
		var event ResponseReasoningSummaryPartAddedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseReasoningSummaryPartAdded = &event
	case "response.reasoning_summary_part.done":
		var event ResponseReasoningSummaryPartDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseReasoningSummaryPartDone = &event
	case "response.reasoning_summary_text.delta":
		var event ResponseReasoningSummaryTextDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseReasoningSummaryTextDelta = &event
	case "response.reasoning_summary_text.done":
		var event ResponseReasoningSummaryTextDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseReasoningSummaryTextDone = &event
	case "response.reasoning_text.delta":
		var event ResponseReasoningTextDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseReasoningTextDelta = &event
	case "response.reasoning_text.done":
		var event ResponseReasoningTextDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseReasoningTextDone = &event
	case "response.refusal.delta":
		var event ResponseRefusalDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseRefusalDelta = &event
	case "response.refusal.done":
		var event ResponseRefusalDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseRefusalDone = &event
	case "response.output_text.delta":
		var event ResponseTextDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseTextDelta = &event
	case "response.output_text.done":
		var event ResponseTextDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseTextDone = &event
	case "response.web_search_call.completed":
		var event ResponseWebSearchCallCompletedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseWebSearchCallCompleted = &event
	case "response.web_search_call.in_progress":
		var event ResponseWebSearchCallInProgressEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseWebSearchCallInProgress = &event
	case "response.web_search_call.searching":
		var event ResponseWebSearchCallSearchingEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseWebSearchCallSearching = &event
	case "response.image_generation_call.completed":
		var event ResponseImageGenCallCompletedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseImageGenCallCompleted = &event
	case "response.image_generation_call.generating":
		var event ResponseImageGenCallGeneratingEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseImageGenCallGenerating = &event
	case "response.image_generation_call.in_progress":
		var event ResponseImageGenCallInProgressEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseImageGenCallInProgress = &event
	case "response.image_generation_call.partial_image":
		var event ResponseImageGenCallPartialImageEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseImageGenCallPartialImage = &event
	case "response.mcp_call_arguments.delta":
		var event ResponseMcpCallArgumentsDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseMcpCallArgumentsDelta = &event
	case "response.mcp_call_arguments.done":
		var event ResponseMcpCallArgumentsDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseMcpCallArgumentsDone = &event
	case "response.mcp_call.completed":
		var event ResponseMcpCallCompletedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseMcpCallCompleted = &event
	case "response.mcp_call.failed":
		var event ResponseMcpCallFailedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseMcpCallFailed = &event
	case "response.mcp_call.in_progress":
		var event ResponseMcpCallInProgressEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseMcpCallInProgress = &event
	case "response.mcp_list_tools.completed":
		var event ResponseMcpListToolsCompletedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseMcpListToolsCompleted = &event
	case "response.mcp_list_tools.failed":
		var event ResponseMcpListToolsFailedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseMcpListToolsFailed = &event
	case "response.mcp_list_tools.in_progress":
		var event ResponseMcpListToolsInProgressEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseMcpListToolsInProgress = &event
	case "response.output_text.annotation.added":
		var event ResponseOutputTextAnnotationAddedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseOutputTextAnnotationAdded = &event
	case "response.queued":
		var event ResponseQueuedEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseQueued = &event
	case "response.custom_tool_call_input.delta":
		var event ResponseCustomToolCallInputDeltaEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseCustomToolCallInputDelta = &event
	case "response.custom_tool_call_input.done":
		var event ResponseCustomToolCallInputDoneEvent
		if err := json.Unmarshal(data, &event); err != nil {
			return err
		}
		r.OfResponseCustomToolCallInputDone = &event
	default:
		return fmt.Errorf("unknown type field value '%s' for response stream event", typ.String())
	}
	return nil
}

func (r *ResponseStreamEventUnion) GetEventType() string {
	switch {
	case r.OfAudioDelta != nil:
		return r.OfAudioDelta.Type
	case r.OfAudioDone != nil:
		return r.OfAudioDone.Type
	case r.OfAudioTranscriptDelta != nil:
		return r.OfAudioTranscriptDelta.Type
	case r.OfAudioTranscriptDone != nil:
		return r.OfAudioTranscriptDone.Type
	case r.OfCodeInterpreterCallCodeDelta != nil:
		return r.OfCodeInterpreterCallCodeDelta.Type
	case r.OfCodeInterpreterCallCodeDone != nil:
		return r.OfCodeInterpreterCallCodeDone.Type
	case r.OfCodeInterpreterCallCompleted != nil:
		return r.OfCodeInterpreterCallCompleted.Type
	case r.OfCodeInterpreterCallInprogress != nil:
		return r.OfCodeInterpreterCallInprogress.Type
	case r.OfCodeInterpreterCallInterpreting != nil:
		return r.OfCodeInterpreterCallInterpreting.Type
	case r.OfResponseCompleted != nil:
		return r.OfResponseCompleted.Type
	case r.OfResponseContentPartAdded != nil:
		return r.OfResponseContentPartAdded.Type
	case r.OfResponseContentPartDone != nil:
		return r.OfResponseContentPartDone.Type
	case r.OfResponseCreated != nil:
		return r.OfResponseCreated.Type
	case r.OfError != nil:
		return r.OfError.Type
	case r.OfResponseFileSearchCallCompleted != nil:
		return r.OfResponseFileSearchCallCompleted.Type
	case r.OfResponseFileSearchCallInProgress != nil:
		return r.OfResponseFileSearchCallInProgress.Type
	case r.OfResponseFileSearchCallSearching != nil:
		return r.OfResponseFileSearchCallSearching.Type
	case r.OfResponseFunctionCallArgumentsDelta != nil:
		return r.OfResponseFunctionCallArgumentsDelta.Type
	case r.OfResponseFunctionCallArgumentsDone != nil:
		return r.OfResponseFunctionCallArgumentsDone.Type
	case r.OfResponseInProgress != nil:
		return r.OfResponseInProgress.Type
	case r.OfResponseFailed != nil:
		return r.OfResponseFailed.Type
	case r.OfResponseIncomplete != nil:
		return r.OfResponseIncomplete.Type
	case r.OfResponseOutputItemAdded != nil:
		return r.OfResponseOutputItemAdded.Type
	case r.OfResponseOutputItemDone != nil:
		return r.OfResponseOutputItemDone.Type
	case r.OfResponseReasoningSummaryPartAdded != nil:
		return r.OfResponseReasoningSummaryPartAdded.Type
	case r.OfResponseReasoningSummaryPartDone != nil:
		return r.OfResponseReasoningSummaryPartDone.Type
	case r.OfResponseReasoningSummaryTextDelta != nil:
		return r.OfResponseReasoningSummaryTextDelta.Type
	case r.OfResponseReasoningSummaryTextDone != nil:
		return r.OfResponseReasoningSummaryTextDone.Type
	case r.OfResponseReasoningTextDelta != nil:
		return r.OfResponseReasoningTextDelta.Type
	case r.OfResponseReasoningTextDone != nil:
		return r.OfResponseReasoningTextDone.Type
	case r.OfResponseRefusalDelta != nil:
		return r.OfResponseRefusalDelta.Type
	case r.OfResponseRefusalDone != nil:
		return r.OfResponseRefusalDone.Type
	case r.OfResponseTextDelta != nil:
		return r.OfResponseTextDelta.Type
	case r.OfResponseTextDone != nil:
		return r.OfResponseTextDone.Type
	case r.OfResponseWebSearchCallCompleted != nil:
		return r.OfResponseWebSearchCallCompleted.Type
	case r.OfResponseWebSearchCallInProgress != nil:
		return r.OfResponseWebSearchCallInProgress.Type
	case r.OfResponseWebSearchCallSearching != nil:
		return r.OfResponseWebSearchCallSearching.Type
	case r.OfResponseImageGenCallCompleted != nil:
		return r.OfResponseImageGenCallCompleted.Type
	case r.OfResponseImageGenCallGenerating != nil:
		return r.OfResponseImageGenCallGenerating.Type
	case r.OfResponseImageGenCallInProgress != nil:
		return r.OfResponseImageGenCallInProgress.Type
	case r.OfResponseImageGenCallPartialImage != nil:
		return r.OfResponseImageGenCallPartialImage.Type
	case r.OfResponseMcpCallArgumentsDelta != nil:
		return r.OfResponseMcpCallArgumentsDelta.Type
	case r.OfResponseMcpCallArgumentsDone != nil:
		return r.OfResponseMcpCallArgumentsDone.Type
	case r.OfResponseMcpCallCompleted != nil:
		return r.OfResponseMcpCallCompleted.Type
	case r.OfResponseMcpCallFailed != nil:
		return r.OfResponseMcpCallFailed.Type
	case r.OfResponseMcpCallInProgress != nil:
		return r.OfResponseMcpCallInProgress.Type
	case r.OfResponseMcpListToolsCompleted != nil:
		return r.OfResponseMcpListToolsCompleted.Type
	case r.OfResponseMcpListToolsFailed != nil:
		return r.OfResponseMcpListToolsFailed.Type
	case r.OfResponseMcpListToolsInProgress != nil:
		return r.OfResponseMcpListToolsInProgress.Type
	case r.OfResponseOutputTextAnnotationAdded != nil:
		return r.OfResponseOutputTextAnnotationAdded.Type
	case r.OfResponseQueued != nil:
		return r.OfResponseQueued.Type
	case r.OfResponseCustomToolCallInputDelta != nil:
		return r.OfResponseCustomToolCallInputDelta.Type
	case r.OfResponseCustomToolCallInputDone != nil:
		return r.OfResponseCustomToolCallInputDone.Type
	default:
		return ""
	}
}

// Emitted when there is a partial audio response.
type ResponseAudioDeltaEvent struct {
	// A chunk of Base64 encoded response audio bytes.
	Delta string `json:"delta"`
	// A sequence number for this chunk of the stream response.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.audio.delta`.
	Type string `json:"type"`
}

// Emitted when the audio response is complete.
type ResponseAudioDoneEvent struct {
	// The sequence number of the delta.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.audio.done`.
	Type string `json:"type"`
	// JSON contains metadata for fields, check presence with [respjson.Field.Valid].
}

// Emitted when there is a partial transcript of audio.
type ResponseAudioTranscriptDeltaEvent struct {
	// The partial transcript of the audio response.
	Delta string `json:"delta"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.audio.transcript.delta`.
	Type string `json:"type"`
}

// Emitted when the full audio transcript is completed.
type ResponseAudioTranscriptDoneEvent struct {
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.audio.transcript.done`.
	Type string `json:"type"`
}

// Emitted when a partial code snippet is streamed by the code interpreter.
type ResponseCodeInterpreterCallCodeDeltaEvent struct {
	// The partial code snippet being streamed by the code interpreter.
	Delta string `json:"delta"`
	// The unique identifier of the code interpreter tool call item.
	ItemID string `json:"item_id"`
	// The index of the output item in the response for which the code is being
	// streamed.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event, used to order streaming events.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.code_interpreter_call_code.delta`.
	Type string `json:"type"`
}

// Emitted when the code snippet is finalized by the code interpreter.
type ResponseCodeInterpreterCallCodeDoneEvent struct {
	// The final code snippet output by the code interpreter.
	Code string `json:"code"`
	// The unique identifier of the code interpreter tool call item.
	ItemID string `json:"item_id"`
	// The index of the output item in the response for which the code is finalized.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event, used to order streaming events.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.code_interpreter_call_code.done`.
	Type string `json:"type"`
}

// Emitted when the code interpreter call is completed.
type ResponseCodeInterpreterCallCompletedEvent struct {
	// The unique identifier of the code interpreter tool call item.
	ItemID string `json:"item_id"`
	// The index of the output item in the response for which the code interpreter call
	// is completed.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event, used to order streaming events.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.code_interpreter_call.completed`.
	Type string `json:"type"`
}

// Emitted when a code interpreter call is in progress.
type ResponseCodeInterpreterCallInProgressEvent struct {
	// The unique identifier of the code interpreter tool call item.
	ItemID string `json:"item_id"`
	// The index of the output item in the response for which the code interpreter call
	// is in progress.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event, used to order streaming events.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.code_interpreter_call.in_progress`.
	Type string `json:"type"`
}

// Emitted when the code interpreter is actively interpreting the code snippet.
type ResponseCodeInterpreterCallInterpretingEvent struct {
	// The unique identifier of the code interpreter tool call item.
	ItemID string `json:"item_id"`
	// The index of the output item in the response for which the code interpreter is
	// interpreting code.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event, used to order streaming events.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.code_interpreter_call.interpreting`.
	Type string `json:"type"`
}

// A tool call to run code.
type ResponseCodeInterpreterToolCall struct {
	// The unique ID of the code interpreter tool call.
	ID string `json:"id"`
	// The code to run, or null if not available.
	Code string `json:"code"`
	// The ID of the container used to run the code.
	ContainerID string `json:"container_id"`
	// The outputs generated by the code interpreter, such as logs or images. Can be
	// null if no outputs are available.
	Outputs []ResponseCodeInterpreterToolCallOutputUnion `json:"outputs"`
	// The status of the code interpreter tool call. Valid values are `in_progress`,
	// `completed`, `incomplete`, `interpreting`, and `failed`.
	//
	// Any of "in_progress", "completed", "incomplete", "interpreting", "failed".
	Status string `json:"status"`
	// The type of the code interpreter tool call. Always `code_interpreter_call`.
	Type string `json:"type"`
}

// ResponseCodeInterpreterToolCallOutputUnion contains all possible properties and
// values from [ResponseCodeInterpreterToolCallOutputLogs],
// [ResponseCodeInterpreterToolCallOutputImage].
type ResponseCodeInterpreterToolCallOutputUnion struct {
	OfResponseCodeInterpreterToolCallOutputLogs  *ResponseCodeInterpreterToolCallOutputLogs
	OfResponseCodeInterpreterToolCallOutputImage *ResponseCodeInterpreterToolCallOutputImage
}

func (r ResponseCodeInterpreterToolCallOutputUnion) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfResponseCodeInterpreterToolCallOutputLogs != nil:
		return json.Marshal(r.OfResponseCodeInterpreterToolCallOutputLogs)
	case r.OfResponseCodeInterpreterToolCallOutputImage != nil:
		return json.Marshal(r.OfResponseCodeInterpreterToolCallOutputImage)
	default:
		return nil, errors.New("no output to marshal in code interpreter tool call output")
	}
}

func (r *ResponseCodeInterpreterToolCallOutputUnion) UnmarshalJSON(data []byte) error {
	// Peek at the "type" field to determine which struct to unmarshal into
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "logs":
		var logs ResponseCodeInterpreterToolCallOutputLogs
		if err := json.Unmarshal(data, &logs); err != nil {
			return err
		}
		r.OfResponseCodeInterpreterToolCallOutputLogs = &logs
		return nil
	case "image":
		var image ResponseCodeInterpreterToolCallOutputImage
		if err := json.Unmarshal(data, &image); err != nil {
			return err
		}
		r.OfResponseCodeInterpreterToolCallOutputImage = &image
		return nil
	default:
		return fmt.Errorf("unknown type for code interpreter tool call output: %s", typ.String())
	}
}

// The logs output from the code interpreter.
type ResponseCodeInterpreterToolCallOutputLogs struct {
	// The logs output from the code interpreter.
	Logs string `json:"logs"`
	// The type of the output. Always `logs`.
	Type string `json:"type"`
}

// The image output from the code interpreter.
type ResponseCodeInterpreterToolCallOutputImage struct {
	// The type of the output. Always `image`.
	Type string `json:"type"`
	// The URL of the image output from the code interpreter.
	URL string `json:"url"`
}

// Emitted when a new content part is added.
type ResponseContentPartAddedEvent struct {
	// The index of the content part that was added.
	ContentIndex int64 `json:"content_index"`
	// The ID of the output item that the content part was added to.
	ItemID string `json:"item_id"`
	// The index of the output item that the content part was added to.
	OutputIndex int64 `json:"output_index"`
	// The content part that was added.
	Part ResponseContentPartAddedEventPartUnion `json:"part"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.content_part.added`.
	Type string `json:"type"`
}

// ResponseContentPartAddedEventPartUnion contains all possible properties and
// values from [ResponseOutputText], [ResponseOutputRefusal],
// [ResponseContentPartAddedEventPartReasoningText].
type ResponseContentPartAddedEventPartUnion struct {
	OfResponseOutputText                            *ResponseOutputTextParam
	OfResponseOutputRefusal                         *ResponseOutputRefusalParam
	OfResponsContentPartAddedEventPartReasoningText *ResponseContentPartAddedEventPartReasoningText
}

func (r ResponseContentPartAddedEventPartUnion) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfResponseOutputText != nil:
		return json.Marshal(r.OfResponseOutputText)
	case r.OfResponseOutputRefusal != nil:
		return json.Marshal(r.OfResponseOutputRefusal)
	case r.OfResponsContentPartAddedEventPartReasoningText != nil:
		return json.Marshal(r.OfResponsContentPartAddedEventPartReasoningText)
	default:
		return nil, errors.New("no part to marshal in content part added event")
	}
}

func (r *ResponseContentPartAddedEventPartUnion) UnmarshalJSON(data []byte) error {
	// Peek at the "type" field to determine which struct to unmarshal into
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "output_text":
		var text ResponseOutputTextParam
		if err := json.Unmarshal(data, &text); err != nil {
			return err
		}
		r.OfResponseOutputText = &text
		return nil
	case "refusal":
		var refusal ResponseOutputRefusalParam
		if err := json.Unmarshal(data, &refusal); err != nil {
			return err
		}
		r.OfResponseOutputRefusal = &refusal
		return nil
	case "reasoning_text":
		var reasoningText ResponseContentPartAddedEventPartReasoningText
		if err := json.Unmarshal(data, &reasoningText); err != nil {
			return err
		}
		r.OfResponsContentPartAddedEventPartReasoningText = &reasoningText
		return nil
	default:
		return fmt.Errorf("unknown type for content part added event part: %s", typ.String())
	}
}

// Reasoning text from the model.
type ResponseContentPartAddedEventPartReasoningText struct {
	// The reasoning text from the model.
	Text string `json:"text"`
	// The type of the reasoning text. Always `reasoning_text`.
	Type string `json:"type"`
}

// Emitted when a content part is done.
type ResponseContentPartDoneEvent struct {
	// The index of the content part that is done.
	ContentIndex int64 `json:"content_index"`
	// The ID of the output item that the content part was added to.
	ItemID string `json:"item_id"`
	// The index of the output item that the content part was added to.
	OutputIndex int64 `json:"output_index"`
	// The content part that is done.
	Part ResponseContentPartDoneEventPartUnion `json:"part"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.content_part.done`.
	Type string `json:"type"`
}

// ResponseContentPartDoneEventPartUnion contains all possible properties and
// values from [ResponseOutputText], [ResponseOutputRefusal],
// [ResponseContentPartDoneEventPartReasoningText].
type ResponseContentPartDoneEventPartUnion struct {
	OfResponseOutputText                           *ResponseOutputTextParam
	OfResponseOutputRefusal                        *ResponseOutputRefusalParam
	OfResponsContentPartDoneEventPartReasoningText *ResponseContentPartDoneEventPartReasoningText
}

func (r ResponseContentPartDoneEventPartUnion) MarshalJSON() ([]byte, error) {
	switch {
	case r.OfResponseOutputText != nil:
		return json.Marshal(r.OfResponseOutputText)
	case r.OfResponseOutputRefusal != nil:
		return json.Marshal(r.OfResponseOutputRefusal)
	case r.OfResponsContentPartDoneEventPartReasoningText != nil:
		return json.Marshal(r.OfResponsContentPartDoneEventPartReasoningText)
	default:
		return nil, errors.New("no part to marshal in content part done event")
	}
}

func (r *ResponseContentPartDoneEventPartUnion) UnmarshalJSON(data []byte) error {
	// Peek at the "type" field to determine which struct to unmarshal into
	typ := gjson.GetBytes(data, "type")
	switch typ.String() {
	case "output_text":
		var text ResponseOutputTextParam
		if err := json.Unmarshal(data, &text); err != nil {
			return err
		}
		r.OfResponseOutputText = &text
		return nil
	case "refusal":
		var refusal ResponseOutputRefusalParam
		if err := json.Unmarshal(data, &refusal); err != nil {
			return err
		}
		r.OfResponseOutputRefusal = &refusal
		return nil
	case "reasoning_text":
		var reasoningText ResponseContentPartDoneEventPartReasoningText
		if err := json.Unmarshal(data, &reasoningText); err != nil {
			return err
		}
		r.OfResponsContentPartDoneEventPartReasoningText = &reasoningText
		return nil
	default:
		return fmt.Errorf("unknown type for content part done event part: %s", typ.String())
	}
}

// Reasoning text from the model.
type ResponseContentPartDoneEventPartReasoningText struct {
	// The reasoning text from the model.
	Text string `json:"text"`
	// The type of the reasoning text. Always `reasoning_text`.
	Type string `json:"type"`
}

// An event that is emitted when a response is created.
type ResponseCreatedEvent struct {
	// The response that was created.
	Response Response `json:"response"`
	// The sequence number for this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.created`.
	Type string `json:"type"`
}

// Emitted when an error occurs.
type ResponseErrorEvent struct {
	// The error code.
	Code string `json:"code"`
	// The error message.
	Message string `json:"message"`
	// The error parameter.
	Param string `json:"param"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `error`.
	Type string `json:"type"`
}

// An event that is emitted when a response fails.
type ResponseFailedEvent struct {
	// The response that failed.
	Response Response `json:"response"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.failed`.
	Type string `json:"type"`
}

// Emitted when a file search call is completed (results found).
type ResponseFileSearchCallCompletedEvent struct {
	// The ID of the output item that the file search call is initiated.
	ItemID string `json:"item_id"`
	// The index of the output item that the file search call is initiated.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.file_search_call.completed`.
	Type string `json:"type"`
}

// Emitted when a file search call is initiated.
type ResponseFileSearchCallInProgressEvent struct {
	// The ID of the output item that the file search call is initiated.
	ItemID string `json:"item_id"`
	// The index of the output item that the file search call is initiated.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.file_search_call.in_progress`.
	Type string `json:"type"`
}

// Emitted when a file search is currently searching.
type ResponseFileSearchCallSearchingEvent struct {
	// The ID of the output item that the file search call is initiated.
	ItemID string `json:"item_id"`
	// The index of the output item that the file search call is searching.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.file_search_call.searching`.
	Type string `json:"type"`
}

// Emitted when there is a partial function-call arguments delta.
type ResponseFunctionCallArgumentsDeltaEvent struct {
	// The function-call arguments delta that is added.
	Delta string `json:"delta"`
	// The ID of the output item that the function-call arguments delta is added to.
	ItemID string `json:"item_id"`
	// The index of the output item that the function-call arguments delta is added to.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.function_call_arguments.delta`.
	Type string `json:"type"`
}

// Emitted when function-call arguments are finalized.
type ResponseFunctionCallArgumentsDoneEvent struct {
	// The function-call arguments.
	Arguments string `json:"arguments"`
	// The ID of the item.
	ItemID string `json:"item_id"`
	// The name of the function that was called.
	Name string `json:"name"`
	// The index of the output item.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.function_call_arguments.done`.
	Type string `json:"type"`
}

// Emitted when the response is in progress.
type ResponseInProgressEvent struct {
	// The response that is in progress.
	Response Response `json:"response"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.in_progress`.
	Type string `json:"type"`
}

// Emitted when the model response is complete.
type ResponseCompletedEvent struct {
	// Properties of the completed response.
	Response Response `json:"response"`
	// The sequence number for this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.completed`.
	Type string `json:"type"`
}

// An event that is emitted when a response finishes as incomplete.
type ResponseIncompleteEvent struct {
	// The response that was incomplete.
	Response Response `json:"response"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.incomplete`.
	Type string `json:"type"`
}

// Emitted when a new output item is added.
type ResponseOutputItemAddedEvent struct {
	// The output item that was added.
	Item ResponseOutputItemUnion `json:"item"`
	// The index of the output item that was added.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.output_item.added`.
	Type string `json:"type"`
}

// Emitted when an output item is marked done.
type ResponseOutputItemDoneEvent struct {
	// The output item that was marked done.
	Item ResponseOutputItemUnion `json:"item"`
	// The index of the output item that was marked done.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.output_item.done`.
	Type string `json:"type"`
}

// Emitted when a new reasoning summary part is added.
type ResponseReasoningSummaryPartAddedEvent struct {
	// The ID of the item this summary part is associated with.
	ItemID string `json:"item_id"`
	// The index of the output item this summary part is associated with.
	OutputIndex int64 `json:"output_index"`
	// The summary part that was added.
	Part ResponseReasoningSummaryPartAddedEventPart `json:"part"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The index of the summary part within the reasoning summary.
	SummaryIndex int64 `json:"summary_index"`
	// The type of the event. Always `response.reasoning_summary_part.added`.
	Type string `json:"type"`
}

// The summary part that was added.
type ResponseReasoningSummaryPartAddedEventPart struct {
	// The text of the summary part.
	Text string `json:"text"`
	// The type of the summary part. Always `summary_text`.
	Type string `json:"type"`
}

// Emitted when a reasoning summary part is completed.
type ResponseReasoningSummaryPartDoneEvent struct {
	// The ID of the item this summary part is associated with.
	ItemID string `json:"item_id"`
	// The index of the output item this summary part is associated with.
	OutputIndex int64 `json:"output_index"`
	// The completed summary part.
	Part ResponseReasoningSummaryPartDoneEventPart `json:"part"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The index of the summary part within the reasoning summary.
	SummaryIndex int64 `json:"summary_index"`
	// The type of the event. Always `response.reasoning_summary_part.done`.
	Type string `json:"type"`
}

// The completed summary part.
type ResponseReasoningSummaryPartDoneEventPart struct {
	// The text of the summary part.
	Text string `json:"text"`
	// The type of the summary part. Always `summary_text`.
	Type string `json:"type"`
}

// Emitted when a delta is added to a reasoning summary text.
type ResponseReasoningSummaryTextDeltaEvent struct {
	// The text delta that was added to the summary.
	Delta string `json:"delta"`
	// The ID of the item this summary text delta is associated with.
	ItemID string `json:"item_id"`
	// The index of the output item this summary text delta is associated with.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The index of the summary part within the reasoning summary.
	SummaryIndex int64 `json:"summary_index"`
	// The type of the event. Always `response.reasoning_summary_text.delta`.
	Type string `json:"type"`
}

// Emitted when a reasoning summary text is completed.
type ResponseReasoningSummaryTextDoneEvent struct {
	// The ID of the item this summary text is associated with.
	ItemID string `json:"item_id"`
	// The index of the output item this summary text is associated with.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The index of the summary part within the reasoning summary.
	SummaryIndex int64 `json:"summary_index"`
	// The full text of the completed reasoning summary.
	Text string `json:"text"`
	// The type of the event. Always `response.reasoning_summary_text.done`.
	Type string `json:"type"`
}

// Emitted when a delta is added to a reasoning text.
type ResponseReasoningTextDeltaEvent struct {
	// The index of the reasoning content part this delta is associated with.
	ContentIndex int64 `json:"content_index"`
	// The text delta that was added to the reasoning content.
	Delta string `json:"delta"`
	// The ID of the item this reasoning text delta is associated with.
	ItemID string `json:"item_id"`
	// The index of the output item this reasoning text delta is associated with.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.reasoning_text.delta`.
	Type string `json:"type"`
}

// Emitted when a reasoning text is completed.
type ResponseReasoningTextDoneEvent struct {
	// The index of the reasoning content part.
	ContentIndex int64 `json:"content_index"`
	// The ID of the item this reasoning text is associated with.
	ItemID string `json:"item_id"`
	// The index of the output item this reasoning text is associated with.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The full text of the completed reasoning content.
	Text string `json:"text"`
	// The type of the event. Always `response.reasoning_text.done`.
	Type string `json:"type"`
}

// Emitted when there is a partial refusal text.
type ResponseRefusalDeltaEvent struct {
	// The index of the content part that the refusal text is added to.
	ContentIndex int64 `json:"content_index"`
	// The refusal text that is added.
	Delta string `json:"delta"`
	// The ID of the output item that the refusal text is added to.
	ItemID string `json:"item_id"`
	// The index of the output item that the refusal text is added to.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.refusal.delta`.
	Type string `json:"type"`
}

// Emitted when refusal text is finalized.
type ResponseRefusalDoneEvent struct {
	// The index of the content part that the refusal text is finalized.
	ContentIndex int64 `json:"content_index"`
	// The ID of the output item that the refusal text is finalized.
	ItemID string `json:"item_id"`
	// The index of the output item that the refusal text is finalized.
	OutputIndex int64 `json:"output_index"`
	// The refusal text that is finalized.
	Refusal string `json:"refusal"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.refusal.done`.
	Type string `json:"type"`
}

// Emitted when there is an additional text delta.
type ResponseTextDeltaEvent struct {
	// The index of the content part that the text delta was added to.
	ContentIndex int64 `json:"content_index"`
	// The text delta that was added.
	Delta string `json:"delta"`
	// The ID of the output item that the text delta was added to.
	ItemID string `json:"item_id"`
	// The log probabilities of the tokens in the delta.
	Logprobs []ResponseTextDeltaEventLogprob `json:"logprobs,omitzero"`
	// The index of the output item that the text delta was added to.
	OutputIndex int64 `json:"output_index"`
	// The sequence number for this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.output_text.delta`.
	Type string `json:"type"`
}

// A logprob is the logarithmic probability that the model assigns to producing a
// particular token at a given position in the sequence. Less-negative (higher)
// logprob values indicate greater model confidence in that token choice.
type ResponseTextDeltaEventLogprob struct {
	// A possible text token.
	Token string `json:"token"`
	// The log probability of this token.
	Logprob float64 `json:"logprob"`
	// The log probability of the top 20 most likely tokens.
	TopLogprobs []ResponseTextDeltaEventLogprobTopLogprob `json:"top_logprobs"`
}

type ResponseTextDeltaEventLogprobTopLogprob struct {
	// A possible text token.
	Token string `json:"token"`
	// The log probability of this token.
	Logprob float64 `json:"logprob"`
}

// Emitted when text content is finalized.
type ResponseTextDoneEvent struct {
	// The index of the content part that the text content is finalized.
	ContentIndex int64 `json:"content_index"`
	// The ID of the output item that the text content is finalized.
	ItemID string `json:"item_id"`
	// The log probabilities of the tokens in the delta.
	Logprobs []ResponseTextDoneEventLogprob `json:"logprobs,omitzero"`
	// The index of the output item that the text content is finalized.
	OutputIndex int64 `json:"output_index"`
	// The sequence number for this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The text content that is finalized.
	Text string `json:"text"`
	// The type of the event. Always `response.output_text.done`.
	Type string `json:"type"`
}

// A logprob is the logarithmic probability that the model assigns to producing a
// particular token at a given position in the sequence. Less-negative (higher)
// logprob values indicate greater model confidence in that token choice.
type ResponseTextDoneEventLogprob struct {
	// A possible text token.
	Token string `json:"token"`
	// The log probability of this token.
	Logprob float64 `json:"logprob"`
	// The log probability of the top 20 most likely tokens.
	TopLogprobs []ResponseTextDoneEventLogprobTopLogprob `json:"top_logprobs"`
}

type ResponseTextDoneEventLogprobTopLogprob struct {
	// A possible text token.
	Token string `json:"token"`
	// The log probability of this token.
	Logprob float64 `json:"logprob"`
}

// Emitted when a web search call is completed.
type ResponseWebSearchCallCompletedEvent struct {
	// Unique ID for the output item associated with the web search call.
	ItemID string `json:"item_id"`
	// The index of the output item that the web search call is associated with.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of the web search call being processed.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.web_search_call.completed`.
	Type string `json:"type"`
}

// Emitted when a web search call is initiated.
type ResponseWebSearchCallInProgressEvent struct {
	// Unique ID for the output item associated with the web search call.
	ItemID string `json:"item_id"`
	// The index of the output item that the web search call is associated with.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of the web search call being processed.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.web_search_call.in_progress`.
	Type string `json:"type"`
}

// Emitted when a web search call is executing.
type ResponseWebSearchCallSearchingEvent struct {
	// Unique ID for the output item associated with the web search call.
	ItemID string `json:"item_id"`
	// The index of the output item that the web search call is associated with.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of the web search call being processed.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always `response.web_search_call.searching`.
	Type string `json:"type"`
}

// Emitted when an image generation tool call has completed and the final image is
// available.
type ResponseImageGenCallCompletedEvent struct {
	// The unique identifier of the image generation item being processed.
	ItemID string `json:"item_id"`
	// The index of the output item in the response's output array.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.image_generation_call.completed'.
	Type string `json:"type"`
}

// Emitted when an image generation tool call is actively generating an image
// (intermediate state).
type ResponseImageGenCallGeneratingEvent struct {
	// The unique identifier of the image generation item being processed.
	ItemID string `json:"item_id"`
	// The index of the output item in the response's output array.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of the image generation item being processed.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.image_generation_call.generating'.
	Type string `json:"type"`
}

// Emitted when an image generation tool call is in progress.
type ResponseImageGenCallInProgressEvent struct {
	// The unique identifier of the image generation item being processed.
	ItemID string `json:"item_id"`
	// The index of the output item in the response's output array.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of the image generation item being processed.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.image_generation_call.in_progress'.
	Type string `json:"type"`
}

// Emitted when a partial image is available during image generation streaming.
type ResponseImageGenCallPartialImageEvent struct {
	// The unique identifier of the image generation item being processed.
	ItemID string `json:"item_id"`
	// The index of the output item in the response's output array.
	OutputIndex int64 `json:"output_index"`
	// Base64-encoded partial image data, suitable for rendering as an image.
	PartialImageB64 string `json:"partial_image_b64"`
	// 0-based index for the partial image (backend is 1-based, but this is 0-based for
	// the user).
	PartialImageIndex int64 `json:"partial_image_index"`
	// The sequence number of the image generation item being processed.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.image_generation_call.partial_image'.
	Type string `json:"type"`
}

// Emitted when there is a delta (partial update) to the arguments of an MCP tool
// call.
type ResponseMcpCallArgumentsDeltaEvent struct {
	// A JSON string containing the partial update to the arguments for the MCP tool
	// call.
	Delta string `json:"delta"`
	// The unique identifier of the MCP tool call item being processed.
	ItemID string `json:"item_id"`
	// The index of the output item in the response's output array.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.mcp_call_arguments.delta'.
	Type string `json:"type"`
}

// Emitted when the arguments for an MCP tool call are finalized.
type ResponseMcpCallArgumentsDoneEvent struct {
	// A JSON string containing the finalized arguments for the MCP tool call.
	Arguments string `json:"arguments"`
	// The unique identifier of the MCP tool call item being processed.
	ItemID string `json:"item_id"`
	// The index of the output item in the response's output array.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.mcp_call_arguments.done'.
	Type string `json:"type"`
}

// Emitted when an MCP tool call has completed successfully.
type ResponseMcpCallCompletedEvent struct {
	// The ID of the MCP tool call item that completed.
	ItemID string `json:"item_id"`
	// The index of the output item that completed.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.mcp_call.completed'.
	Type string `json:"type"`
}

// Emitted when an MCP tool call has failed.
type ResponseMcpCallFailedEvent struct {
	// The ID of the MCP tool call item that failed.
	ItemID string `json:"item_id"`
	// The index of the output item that failed.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.mcp_call.failed'.
	Type string `json:"type"`
}

// Emitted when an MCP tool call is in progress.
type ResponseMcpCallInProgressEvent struct {
	// The unique identifier of the MCP tool call item being processed.
	ItemID string `json:"item_id"`
	// The index of the output item in the response's output array.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.mcp_call.in_progress'.
	Type string `json:"type"`
}

// Emitted when the list of available MCP tools has been successfully retrieved.
type ResponseMcpListToolsCompletedEvent struct {
	// The ID of the MCP tool call item that produced this output.
	ItemID string `json:"item_id"`
	// The index of the output item that was processed.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.mcp_list_tools.completed'.
	Type string `json:"type"`
}

// Emitted when the attempt to list available MCP tools has failed.
type ResponseMcpListToolsFailedEvent struct {
	// The ID of the MCP tool call item that failed.
	ItemID string `json:"item_id"`
	// The index of the output item that failed.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.mcp_list_tools.failed'.
	Type string `json:"type"`
}

// Emitted when the system is in the process of retrieving the list of available
// MCP tools.
type ResponseMcpListToolsInProgressEvent struct {
	// The ID of the MCP tool call item that is being processed.
	ItemID string `json:"item_id"`
	// The index of the output item that is being processed.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.mcp_list_tools.in_progress'.
	Type string `json:"type"`
}

// Emitted when an annotation is added to output text content.
type ResponseOutputTextAnnotationAddedEvent struct {
	// The annotation object being added. (See annotation schema for details.)
	Annotation any `json:"annotation"`
	// The index of the annotation within the content part.
	AnnotationIndex int64 `json:"annotation_index"`
	// The index of the content part within the output item.
	ContentIndex int64 `json:"content_index"`
	// The unique identifier of the item to which the annotation is being added.
	ItemID string `json:"item_id"`
	// The index of the output item in the response's output array.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.output_text.annotation.added'.
	Type string `json:"type"`
}

// Emitted when a response is queued and waiting to be processed.
type ResponseQueuedEvent struct {
	// The full response object that is queued.
	Response Response `json:"response"`
	// The sequence number for this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The type of the event. Always 'response.queued'.
	Type string `json:"type"`
}

// Event representing a delta (partial update) to the input of a custom tool call.
type ResponseCustomToolCallInputDeltaEvent struct {
	// The incremental input data (delta) for the custom tool call.
	Delta string `json:"delta"`
	// Unique identifier for the API item associated with this event.
	ItemID string `json:"item_id"`
	// The index of the output this delta applies to.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The event type identifier. Always response.custom_tool_call_input.delta
	Type string `json:"type"`
}

// Event indicating that input for a custom tool call is complete.
type ResponseCustomToolCallInputDoneEvent struct {
	// The complete input data for the custom tool call.
	Input string `json:"input"`
	// Unique identifier for the API item associated with this event.
	ItemID string `json:"item_id"`
	// The index of the output this event applies to.
	OutputIndex int64 `json:"output_index"`
	// The sequence number of this event.
	SequenceNumber int64 `json:"sequence_number"`
	// The event type identifier. Always response.custom_tool_call_input.done
	Type string `json:"type"`
}
